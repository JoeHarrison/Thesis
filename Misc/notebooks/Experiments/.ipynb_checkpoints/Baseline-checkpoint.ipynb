{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import rubiks\n",
    "import rubiks2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os \n",
    "import copy\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from replay_memories import ReplayMemory, PrioritizedReplayMemory\n",
    "from networks import DQN, DuelingDQN, DuelingDQNHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Torch Version:  1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "print(\"Torch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon decay\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 1000\n",
    "\n",
    "epsilon_by_exponential_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "\n",
    "epsilon_by_linear_step = lambda step_idx: epsilon_final + (epsilon_start-epsilon_final)*((epsilon_decay-step_idx)/epsilon_decay) if step_idx < epsilon_decay else epsilon_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b9c4e38d0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.title('Epsilon decay')\n",
    "plt.xlabel('Global steps')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.plot([epsilon_by_exponential_step(i) for i in range(10000)])\n",
    "plt.plot([epsilon_by_linear_step(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the q-values of an action in a state\n",
    "def compute_q_val(model, state, action):\n",
    "    qactions = model(state)\n",
    "    return torch.gather(qactions,1,action.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the target. When done, 0 is added to the reward as there is no next state.\n",
    "def compute_target_dqn(model, reward, next_state, done, gamma):\n",
    "    return reward + gamma * model(next_state).max(1)[0] * (1-done)\n",
    "\n",
    "# Computes the target. When done, 0 is added to the reward as there is no next state. But now for Double DQN\n",
    "def compute_target_ddqn(model, target_model, reward, next_state, done, gamma):\n",
    "    a = model(next_state)\n",
    "    return reward.view(-1,1) + gamma * torch.gather(target_model(next_state),1,model(next_state).max(1)[1].view(-1,1)) * (1-done).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(online_network, target_network, memory, optimizer, batch_size, gamma, local_steps, doubleDQN):\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "    \n",
    "    batch, indices, weights = memory.sample(batch_size, local_steps, device)\n",
    "\n",
    "    state, action, reward, next_state, done = zip(*batch)\n",
    "    \n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    action = torch.tensor(action, dtype=torch.long, device=device)\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "    reward = torch.tensor(reward, dtype=torch.float32, device=device)\n",
    "    done = torch.tensor(done, dtype=torch.float32, device=device)\n",
    "    \n",
    "    weights.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    q_val = compute_q_val(online_network, state, action)\n",
    "\n",
    "    with torch.no_grad():\n",
    "# Vanilla\n",
    "#         target = compute_target_dqn(q1, reward, next_state, done, gamma)\n",
    "        if doubleDQN:\n",
    "            target = compute_target_ddqn(online_network, target_network, reward, next_state, done, gamma)\n",
    "        else:\n",
    "            target = compute_target_dqn(target_network, reward, next_state, done, gamma)\n",
    "#     loss = F.mse_loss(q_val, target)\n",
    "    difference = (q_val - target.view(-1,1))\n",
    "    \n",
    "    # Weights is 1 for normal replay buffer so nothing changes\n",
    "    # McAleer divides the loss by the number of moves of the scramble here. Might not make sense in non-MCTS setting\n",
    "    loss = difference.pow(2) * weights\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Also taken from higgsfield\n",
    "    memory.update_priorities(indices, difference.detach().squeeze().abs().cpu().numpy().tolist())\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_capacity_keep_lr(network, capacity, optimizer, device):\n",
    "    # Store old ids\n",
    "    old_ids = [id(p) for p in network.parameters()]\n",
    "    old_param_sizes = [p.size() for p in network.parameters()]\n",
    "\n",
    "    network.increase_capacity(capacity)\n",
    "\n",
    "    # Store new ids\n",
    "    new_ids = [id(p) for p in network.parameters()]\n",
    "    new_param_sizes = [p.size() for p in network.parameters()]\n",
    "\n",
    "    # Store old state \n",
    "    opt_state_dict = optimizer.state_dict()\n",
    "    for old_id, new_id, new_param_size, old_param_size in zip(old_ids, new_ids, new_param_sizes, old_param_sizes):\n",
    "        # Store step, and exp_avgs\n",
    "        step = opt_state_dict['state'][old_id]['step']\n",
    "        old_exp_avg = opt_state_dict['state'][old_id]['exp_avg']\n",
    "        old_exp_avg_sq = opt_state_dict['state'][old_id]['exp_avg_sq']\n",
    "        old_max_exp_avg_sq = opt_state_dict['state'][old_id]['max_exp_avg_sq']\n",
    "\n",
    "        exp_avg = torch.zeros(new_param_size)\n",
    "        exp_avg_sq = torch.zeros(new_param_size)\n",
    "        max_exp_avg_sq =  torch.zeros(new_param_size)\n",
    "        # Extend exp_avgs to new shape depending on wether param is bias or weight\n",
    "        if exp_avg.dim()>1:\n",
    "            # Weights\n",
    "            exp_avg[0:old_param_size[0],0:old_param_size[1]] = old_exp_avg\n",
    "            exp_avg_sq[0:old_param_size[0],0:old_param_size[1]] = old_exp_avg_sq\n",
    "            max_exp_avg_sq[0:old_param_size[0],0:old_param_size[1]] = old_max_exp_avg_sq\n",
    "        else:\n",
    "            # Biases/last layer\n",
    "            exp_avg[0:old_param_size[0]] = old_exp_avg\n",
    "            exp_avg_sq[0:old_param_size[0]] = old_exp_avg_sq\n",
    "            max_exp_avg_sq[0:old_param_size[0]] = old_max_exp_avg_sq\n",
    "        \n",
    "        # Delete old id from state_dict and update new params and new id\n",
    "        del opt_state_dict['state'][old_id]\n",
    "        opt_state_dict['state'][new_id] = {\n",
    "            'step': step,\n",
    "            'exp_avg': exp_avg,\n",
    "            'exp_avg_sq': exp_avg_sq.to(device),\n",
    "            'max_exp_avg_sq' : max_exp_avg_sq.to(device)\n",
    "        }\n",
    "        opt_state_dict['param_groups'][0]['params'].remove(old_id)\n",
    "        opt_state_dict['param_groups'][0]['params'].append(new_id)\n",
    "\n",
    "    network.to(device)\n",
    "    optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "    optimizer.load_state_dict(opt_state_dict)\n",
    "    \n",
    "    return network, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_settings(architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, \n",
    "                        memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, \n",
    "                        threshold, evaluation_frequency, tau, curriculum, non_linearity,\n",
    "                        verbose=False, load_path=None, save_path=None, seed=None):\n",
    "    # If the directory does not exist, make one\n",
    "    if save_path:\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "    \n",
    "    # If a seed is set, set the seed for all sources of randomness\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "            \n",
    "    # Difficulty the problem starts with\n",
    "    difficulty = 0\n",
    "    # The maximum number of tries the agent gets at the start\n",
    "    max_tries_start = 1\n",
    "    max_tries = max_tries_start\n",
    "    # 3 is chosen because this allows the network to learn the difference between short and long paths from the beginning. Take for example a cube that has been scrambled as follows: U. The solution within 3 steps is eather U' (r=1) or U, U, U (r=-1)\n",
    "    \n",
    "    # Arrays to keep track of losses and accuracies over time\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Global steps keeps track of the total number of optimisation steps\n",
    "    global_steps = 0\n",
    "    # Local steps keeps track of number of optimisation steps within a level\n",
    "    local_steps = 0\n",
    "    # Total time keeps track of how long the training process takes\n",
    "    \n",
    "    # Epsilon exponential decay\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_final = 0.01\n",
    "    # Duration of decay dependent on difficulty\n",
    "#     epsilon_decay = 10000*(difficulty//12 + 1)\n",
    "    epsilon_decay = 1000\n",
    "    # Duration independent on dificulty\n",
    "    epsilon_by_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "    \n",
    "    # If a path with a model is provided certain variables are loaded\n",
    "    if load_path:\n",
    "        current_model = torch.load(load_path + 'model.pt')\n",
    "        target_model = copy.deepcopy(current_model)\n",
    "        max_tries = torch.load(load_path + 'max_tries')\n",
    "        epsilon_decay = torch.load(load_path + 'epsilon_decay')\n",
    "        global_steps = torch.load(load_path + 'global_steps')\n",
    "        local_steps = torch.load(load_path + 'local_steps')\n",
    "        difficulty = torch.load(load_path + 'difficulty')\n",
    "    else:\n",
    "        # n^2 per face, 6 faces, 6 colours one-hot encoded. 3x3x6x6=324, 2x2x6x6=144\n",
    "        state_size = env.size**2 * 6**2\n",
    "        \n",
    "        # The number of output nodes is different for the 2x2x2. The move L is the same as the move R, except the orientation changes.\n",
    "        output_nodes = 12\n",
    "        if env.size == 2:\n",
    "            output_nodes = 6\n",
    "        \n",
    "        # Initialising either a network with dueling architecture or regular network\n",
    "        if duelingDQN:\n",
    "            current_model = DuelingDQN(state_size, architecture, output_nodes, non_linearity)\n",
    "            target_model = DuelingDQN(state_size, copy.copy(architecture), output_nodes, non_linearity)\n",
    "        else:\n",
    "            current_model = DQN(state_size, architecture, output_nodes, non_linearity)\n",
    "            target_model = DQN(state_size, copy.copy(architecture), output_nodes, non_linearity)\n",
    "            \n",
    "    if torch.cuda.is_available():\n",
    "        current_model.to('cuda')\n",
    "        target_model.to('cuda')\n",
    "    else:\n",
    "        current_model.to('cpu')\n",
    "        target_model.to('cpu')\n",
    "    \n",
    "    # Uses prioritized replay sampling when set to true, otherwise uniform replay sampling is used\n",
    "    if prioritizedReplayMemory:\n",
    "        memory = PrioritizedReplayMemory(memoryCapacity, alpha)\n",
    "    else:\n",
    "        memory = ReplayMemory(memoryCapacity)\n",
    "    \n",
    "    # Initialise optimiser\n",
    "    optimizer = optim.Adam(current_model.parameters(), lr=lr, amsgrad=amsgrad)\n",
    "    \n",
    "    # This allows you to stop the training progress\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            # Different types of curricula decide what state to show the network next.\n",
    "            if curriculum is 'Naive':\n",
    "                state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Joe':\n",
    "                p = np.random.rand()\n",
    "                if p < 0.2:\n",
    "                    state = env.curriculum_reset(np.random.randint(1, difficulty + 12))\n",
    "                else:\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Sutskever':\n",
    "                p = np.random.rand()\n",
    "                if p < 0.2:\n",
    "                    state = env.reset(np.random.randint(1, 1000))\n",
    "                else:\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Mixed':\n",
    "                state = env.curriculum_reset(np.random.randint(1,1000))\n",
    "            else:\n",
    "                state = env.reset(1000)\n",
    "\n",
    "            done = 0\n",
    "            tries = 0\n",
    "            while tries < max_tries and not done:\n",
    "                \n",
    "                epsilon = epsilon_by_step(local_steps)\n",
    "                action = current_model.act(state, epsilon, [0]*env.action_space.n, device)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                memory.push((state, action, reward, next_state, done))\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                tries += 1\n",
    "            \n",
    "            loss = train_dqn(current_model, target_model, memory, optimizer, batch_size, gamma, local_steps, doubleDQN)\n",
    "\n",
    "            if loss:\n",
    "                epoch_losses.append(loss)\n",
    "                \n",
    "            global_steps += 1\n",
    "            local_steps += 1\n",
    "                \n",
    "            if global_steps % tau == 0:\n",
    "                target_model.load_state_dict(current_model.state_dict())\n",
    "                if save_path:\n",
    "                    torch.save(current_model, save_path + \"model.pt\")\n",
    "                    torch.save(max_tries, save_path + \"max_tries\")\n",
    "                    torch.save(epsilon_decay, save_path + \"epsilon_decay\")\n",
    "                    torch.save(global_steps, save_path + \"global_steps\")\n",
    "                    torch.save(local_steps, save_path + \"local_steps\")\n",
    "                    torch.save(local_steps, save_path + \"difficulty\")\n",
    "                    \n",
    "            if global_steps % evaluation_frequency == 0 and curriculum is not None:\n",
    "                total_done = 0\n",
    "                for i in range(difficulty + 1):\n",
    "                    # Here the agent is forced to evaluate its ability to solve certain last moves\n",
    "                    hashes = defaultdict(list)\n",
    "                    state = env.force_last_action_reset(i)\n",
    "                    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "                    done = 0\n",
    "                    tries = 0\n",
    "                    while tries < max_tries and not done:\n",
    "                        mask = hashes[hash(state.tostring())]\n",
    "                        action = current_model.act(state, 0, mask, device)\n",
    "                        next_state, reward, done, info = env.step(action)\n",
    "                        # memory.push((state, action, reward, next_state, done))\n",
    "                        hstate = state.copy()\n",
    "                        state = next_state\n",
    "                        \n",
    "                        h = hash(state.tostring())\n",
    "                        if h in hashes.keys():\n",
    "                            hashes[hash(hstate.tostring())][action] = -999\n",
    "                        else:\n",
    "                            hashes[h] = [0]*env.action_space.n\n",
    "                        \n",
    "                        total_done += done\n",
    "                        tries += 1\n",
    "                        \n",
    "                # Here the agent evaluates the ability to solve puzzles that have the last move from a set of moves with the same difficulty\n",
    "                for i in range(1000):\n",
    "                    hashes = defaultdict(list)\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "                    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "                    done = 0\n",
    "                    tries = 0\n",
    "                    while tries < max_tries and not done:\n",
    "                        mask = hashes[hash(state.tostring())]\n",
    "                        action = current_model.act(state, 0, mask, device)\n",
    "                        next_state, reward, done, info = env.step(action)\n",
    "                        # memory.push((state, action, reward, next_state, done))\n",
    "                        hstate = state.copy()\n",
    "                        state = next_state\n",
    "                        \n",
    "                        h = hash(state.tostring())\n",
    "                        if h in hashes.keys():\n",
    "                            hashes[hash(hstate.tostring())][action] = -999\n",
    "                        else:\n",
    "                            hashes[h] = [0]*env.action_space.n\n",
    "                            \n",
    "                        \n",
    "                        total_done += done\n",
    "                        tries += 1\n",
    "                \n",
    "                accuracy = total_done/(1000 + difficulty + 1)\n",
    "                accuracies.append(accuracy)\n",
    "                \n",
    "                if accuracy >= threshold:\n",
    "                    difficulty += 1\n",
    "                    max_tries = difficulty // output_nodes + max_tries_start\n",
    "                    local_steps = 0\n",
    "                    \n",
    "                    epsilon_start = 1.0\n",
    "                    epsilon_final = 0.01\n",
    "#                     epsilon_decay = 10000*(difficulty//output_nodes + 1)\n",
    "                    epsilon_decay = 1000\n",
    "\n",
    "                    epsilon_by_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "                \n",
    "                if local_steps > 1000:\n",
    "                    if capacity_increase:\n",
    "                        local_steps = 0\n",
    "                        capacity = [c(difficulty) for c in capacity_increase]\n",
    "\n",
    "                        current_model, optimizer = increase_capacity_keep_lr(current_model, capacity, optimizer, device)\n",
    "                        target_model.increase_capacity(capacity)\n",
    "\n",
    "                        target_model.to(device)\n",
    "\n",
    "                if verbose:\n",
    "                    clear_output(True)\n",
    "                    print(\"Epoch: \", epoch, \"Global steps: \", global_steps)\n",
    "                    print(\"Difficulty: \", difficulty, \"Max tries:\", max_tries)\n",
    "                    print(\"Memory: \", len(memory), \"epsilon: \", epsilon, \"local steps: \", local_steps)\n",
    "                    print(\"Accuracy: \", accuracy, \"Threshold: \", threshold)\n",
    "                    print(current_model)\n",
    "                    \n",
    "                losses.append(np.average(epoch_losses))\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if save_path:\n",
    "        torch.save(current_model, save_path + \"model.pt\")\n",
    "        torch.save(max_tries, save_path + \"max_tries\")\n",
    "        torch.save(epsilon_decay, save_path + \"epsilon_decay\")\n",
    "        torch.save(global_steps, save_path + \"global_steps\")\n",
    "        torch.save(local_steps, save_path + \"local_steps\")\n",
    "        torch.save(local_steps, save_path + \"difficulty\")\n",
    "            \n",
    "    return difficulty, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-55378b39e92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrubiks2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRubiksEnv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsolved_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m420\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_with_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduelingDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoubleDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprioritizedReplayMemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemoryCapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity_increase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurriculum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_linearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-ae2b71974dc5>\u001b[0m in \u001b[0;36mtrain_with_settings\u001b[0;34m(architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, threshold, evaluation_frequency, tau, curriculum, non_linearity, verbose, load_path, save_path, seed)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "epochs = 50000\n",
    "experiments = []\n",
    "# experiments.append([\"Baseline3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, False, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Naive', F.relu])\n",
    "# experiments.append([\"Mixed3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Mixed', F.relu])\n",
    "# experiments.append([\"Joe3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Joe', F.relu])\n",
    "# experiments.append([\"Sutskever3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.53\", [4096, 2048, 512], False, False, True, 0.5, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.73\", [4096, 2048, 512], False, False, True, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.93\", [4096, 2048, 512], False, False, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Dueling3\", [4096, 2048, 512], True, False, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Double3\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Linear_all3\", [64, 32, 8], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 6], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Elu3\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.elu])\n",
    "experiments.append([\"Increasing_all\", [8, 4, 1], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 8, lambda x: 4, lambda x: 1], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Increasing_all\", [64, 32, 8], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 6], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Increasing_bottom\", [64, 32, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 0], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Same\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 0, lambda x: 0, lambda x: 0], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "\n",
    "for experiment in experiments:\n",
    "    architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, threshold, evaluation_frequency, tau, curriculum, non_linearity = experiment[1:]\n",
    "\n",
    "    env = rubiks2.RubiksEnv2(2, unsolved_reward = -1.0, seed= 420)\n",
    "\n",
    "    train_with_settings(architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, threshold, evaluation_frequency, tau, curriculum, non_linearity, save_path='models/'+experiment[0]+'/', seed=420, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0 accuracy: 1.0\n",
      "1.0 1.0\n",
      "Level 1 accuracy: 1.0\n",
      "2.0 2.0\n",
      "Level 2 accuracy: 1.0\n",
      "3.0 3.0\n",
      "Level 3 accuracy: 0.9963768115942029\n",
      "4.3478260869565215 4.0\n",
      "Level 4 accuracy: 0.9927536231884058\n",
      "5.760869565217392 5.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-73563c79f7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperflip_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/Increasing_all/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperflip_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/Increasing_bottom/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperflip_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/Same/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-73563c79f7b0>\u001b[0m in \u001b[0;36msuperflip_test\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/Code/notebooks/Experiments/networks.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state, epsilon, mask, device)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/Code/notebooks/Experiments/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedLayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedLayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def superflip_test(model):\n",
    "    eval_model = torch.load(model)\n",
    "    eval_model.to(device)\n",
    "    \n",
    "    max_tries = 100\n",
    "    solve_rate_per_difficulty = []\n",
    "    average_tries_per_difficulty = []\n",
    "    \n",
    "    for i in range(14):\n",
    "        solved = 0\n",
    "        tries_solved = []\n",
    "        cycles = 0\n",
    "        start_states = defaultdict(list)\n",
    "        \n",
    "        for sequence in superflip_set:\n",
    "            env = rubiks2.RubiksEnv2(2, unsolved_reward=-1.0)\n",
    "            goal = env.get_observation()\n",
    "            \n",
    "            for j in range(i + 1):\n",
    "                env.step(sequence[j])\n",
    "\n",
    "            \n",
    "            hashes = defaultdict(list)\n",
    "            state = env.get_observation()\n",
    "            \n",
    "            # Remove duplicate starting states\n",
    "            if hash(state.tostring()) in start_states.keys():\n",
    "                continue\n",
    "                \n",
    "            hashes[hash(state.tostring())] = [0,0,0,0,0,0]\n",
    "            done = 0\n",
    "            tries = 0\n",
    "            \n",
    "            while not done and tries < max_tries:\n",
    "                mask = hashes[hash(state.tostring())]\n",
    "                \n",
    "                action = eval_model.act(state, 0, mask, device)\n",
    "\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "\n",
    "                hstate = state.copy()\n",
    "                state = next_state\n",
    "\n",
    "                tries += 1\n",
    "\n",
    "                h = hash(state.tostring())\n",
    "                if h in hashes.keys():\n",
    "                    #hashes[hash(hstate.tostring())][action] = -999\n",
    "                    cycles += 1\n",
    "                else:\n",
    "                    hashes[h] = [0,0,0,0,0,0]\n",
    "            if done:\n",
    "                solved += 1\n",
    "            tries_solved.append(tries)   \n",
    "            \n",
    "        solve_rate_per_difficulty.append(solved / len(superflip_set))\n",
    "        average_tries_per_difficulty.append(np.average(tries_solved))\n",
    "        print('Level', i, 'accuracy:', solved / len(superflip_set))\n",
    "        print(np.average(tries_solved), np.median(tries_solved))\n",
    "        \n",
    "    score = 0\n",
    "    for target_tries, avg_tries in enumerate(average_tries_per_difficulty):\n",
    "        score += ((target_tries + 1)/avg_tries)*solve_rate_per_difficulty[target_tries]\n",
    "    score /= 14\n",
    "    return solve_rate_per_difficulty, average_tries_per_difficulty, score\n",
    "    \n",
    "\n",
    "print(superflip_test('./models/Increasing_all/model.pt'))\n",
    "print(superflip_test('./models/Increasing_bottom/model.pt'))\n",
    "print(superflip_test('./models/Same/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "tensor([-7.3568, -9.4022, -8.8316, -7.7485, -8.9987, -7.7962], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", 'D', \"B'\", 'D', \"B'\", 'R', 'B', 'D']\n",
      "tensor([ -9.7809, -11.0316, -10.1009, -11.2816, -11.7569, -10.7492],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "[\"R'\", \"D'\", 'R', 'R', 'B', \"R'\", 'B', 'D']\n",
      "tensor([-6.7750, -6.5081, -7.9337, -8.0642, -7.7045, -8.0909], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', \"R'\", 'D', \"B'\", \"D'\", 'R', 'R', 'D']\n",
      "tensor([-5.8753, -4.8949, -7.0861, -5.7633, -4.4354, -5.9509], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', \"R'\", \"R'\", \"B'\", 'D', \"R'\", 'D', 'D']\n",
      "tensor([-6.8149, -7.7838, -8.8054, -6.9508, -8.9753, -8.8836], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", 'R', \"B'\", 'D', 'B', \"R'\", 'D', 'D']\n",
      "tensor([-7.0395, -8.9979, -8.0240, -4.7824, -9.1378, -8.5070], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', \"D'\", \"B'\", 'D', 'B', 'B', 'D', 'D']\n",
      "tensor([-4.1759, -2.6119, -4.4617, -5.2466, -2.9511, -4.7424], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'R', 'R', 'D', \"B'\", 'D', \"R'\", 'D']\n",
      "tensor([-8.0888, -8.5073, -9.4262, -7.9236, -8.2029, -9.8269], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", 'B', \"D'\", \"B'\", \"B'\", \"R'\", \"B'\", 'D']\n",
      "tensor([-4.6893, -4.6379, -4.6108, -5.4387, -4.9964, -3.0652], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"D'\", 'R', 'D', 'B', \"R'\", 'D', 'D']\n",
      "tensor([-4.5832, -5.0026, -4.1352, -5.9386, -3.9104, -5.2332], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'B', 'R', \"B'\", 'D', \"R'\", 'D', 'D']\n",
      "tensor([-6.6131, -7.6047, -7.7922, -5.7649, -7.6478, -7.4232], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"D'\", \"R'\", \"R'\", 'B', 'R', \"B'\", 'D']\n",
      "tensor([-7.8098, -7.4307, -8.4870, -9.4159, -7.7662, -8.9589], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", 'R', \"B'\", 'D', 'R', 'B', \"R'\", 'D']\n",
      "tensor([-8.8466, -8.5996, -9.3156, -8.5040, -8.7126, -8.1822], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'R', 'R', 'D', \"R'\", 'D', 'B', 'D']\n",
      "tensor([-5.2135, -7.2488, -6.4590, -5.9032, -6.2845, -7.0931], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"R'\", \"D'\", 'B', \"D'\", 'B', 'B', 'D']\n",
      "tensor([-2.3134, -0.6442, -2.5691, -2.5100, -2.1781, -2.1809], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'B', \"R'\", \"B'\", 'D', \"R'\", 'B', 'D']\n",
      "tensor([-6.8329, -7.9385, -6.5497, -7.8552, -7.6275, -6.2891], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", \"D'\", 'R', \"B'\", \"B'\", \"D'\", 'R', 'D']\n",
      "tensor([ -9.1126, -10.3662,  -9.2873,  -7.5558, -10.5131,  -9.7106],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "['D', 'B', 'D', \"B'\", \"R'\", 'B', \"R'\", 'D']\n",
      "tensor([-5.8572, -7.1335, -6.2090, -6.8934, -7.2224, -3.6644], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'B', 'R', 'D', 'D', 'B', \"R'\", 'D']\n",
      "tensor([-5.3880, -6.1672, -5.9393, -7.3848, -4.8624, -6.8692], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"D'\", 'B', \"D'\", \"R'\", \"B'\", 'R', 'D']\n",
      "tensor([-5.3804, -5.6713, -6.7284, -4.3162, -6.5154, -6.9040], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'R', 'D', 'R', 'R', \"B'\", \"R'\", 'D']\n",
      "tensor([-3.2617, -3.9275, -3.9479, -1.4945, -3.8215, -3.3607], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", 'R', \"D'\", 'B', 'B', 'D', \"B'\", 'D']\n",
      "tensor([-5.7088, -7.1655, -7.3507, -6.5171, -7.3392, -6.9307], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'R', 'R', 'B', \"R'\", \"B'\", 'R', 'D']\n",
      "tensor([-8.0278, -7.3749, -5.9554, -8.1256, -8.2077, -7.4327], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', \"R'\", 'B', \"D'\", \"R'\", \"D'\", 'R', 'D']\n",
      "tensor([-6.2548, -6.9113, -8.3036, -5.0237, -7.7610, -7.2571], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"D'\", \"B'\", 'D', \"B'\", 'R', 'B', 'D']\n",
      "tensor([-8.5160, -9.8178, -8.7882, -9.3067, -9.9983, -9.5257], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', 'B', \"R'\", 'D', \"R'\", 'B', 'B', 'D']\n",
      "tensor([-5.1278, -8.0157, -4.9520, -7.0684, -6.5108, -7.3233], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", \"B'\", 'D', \"R'\", 'B', \"D'\", \"R'\", 'D']\n",
      "tensor([-6.1160, -7.3126, -7.5879, -6.5041, -6.9561, -7.0432], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"B'\", \"R'\", 'D', \"R'\", \"B'\", 'R', 'D']\n",
      "tensor([-4.9970, -5.7039, -5.9828, -6.1999, -5.0359, -6.1386], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", \"D'\", 'R', \"D'\", \"R'\", 'B', 'B', 'D']\n",
      "tensor([-5.5910, -7.3826, -7.3968, -6.5426, -7.3320, -7.3518], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", \"R'\", 'D', \"R'\", 'D', 'B', \"R'\", 'D']\n",
      "tensor([-6.0503, -7.2897, -5.8974, -6.5784, -6.4724, -6.4853], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", \"B'\", \"D'\", 'B', 'B', 'R', 'B', 'D']\n",
      "tensor([-6.2491, -6.3903, -7.2924, -5.3690, -7.1150, -6.9406], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"B'\", 'R', 'R', 'D', 'D', \"B'\", 'D']\n",
      "tensor([-4.5998, -5.2452, -5.5031, -6.0850, -5.0560, -5.4563], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', 'B', \"R'\", 'B', \"R'\", \"D'\", \"R'\", 'D']\n",
      "tensor([-8.6778, -8.8549, -8.4340, -9.3986, -8.4299, -8.9281], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", 'R', 'R', 'B', \"D'\", \"B'\", \"B'\", 'D']\n",
      "tensor([-4.8642, -6.4681, -6.9464, -3.0944, -5.2331, -6.0562], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'R', \"B'\", 'R', 'B', \"R'\", \"D'\", 'D']\n",
      "tensor([-5.5024, -4.1778, -5.2568, -5.8563, -4.8812, -5.5857], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', \"R'\", 'B', 'R', 'B', 'D', 'B', 'D']\n",
      "tensor([-6.6797, -6.9218, -7.4491, -5.7648, -6.8911, -6.8069], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', \"B'\", \"D'\", 'R', \"B'\", \"R'\", \"B'\", 'D']\n",
      "tensor([-7.4100, -6.9728, -7.7569, -7.0256, -7.1068, -7.7533], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'D', \"R'\", \"R'\", 'D', 'R', \"B'\", 'D']\n",
      "tensor([-8.2719, -8.2878, -7.5893, -8.2201, -7.9690, -9.3748], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', \"D'\", 'B', \"R'\", \"B'\", \"D'\", \"D'\", 'D']\n",
      "tensor([-6.2600, -7.4076, -6.4505, -6.4446, -7.7478, -7.0202], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", \"R'\", \"B'\", \"R'\", 'B', \"R'\", 'B', 'D']\n",
      "tensor([-7.5960, -7.2547, -6.2169, -8.6473, -7.7175, -7.7613], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"D'\", \"R'\", \"R'\", \"B'\", 'R', \"B'\", 'D']\n",
      "tensor([-7.9662, -7.5241, -8.2322, -7.5846, -7.9620, -7.9392], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", \"D'\", 'R', 'B', 'B', \"D'\", 'B', 'D']\n",
      "tensor([-5.8987, -5.7110, -5.0144, -5.8378, -5.9419, -4.9976], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"R'\", 'D', 'R', \"B'\", \"D'\", 'B', 'D']\n",
      "tensor([-6.7317, -7.7671, -7.2315, -6.8663, -7.6473, -7.3294], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'B', \"R'\", \"B'\", 'D', 'R', 'B', 'D']\n",
      "tensor([-2.7282, -2.8121, -0.7827, -2.8456, -2.7552, -2.4693], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", 'D', \"B'\", 'R', \"D'\", 'B', 'B', 'D']\n",
      "tensor([-8.0173, -8.1775, -7.9323, -7.7281, -8.5644, -7.8636], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'D', \"B'\", 'D', 'D', 'R', 'B', 'D']\n",
      "tensor([-5.2324, -5.4870, -6.5368, -6.6346, -3.3766, -6.9629], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', \"R'\", \"D'\", \"D'\", 'R', 'D', \"B'\", 'D']\n",
      "tensor([-8.0581, -7.2798, -7.9111, -7.8027, -6.8243, -6.7179], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", 'D', \"B'\", \"D'\", 'R', 'R', 'B', 'D']\n",
      "tensor([-6.2624, -6.5129, -6.7340, -7.6938, -7.1912, -5.9032], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", \"B'\", 'R', \"D'\", \"B'\", \"B'\", \"R'\", 'D']\n",
      "tensor([-8.8057, -9.6019, -8.6201, -9.1112, -9.3774, -8.8834], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", 'R', 'R', 'B', 'B', \"D'\", 'R', 'D']\n",
      "tensor([-8.6581, -9.0273, -7.4977, -8.4067, -8.7753, -9.2273], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"D'\", 'R', \"B'\", \"B'\", \"D'\", \"R'\", 'D']\n",
      "tensor([-8.7014, -9.9196, -8.7959, -8.3111, -9.4352, -9.2917], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"D'\", \"B'\", \"B'\", \"R'\", \"D'\", \"D'\", 'R', 'D']\n",
      "tensor([-8.1474, -9.8256, -7.8091, -6.5673, -9.5617, -8.6143], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'D', 'D', \"R'\", 'D', 'B', 'D', 'D']\n",
      "tensor([-7.7007, -8.1728, -7.6475, -7.6570, -8.1943, -7.9744], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['D', 'D', 'R', \"D'\", 'R', 'B', \"D'\", 'D']\n",
      "tensor([-7.5778, -7.8917, -7.3697, -5.8029, -8.2616, -8.0771], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', \"B'\", 'D', 'B', \"D'\", 'R', 'B', 'D']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7481, -7.2982, -8.0371, -8.0079, -6.7984, -6.8344], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', 'D', \"B'\", \"D'\", 'B', \"D'\", 'R', 'D']\n",
      "tensor([-6.9977, -7.6895, -6.9198, -6.0075, -8.1446, -6.5995], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['B', 'R', 'R', 'D', \"B'\", \"R'\", 'B', 'D']\n",
      "tensor([-9.3027, -9.4558, -9.0998, -9.6976, -9.5360, -9.2569], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"B'\", \"R'\", 'B', \"D'\", 'R', \"B'\", \"R'\", 'D']\n",
      "tensor([-6.0932, -6.6710, -7.3958, -7.4678, -4.6837, -7.0992], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "[\"R'\", 'B', 'D', \"B'\", \"R'\", 'D', \"B'\", 'D']\n",
      "tensor([-6.4813, -7.6940, -7.1144, -4.9877, -7.4467, -6.8550], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "['R', 'D', 'D', \"R'\", 'B', 'D', \"R'\", 'D']\n",
      "941\n",
      "0.9424736337488016\n",
      "0.9424736337488016\n"
     ]
    }
   ],
   "source": [
    "env = rubiks2.RubiksEnv2(2, unsolved_reward = -1.0, seed= 42)\n",
    "\n",
    "# Which tests are failing?\n",
    "difficulty = 42\n",
    "max_tries = 16\n",
    "current_model = torch.load('./models/Same/model.pt')\n",
    "current_model.to(device)\n",
    "\n",
    "total = 0\n",
    "total_done = 0\n",
    "for i in range(difficulty + 1):\n",
    "    # Here the agent is forced to evaluate its ability to solve certain last moves\n",
    "    hashes = defaultdict(list)\n",
    "    state = env.force_last_action_reset(i)\n",
    "    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "    done = 0\n",
    "    tries = 0\n",
    "    while tries < max_tries and not done:\n",
    "        mask = hashes[hash(state.tostring())]\n",
    "        action = current_model.act(state, 0, mask, device)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        hstate = state.copy()\n",
    "        state = next_state\n",
    "\n",
    "        h = hash(state.tostring())\n",
    "        if h in hashes.keys():\n",
    "            hashes[hash(hstate.tostring())][action] = -999\n",
    "        else:\n",
    "            hashes[h] = [0]*env.action_space.n\n",
    "\n",
    "        total_done += done\n",
    "        tries += 1\n",
    "    total += 1\n",
    "print(total_done)\n",
    "total_done_2 = 0\n",
    "# Here the agent evaluates the ability to solve puzzles that have the last move from a set of moves with the same difficulty\n",
    "for i in range(1000):\n",
    "    hashes = defaultdict(list)\n",
    "    state = env.curriculum_reset(difficulty)\n",
    "    \n",
    "    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "    done = 0\n",
    "    tries = 0\n",
    "    while tries < max_tries and not done:\n",
    "        mask = hashes[hash(state.tostring())]\n",
    "        action = current_model.act(state, 0, mask, device)\n",
    "        q_val = current_model(torch.tensor(state, dtype=torch.float, device=device))\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        hstate = state.copy()\n",
    "        state = next_state\n",
    "\n",
    "        h = hash(state.tostring())\n",
    "        if h in hashes.keys():\n",
    "            hashes[hash(hstate.tostring())][action] = -999\n",
    "        else:\n",
    "            hashes[h] = [0]*env.action_space.n\n",
    "\n",
    "\n",
    "        total_done += done\n",
    "        total_done_2 += done\n",
    "        tries += 1\n",
    "\n",
    "    total+=1\n",
    "    \n",
    "    if not done:\n",
    "        print(q_val\n",
    "             )\n",
    "        print([env.ACTION_MEANING_QUARTER_METRIC[scr] for scr in env.last_scramble])\n",
    "\n",
    "print(total_done_2)\n",
    "print(total_done/total)\n",
    "accuracy = total_done/(1000 + difficulty + 1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "superflip_set = [[4,0,5,1,5,4,5,5,1,3,2,1,3,3],\n",
    "[0,5,1,1,0,0,1,5,0,2,2,4,4,5],\n",
    "[1,2,2,3,3,5,0,4,0,2,4,3,5,0],\n",
    "[1,0,5,0,4,3,3,1,3,1,0,2,3,2],\n",
    "[5,0,5,1,5,1,5,1,5,1,5,3,1,5],\n",
    "[3,5,3,2,4,2,4,5,1,0,4,3,5,0],\n",
    "[2,4,2,0,0,2,4,5,3,1,0,0,4,4],\n",
    "[5,0,5,4,3,2,3,4,3,2,4,2,2,1],\n",
    "[2,0,4,0,4,0,4,0,4,5,3,5,4,5],\n",
    "[2,4,2,4,3,2,2,1,3,5,4,4,2,3],\n",
    "[4,4,0,4,0,5,4,5,0,0,1,3,1,2],\n",
    "[0,4,0,5,1,1,0,2,2,3,2,3,5,5],\n",
    "[0,1,0,4,2,4,2,4,0,2,4,5,4,3],\n",
    "[2,3,2,2,1,5,1,5,3,5,1,5,5,4],\n",
    "[4,0,5,4,0,4,3,2,3,5,1,0,5,0],\n",
    "[2,3,1,2,1,5,3,2,3,1,2,1,2,2],\n",
    "[5,4,0,5,3,1,2,4,2,1,5,1,0,2],\n",
    "[2,4,0,1,3,4,0,0,2,2,4,0,5,4],\n",
    "[5,1,2,3,4,3,5,3,2,4,2,0,2,0],\n",
    "[1,2,0,4,2,3,1,3,1,0,4,5,0,1],\n",
    "[4,2,1,5,0,2,3,5,4,2,3,1,5,3],\n",
    "[2,3,4,5,1,5,0,4,2,3,1,2,1,3],\n",
    "[0,5,1,3,2,4,0,0,4,0,4,0,5,0],\n",
    "[5,1,2,3,5,1,3,4,2,4,5,5,0,2],\n",
    "[0,4,3,5,1,0,5,0,2,3,4,4,3,1],\n",
    "[3,3,4,2,4,5,1,3,3,5,0,2,0,0],\n",
    "[5,3,1,3,5,1,0,0,1,0,1,5,4,4],\n",
    "[2,0,1,5,1,3,1,2,4,3,2,4,0,2],\n",
    "[1,0,4,3,5,3,5,1,5,0,4,3,2,1],\n",
    "[3,1,0,2,2,0,5,3,1,3,4,5,1,3],\n",
    "[1,3,5,4,0,2,2,3,1,3,4,0,2,3],\n",
    "[5,3,1,1,3,2,1,5,0,5,1,1,2,3],\n",
    "[4,3,2,1,3,5,1,5,4,4,2,4,3,4],\n",
    "[4,4,3,5,0,5,5,3,1,3,2,4,5,1],\n",
    "[4,4,5,0,5,3,2,1,1,3,1,0,1,1],\n",
    "[5,1,2,3,2,1,2,3,3,4,3,2,4,4],\n",
    "[3,3,1,2,4,0,4,2,4,3,3,4,2,2],\n",
    "[3,5,0,5,5,3,1,3,2,3,2,1,5,4],\n",
    "[3,4,2,2,4,5,1,5,0,5,1,2,4,5],\n",
    "[4,2,4,2,2,1,0,4,0,1,2,4,5,4],\n",
    "[4,0,4,0,5,1,2,1,3,2,1,0,5,3],\n",
    "[1,2,2,3,3,4,0,2,1,0,4,0,5,0],\n",
    "[2,3,3,5,1,3,2,3,1,5,4,4,2,2],\n",
    "[1,2,2,4,2,4,0,4,3,3,5,5,4,0],\n",
    "[4,0,4,4,5,4,4,2,4,0,5,5,0,4],\n",
    "[5,1,3,2,1,3,2,1,2,1,0,5,4,3],\n",
    "[4,4,2,0,1,1,5,3,1,3,2,0,4,5],\n",
    "[0,1,5,3,2,1,5,3,2,4,0,2,4,2],\n",
    "[1,3,2,3,5,0,1,5,0,1,3,4,0,0],\n",
    "[1,2,1,3,1,5,1,3,1,5,4,3,5,5],\n",
    "[3,1,3,4,2,3,4,3,4,4,0,2,3,1],\n",
    "[5,1,2,2,1,5,0,5,5,3,5,5,1,3],\n",
    "[5,3,2,4,0,5,4,3,2,4,5,3,2,3],\n",
    "[1,2,1,3,2,4,0,4,2,0,1,2,3,5],\n",
    "[3,5,5,3,5,0,5,4,2,2,4,2,3,2],\n",
    "[4,5,1,5,4,2,1,1,3,5,1,2,3,2],\n",
    "[3,5,1,3,3,1,2,3,2,3,1,2,4,2],\n",
    "[2,0,1,3,2,3,1,3,2,4,5,0,4,4],\n",
    "[1,2,4,2,0,0,4,3,1,3,2,2,0,0],\n",
    "[2,3,3,5,4,0,4,0,4,5,4,5,4,0],\n",
    "[2,1,3,2,2,3,1,3,2,0,4,3,3,2],\n",
    "[4,4,5,4,2,2,4,0,5,0,1,3,2,3],\n",
    "[3,2,4,4,3,5,0,4,0,4,5,5,1,0],\n",
    "[3,4,2,4,2,4,2,4,0,2,0,2,0,1],\n",
    "[4,5,3,4,0,4,5,0,1,3,1,2,1,2],\n",
    "[3,5,5,1,3,2,4,3,3,4,3,2,1,1],\n",
    "[3,4,4,3,1,2,3,1,5,0,5,4,5,0],\n",
    "[0,2,0,1,1,5,0,1,3,1,3,5,1,5],\n",
    "[3,1,5,1,2,0,5,3,1,5,5,4,2,4],\n",
    "[2,4,4,5,3,1,3,5,1,2,4,3,3,4],\n",
    "[3,1,3,4,3,5,1,5,0,5,4,4,0,4],\n",
    "[2,3,1,5,3,1,5,1,2,1,5,5,1,2],\n",
    "[3,3,4,0,1,5,3,2,3,3,2,3,1,3],\n",
    "[1,5,3,1,2,0,2,0,4,0,5,3,5,4],\n",
    "[0,1,1,5,0,4,5,0,2,4,5,1,5,4],\n",
    "[3,2,4,2,1,5,0,0,1,2,4,5,4,0],\n",
    "[0,4,0,5,0,4,2,4,2,2,4,2,3,2],\n",
    "[5,0,5,5,4,3,5,1,5,1,5,3,1,5],\n",
    "[0,5,4,5,0,4,0,4,0,1,5,3,3,2],\n",
    "[5,5,3,2,3,1,0,1,5,1,1,3,5,5],\n",
    "[0,5,1,0,5,3,3,5,1,2,0,5,5,4],\n",
    "[0,4,5,5,1,5,0,5,3,1,5,4,3,1],\n",
    "[5,1,0,4,2,2,0,1,2,2,1,5,1,1],\n",
    "[4,4,0,2,3,1,5,1,3,4,4,3,1,1],\n",
    "[0,5,1,5,1,2,2,0,0,1,1,2,4,2],\n",
    "[2,0,2,2,3,1,0,4,0,2,2,3,1,2],\n",
    "[4,0,2,3,1,5,3,1,5,0,2,4,0,4],\n",
    "[1,3,5,4,0,2,4,2,4,3,5,4,4,0],\n",
    "[5,4,3,5,1,5,1,1,2,4,2,0,4,3],\n",
    "[1,5,4,0,5,4,3,1,2,3,4,4,5,3],\n",
    "[0,2,3,2,0,2,3,1,3,1,5,1,0,0],\n",
    "[5,4,3,2,3,2,0,5,0,4,4,2,0,2],\n",
    "[2,1,5,1,2,4,4,0,2,1,2,4,3,3],\n",
    "[2,3,2,2,1,0,1,3,5,1,2,1,1,2],\n",
    "[5,0,4,3,1,3,4,0,1,5,1,0,1,3],\n",
    "[5,5,0,0,2,4,2,1,5,0,4,3,4,4],\n",
    "[1,0,5,0,1,2,4,5,1,3,5,0,2,3],\n",
    "[4,4,2,0,5,1,5,0,5,1,1,5,3,3],\n",
    "[0,2,4,5,5,4,5,3,1,3,3,2,3,1],\n",
    "[4,0,5,5,1,3,5,1,3,1,3,5,0,4],\n",
    "[0,2,2,4,2,4,3,2,2,3,3,1,0,2],\n",
    "[5,1,3,1,2,0,4,2,2,0,4,4,3,1],\n",
    "[1,2,1,1,0,5,0,5,1,2,0,5,3,5],\n",
    "[3,1,5,1,0,4,3,1,0,2,4,5,5,0],\n",
    "[5,5,1,0,4,2,3,2,4,5,5,1,2,2],\n",
    "[2,3,2,3,1,5,0,1,2,3,3,5,1,3],\n",
    "[4,2,4,4,0,4,5,0,5,0,4,3,1,3],\n",
    "[1,3,1,3,4,0,2,2,0,1,0,4,2,2],\n",
    "[3,1,5,1,5,0,4,3,4,5,5,1,3,1],\n",
    "[5,4,0,1,5,0,2,4,0,5,1,1,2,3],\n",
    "[2,1,0,4,5,0,4,2,3,2,4,2,1,0],\n",
    "[0,4,2,1,3,2,4,0,2,1,5,5,3,1],\n",
    "[0,5,3,4,4,3,2,0,5,0,4,5,4,3],\n",
    "[2,3,2,3,5,0,1,5,4,5,0,5,5,4],\n",
    "[4,0,5,5,0,2,0,4,2,0,4,5,0,4],\n",
    "[4,0,4,5,1,5,0,1,2,3,2,1,1,3],\n",
    "[3,4,4,2,1,5,1,3,2,4,4,5,1,1],\n",
    "[0,5,3,3,2,0,2,4,0,4,0,5,1,2],\n",
    "[2,1,5,1,3,1,0,5,0,2,2,3,3,1],\n",
    "[0,4,5,5,0,4,3,1,3,2,3,2,1,3],\n",
    "[1,0,0,5,0,5,1,3,3,1,2,3,2,2],\n",
    "[4,5,1,3,4,2,0,5,4,2,3,5,5,1],\n",
    "[3,2,1,5,3,2,3,4,5,4,4,2,1,3],\n",
    "[3,5,5,1,3,5,3,2,2,1,3,5,1,2],\n",
    "[3,4,2,1,1,2,3,4,3,5,3,5,5,1],\n",
    "[0,4,0,5,0,4,3,2,3,1,1,0,2,1],\n",
    "[2,1,5,0,4,3,4,2,3,3,1,0,0,1],\n",
    "[4,4,3,2,4,2,0,2,0,0,5,0,5,4],\n",
    "[2,0,4,0,4,5,4,2,0,0,2,4,5,0],\n",
    "[1,2,3,1,3,2,4,4,5,3,4,3,5,0],\n",
    "[4,2,3,5,3,2,3,5,3,1,2,3,5,0],\n",
    "[3,4,0,4,2,3,1,0,5,4,4,0,2,2],\n",
    "[4,2,2,4,0,2,3,1,5,1,1,0,4,4],\n",
    "[1,2,0,2,0,4,0,5,3,1,3,4,0,4],\n",
    "[0,1,3,1,1,5,0,1,3,2,4,4,0,5],\n",
    "[2,3,1,3,1,2,3,4,4,2,4,4,3,1],\n",
    "[4,0,5,5,4,5,1,5,0,4,5,3,1,0],\n",
    "[2,4,2,3,2,0,5,4,4,0,5,5,4,0],\n",
    "[5,3,1,5,0,2,1,3,4,2,1,5,1,3],\n",
    "[4,4,0,5,1,3,1,2,1,5,0,1,0,5],\n",
    "[5,1,1,5,1,2,3,1,3,5,5,1,0,0],\n",
    "[1,5,3,2,3,5,0,1,2,2,1,5,1,3],\n",
    "[5,4,0,0,2,1,0,4,2,3,1,3,1,2],\n",
    "[0,1,1,0,4,3,5,0,4,5,3,1,5,3],\n",
    "[5,4,2,4,2,3,2,1,0,0,4,5,0,0],\n",
    "[4,0,5,0,5,0,2,0,4,3,2,3,4,5],\n",
    "[2,0,5,0,4,4,5,4,2,4,0,0,4,4],\n",
    "[0,4,2,3,1,3,4,0,2,2,4,2,2,0],\n",
    "[2,3,4,5,0,1,2,3,2,1,3,5,3,3],\n",
    "[4,2,3,4,3,1,1,3,4,3,4,2,0,4],\n",
    "[0,4,3,2,4,5,5,1,3,2,1,3,5,5],\n",
    "[5,1,0,1,0,5,1,5,4,2,2,4,3,4],\n",
    "[5,5,4,5,4,0,1,5,3,2,1,3,4,4],\n",
    "[4,4,0,5,3,1,5,0,1,3,3,4,2,4],\n",
    "[5,3,2,1,5,1,3,4,5,0,4,4,5,5],\n",
    "[5,0,5,0,5,1,5,5,0,4,3,4,0,2],\n",
    "[0,2,3,4,5,1,5,1,1,3,2,0,4,0],\n",
    "[5,3,2,3,5,0,1,5,4,2,4,3,3,2],\n",
    "[2,4,4,0,4,0,4,2,3,1,2,0,4,5],\n",
    "[5,5,1,3,5,4,3,2,1,5,4,2,3,4],\n",
    "[5,5,4,2,3,1,5,1,2,0,4,3,4,5],\n",
    "[4,2,3,5,3,2,3,5,3,1,2,3,5,3],\n",
    "[1,3,2,4,5,3,3,1,0,2,3,1,0,2],\n",
    "[3,2,4,4,0,5,3,2,0,2,2,1,1,3],\n",
    "[1,0,4,2,1,3,2,2,3,4,5,1,5,5],\n",
    "[3,1,0,4,2,2,4,3,4,0,4,2,2,4],\n",
    "[2,3,1,2,2,4,2,1,5,0,5,1,5,3],\n",
    "[1,5,0,5,3,4,5,4,2,3,5,1,3,2],\n",
    "[0,4,0,4,0,4,5,0,4,5,0,1,2,2],\n",
    "[3,2,4,4,3,4,2,4,5,1,0,0,5,5],\n",
    "[1,3,4,4,5,1,3,5,0,4,2,3,5,3],\n",
    "[3,3,1,5,1,5,1,2,1,3,5,0,5,3],\n",
    "[3,1,0,4,2,3,2,0,2,4,4,3,2,4],\n",
    "[4,2,3,1,1,2,0,2,2,3,1,3,1,5],\n",
    "[5,3,1,5,1,5,3,4,4,2,4,5,4,2],\n",
    "[5,1,2,3,1,1,2,0,5,5,0,5,1,1],\n",
    "[2,4,0,1,3,1,3,2,0,1,1,0,2,2],\n",
    "[4,0,5,5,0,2,2,1,0,1,0,4,5,5],\n",
    "[3,2,1,5,0,5,0,1,5,1,2,0,4,0],\n",
    "[2,4,2,3,5,0,2,2,1,5,3,2,3,1],\n",
    "[3,3,5,1,2,3,3,5,1,3,4,2,2,3],\n",
    "[5,1,3,4,3,5,3,1,2,4,4,0,2,4],\n",
    "[4,4,3,4,5,0,2,3,2,3,4,2,1,2],\n",
    "[2,3,3,2,3,3,1,5,4,5,0,4,0,1],\n",
    "[4,2,3,1,3,5,4,0,1,3,4,2,1,1],\n",
    "[5,0,2,4,5,3,3,1,3,5,4,0,1,1],\n",
    "[3,4,0,1,5,0,0,1,2,4,0,4,4,3],\n",
    "[2,3,5,4,2,4,0,2,0,5,1,1,5,5],\n",
    "[4,2,3,5,1,3,2,1,5,4,3,1,5,3],\n",
    "[5,1,3,5,4,2,3,4,5,1,2,3,4,0],\n",
    "[5,5,3,2,3,4,0,4,3,1,0,5,4,5],\n",
    "[3,5,0,4,3,5,5,1,3,2,0,2,4,2],\n",
    "[3,1,2,0,5,1,0,2,3,5,1,0,4,5],\n",
    "[2,0,5,3,3,5,1,3,4,2,3,5,3,4],\n",
    "[1,0,5,1,2,3,1,1,2,4,4,2,2,0],\n",
    "[1,5,1,5,1,3,5,0,4,3,1,5,4,2],\n",
    "[0,1,3,3,2,3,4,5,1,5,1,0,0,4],\n",
    "[1,3,4,0,5,3,2,0,1,3,2,4,0,2],\n",
    "[3,2,3,2,2,1,2,1,3,1,3,1,2,4],\n",
    "[4,2,4,0,2,0,4,3,5,0,4,0,4,5],\n",
    "[3,1,2,2,4,0,4,2,3,1,0,1,5,1],\n",
    "[0,1,1,5,1,3,1,5,4,3,1,5,3,3],\n",
    "[3,3,2,2,3,1,2,0,4,2,3,4,3,1],\n",
    "[4,4,0,4,3,1,2,1,5,5,4,2,0,2],\n",
    "[2,4,0,0,1,2,4,2,3,1,2,4,4,3],\n",
    "[3,1,0,4,2,2,4,3,4,0,5,5,0,5],\n",
    "[5,3,1,1,0,5,1,2,1,0,2,2,1,2],\n",
    "[5,3,4,0,4,3,3,5,1,2,3,2,4,3],\n",
    "[2,3,5,1,3,3,5,4,2,2,4,2,0,0],\n",
    "[0,5,1,3,2,3,2,4,3,1,1,2,3,4],\n",
    "[4,2,4,4,3,5,0,4,3,2,3,3,1,1],\n",
    "[2,4,0,0,4,3,3,5,3,5,4,0,5,5],\n",
    "[2,3,2,2,1,5,4,2,3,4,5,3,2,4],\n",
    "[2,1,3,1,1,0,4,2,3,1,2,0,5,1],\n",
    "[0,5,0,5,1,3,2,4,5,4,2,1,3,5],\n",
    "[5,1,0,4,3,2,4,2,4,5,5,3,2,4],\n",
    "[5,0,4,0,4,5,0,2,0,4,0,5,0,1],\n",
    "[2,3,2,4,3,1,5,4,2,3,5,0,4,2],\n",
    "[1,5,0,5,1,2,3,2,4,0,0,4,3,4],\n",
    "[2,3,4,0,2,2,1,3,2,4,2,4,2,4],\n",
    "[2,0,1,5,0,0,4,2,4,3,2,0,0,1],\n",
    "[5,5,3,1,3,3,5,0,2,3,2,4,0,4],\n",
    "[0,2,2,4,2,3,2,4,4,2,1,3,4,4],\n",
    "[2,0,4,2,2,1,3,2,3,2,4,3,1,0],\n",
    "[3,1,2,3,5,1,5,5,3,3,1,0,4,0],\n",
    "[3,5,0,1,1,3,2,3,1,5,0,2,0,4],\n",
    "[4,5,1,3,2,2,1,1,3,1,5,0,5,3],\n",
    "[5,0,4,2,3,2,4,3,2,3,5,0,5,4],\n",
    "[3,2,1,2,4,2,1,2,4,4,0,2,4,3],\n",
    "[3,5,5,4,4,2,3,2,0,5,4,4,5,0],\n",
    "[1,0,2,4,2,0,0,5,0,5,1,0,4,2],\n",
    "[4,2,4,3,2,4,2,1,0,5,1,2,2,3],\n",
    "[2,1,0,0,5,0,1,3,2,3,1,1,2,0],\n",
    "[4,2,2,1,2,4,2,3,2,0,2,1,2,4],\n",
    "[2,3,5,4,4,0,1,2,1,5,0,0,1,1],\n",
    "[5,5,1,0,2,3,1,5,5,4,0,5,3,4],\n",
    "[3,1,5,4,2,3,2,0,2,4,0,0,4,0],\n",
    "[3,2,3,4,0,1,3,4,5,0,1,1,5,1],\n",
    "[5,3,1,2,0,4,0,2,4,2,0,1,2,2],\n",
    "[2,4,3,4,2,4,0,4,2,3,1,0,1,5],\n",
    "[3,3,1,2,2,1,0,5,1,3,1,0,5,0],\n",
    "[4,2,1,5,0,4,4,2,2,0,5,3,2,4],\n",
    "[0,5,1,2,2,1,0,1,3,5,0,4,0,1],\n",
    "[2,4,5,4,0,1,1,5,3,1,3,2,3,2],\n",
    "[5,0,4,0,4,5,4,2,1,0,4,0,4,4],\n",
    "[4,4,5,4,2,2,0,1,3,1,3,5,1,2],\n",
    "[2,1,3,5,0,2,3,4,5,1,3,4,5,1],\n",
    "[0,2,3,5,5,3,1,3,4,0,5,3,5,4],\n",
    "[4,3,1,3,2,4,0,4,2,4,5,0,1,1],\n",
    "[0,5,3,4,4,2,4,2,3,5,1,1,0,1],\n",
    "[3,4,4,2,4,0,1,0,0,1,0,0,2,1],\n",
    "[4,3,2,1,5,3,1,5,3,5,3,4,0,1],\n",
    "[2,4,2,3,1,0,2,3,3,4,3,4,5,1],\n",
    "[2,4,2,0,1,5,1,3,5,1,2,3,3,5],\n",
    "[3,4,0,4,4,0,4,2,0,1,1,0,5,5],\n",
    "[5,5,1,0,5,0,4,3,1,3,2,2,3,3],\n",
    "[3,1,5,3,1,5,1,3,5,1,5,1,1,2],\n",
    "[4,2,3,1,5,5,0,5,0,2,1,5,1,1],\n",
    "[5,4,2,1,5,0,4,0,5,4,5,5,4,5],\n",
    "[0,5,4,2,0,4,2,1,2,0,0,5,4,2],\n",
    "[5,0,0,2,2,1,5,4,2,4,4,3,3,4],\n",
    "[3,1,0,5,1,5,4,2,4,5,4,3,5,1],\n",
    "[4,4,5,0,4,5,3,3,5,1,0,4,2,1],\n",
    "[4,2,3,4,0,2,4,2,2,4,0,5,4,4],\n",
    "[2,4,5,4,0,1,5,1,5,3,5,0,0,1],\n",
    "[3,4,2,4,0,1,2,4,4,3,1,0,1,2],\n",
    "[5,1,2,2,3,5,0,5,4,0,5,5,4,4],\n",
    "[3,2,3,1,2,2,4,5,3,3,1,3,1,5],\n",
    "[3,4,3,2,4,0,4,0,1,2,1,5,0,5],\n",
    "[1,5,4,3,1,5,3,2,0,5,0,2,3,1],\n",
    "[4,5,1,3,5,0,4,2,3,2,0,2,4,4],\n",
    "[1,3,2,4,0,2,3,5,4,2,3,2,4,4],\n",
    "[2,0,1,1,5,0,2,3,2,4,2,2,0,2],\n",
    "[3,1,5,0,4,2,4,2,1,0,4,2,1,1],\n",
    "[3,4,2,4,0,5,3,1,1,3,1,2,4,2],\n",
    "[4,4,5,3,5,1,2,3,1,2,2,4,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_zero():\n",
    "    return random.uniform(0, 49) / 100\n",
    "\n",
    "def generate_one():\n",
    "    return random.uniform(50, 100) / 100\n",
    "\n",
    "def generate_or_XY(num_data_points):\n",
    "    Xs, Ys = [], []\n",
    "    for _ in range(num_data_points):\n",
    "        # or(0, 0) -> 0 \n",
    "        Xs.append([generate_zero(), generate_zero(), 0]); Ys.append([0])\n",
    "        # or(1, 0) -> 1\n",
    "        Xs.append([generate_one(), generate_zero(), 0]); Ys.append([1])\n",
    "        # or(0, 1) -> 1\n",
    "        Xs.append([generate_zero(), generate_one(), 0]); Ys.append([1])\n",
    "        # or(1, 1) -> 1\n",
    "        Xs.append([generate_one(), generate_one(), 0]); Ys.append([1])\n",
    "    return Xs, Ys\n",
    "\n",
    "def generate_xor_XY(num_data_points):\n",
    "    Xs, Ys = [], []\n",
    "    for _ in range(num_data_points):\n",
    "        # xor(0, 0) -> 0 \n",
    "        Xs.append([generate_zero(), generate_zero(), 1]); Ys.append([0])\n",
    "        # xor(1, 0) -> 1\n",
    "        Xs.append([generate_one(), generate_zero(), 1]); Ys.append([1])\n",
    "        # xor(0, 1) -> 1\n",
    "        Xs.append([generate_zero(), generate_one(), 1]); Ys.append([1])\n",
    "        # xor(1, 1) -> 0\n",
    "        Xs.append([generate_one(), generate_one(), 1]); Ys.append([0])\n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] False None\n",
      "Average loss or:  0.2145835181325674\n",
      "Average loss xor:  0.26149887539446354\n",
      "Average loss:  0.23804119676351548\n",
      "[0.1142050065100193, 0.11750936508178711, 0.1109006479382515, 34, [2], False, None]\n",
      "[2] True None\n",
      "Average loss or:  0.12206357872113585\n",
      "Average loss xor:  0.2634724254906178\n",
      "Average loss:  0.1927680021058768\n",
      "[0.08547905832529068, 0.06775370985269547, 0.1032044067978859, 47, [2], True, None]\n",
      "[1] True [1]\n",
      "Average loss or:  0.14868648225441575\n",
      "Average loss xor:  0.24071325831115245\n",
      "Average loss:  0.1946998702827841\n",
      "[0.13807303085923195, 0.19308896362781525, 0.08305709809064865, 20, [1], True, [1]]\n",
      "[3] False None\n",
      "Average loss or:  0.17304493337869645\n",
      "Average loss xor:  0.2532721669226885\n",
      "Average loss:  0.21315855015069246\n",
      "[0.08304987102746964, 0.07354926317930222, 0.09255047887563705, 58, [3], False, None]\n",
      "[3] True None\n",
      "Average loss or:  0.1070100861415267\n",
      "Average loss xor:  0.2559949965029955\n",
      "Average loss:  0.1815025413222611\n",
      "[0.07776246219873428, 0.08126479387283325, 0.07426013052463531, 18, [3], True, None]\n",
      "[2] True [1]\n",
      "Average loss or:  0.10625703405588866\n",
      "Average loss xor:  0.2392973667755723\n",
      "Average loss:  0.17277720041573047\n",
      "[0.06813515536487103, 0.0901181772351265, 0.046152133494615555, 77, [2], True, [1]]\n",
      "[1] True [2]\n",
      "Average loss or:  0.1216855302080512\n",
      "Average loss xor:  0.20801823608577252\n",
      "Average loss:  0.16485188314691185\n",
      "[0.08390745520591736, 0.11114208400249481, 0.056672826409339905, 2, [1], True, [2]]\n",
      "[4] False None\n",
      "Average loss or:  0.15207272563129665\n",
      "Average loss xor:  0.2292224531620741\n",
      "Average loss:  0.19064758939668536\n",
      "[0.08991589024662971, 0.1253119558095932, 0.05451982468366623, 11, [4], False, None]\n",
      "[4] True None\n",
      "Average loss or:  0.0857677673920989\n",
      "Average loss xor:  0.22685763873159887\n",
      "Average loss:  0.15631270306184888\n",
      "[0.05411256663501263, 0.0603606142103672, 0.04786451905965805, 68, [4], True, None]\n",
      "[1] True [3]\n",
      "Average loss or:  0.11002877146005631\n",
      "Average loss xor:  0.1845066687092185\n",
      "Average loss:  0.1472677200846374\n",
      "[0.03247866965830326, 0.04649897664785385, 0.01845836266875267, 99, [1], True, [3]]\n",
      "[2] True [2]\n",
      "Average loss or:  0.09650766547769309\n",
      "Average loss xor:  0.210948678702116\n",
      "Average loss:  0.15372817208990455\n",
      "[0.10247533954679966, 0.16782040894031525, 0.03713027015328407, 46, [2], True, [2]]\n",
      "[3] True [1]\n",
      "Average loss or:  0.09397246841341257\n",
      "Average loss xor:  0.22913689523935318\n",
      "Average loss:  0.16155468182638288\n",
      "[0.08134296536445618, 0.09858688712120056, 0.06409904360771179, 87, [3], True, [1]]\n"
     ]
    }
   ],
   "source": [
    "def xor_experiments(initial_capacity, train_or, capacity):\n",
    "    lowest_loss = 99\n",
    "    lowest_settings = []    \n",
    "    losses_xor = []\n",
    "    losses_or = []\n",
    "    for seed in range(100):\n",
    "        # Set seeds\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialisation network\n",
    "        network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "        # optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "        optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        if train_or:\n",
    "            for i in range(1000):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.rand() < 0.2:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        Xs, Ys = generate_or_XY(1)\n",
    "                    else:\n",
    "                        Xs, Ys = generate_xor_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "                    \n",
    "                Xs = torch.tensor(Xs)\n",
    "                Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "                prediction = network(Xs)\n",
    "                loss = criterion(prediction, Ys)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Evaluation\n",
    "                    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "                    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "                    loss = criterion(prediction, Ys)\n",
    "\n",
    "                if loss<0.05:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        if capacity is not None:\n",
    "            network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "        \n",
    "        \n",
    "        iters = 1000\n",
    "        if not train_or:\n",
    "            iters * 2\n",
    "            \n",
    "        for i in range(iters):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Uniform syllabus 20% of the time\n",
    "            if np.random.rand() < 0.2:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "            else:\n",
    "                Xs, Ys = generate_xor_XY(1)\n",
    "                \n",
    "            Xs = torch.tensor(Xs)\n",
    "            Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "            prediction = network(Xs)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Test or\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "        \n",
    "        average_loss += loss.item()\n",
    "        losses_or.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test xor\n",
    "            prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "        \n",
    "        average_loss += loss.item()\n",
    "        average_loss /= 2\n",
    "        losses_xor.append(loss.item())\n",
    "        \n",
    "        if losses_xor[-1] < lowest_loss:\n",
    "            lowest_loss = losses_xor[-1]\n",
    "            lowest_settings = [average_loss, losses_or[-1], losses_xor[-1], seed, initial_capacity, train_or, capacity]\n",
    "        \n",
    "        \n",
    "    # Print statistics\n",
    "    print(initial_capacity, train_or, capacity)\n",
    "    print('Average loss or: ', np.average(losses_or))\n",
    "    print('Average loss xor: ', np.average(losses_xor))\n",
    "    print('Average loss: ', (np.average(losses_or) +  np.average(losses_xor))/2)\n",
    "    print(lowest_settings)\n",
    "    \n",
    "xor_experiments([2],False, None)\n",
    "xor_experiments([2], True, None)\n",
    "xor_experiments([1], True, [1])\n",
    "\n",
    "xor_experiments([3],False,None)\n",
    "xor_experiments([3], True, None)\n",
    "xor_experiments([2], True, [1])\n",
    "xor_experiments([1], True, [2])\n",
    "\n",
    "xor_experiments([4],False,None)\n",
    "xor_experiments([4], True, None)\n",
    "xor_experiments([1], True, [3])\n",
    "xor_experiments([2], True, [2])\n",
    "xor_experiments([3], True, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capacity = [4]\n",
    "capacity = None\n",
    "train_or = True\n",
    "# Set seeds\n",
    "random.seed(99)\n",
    "np.random.seed(99)\n",
    "torch.manual_seed(99)\n",
    "\n",
    "# Initialisation network\n",
    "network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "# optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if train_or:\n",
    "    for i in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if np.random.rand() < 0.2:\n",
    "            if np.random.rand() < 0.5:\n",
    "                Xs, Ys = generate_or_XY(1)\n",
    "            else:\n",
    "                Xs, Ys = generate_xor_XY(1)\n",
    "        else:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "\n",
    "        Xs = torch.tensor(Xs)\n",
    "        Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "        prediction = network(Xs)\n",
    "        loss = criterion(prediction, Ys)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Evaluation\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        if loss<0.05:\n",
    "            break\n",
    "\n",
    "\n",
    "    nw_before = copy.deepcopy(network) \n",
    "if capacity is not None:\n",
    "    network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "\n",
    "nw_after_increase = copy.deepcopy(network)\n",
    "\n",
    "iters = 1000\n",
    "if not train_or:\n",
    "    iters * 2\n",
    "\n",
    "for i in range(iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Uniform syllabus 20% of the time\n",
    "    if np.random.rand() < 0.2:\n",
    "        if np.random.rand() < 0.5:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "        else:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "    else:\n",
    "        Xs, Ys = generate_xor_XY(1)\n",
    "\n",
    "    Xs = torch.tensor(Xs)\n",
    "    Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "    prediction = network(Xs)\n",
    "    loss = criterion(prediction, Ys)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test or\n",
    "    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "    loss = criterion(prediction, Ys)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test xor\n",
    "    prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "    Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "    loss = criterion(prediction, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6879]], grad_fn=<AddmmBackward>)\n",
      "Weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31834152 0.         0.09608161 0.17247939]]\n",
      "Weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAD8CAYAAADjcbh8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEjFJREFUeJzt3XGMZWV5x/HvDyiGohRwFRAQbMW2aJHiippYlQiKNgGtFm1tQQs1lGpr1LRGEk0kTZdSK22sTcnWiI2JpVTUVBQRazERFFREqdZdNCgIUliDAa3CzNM/zpn1sjsz907vzJm5734/yQn3nnvunWc3y2/ec9573idVhSS1aK/1LkCS1ooBJ6lZBpykZhlwkpplwElqlgEnqVmDB1ySg5NcnWRb/9+Dljn2gCS3J3n3kDXuUsPYepMcn+S6JLckuTnJKwau8dQk/51ke5K3LPL6I5L8S//655McPWR9i9Qzrt43Jvmv/u/ymiRHrUedfS3L1jpy3MuSVJLNQ9an5a3HCO4twDVVdQxwTf98KRcA1w5S1dImqfdHwJlV9WTgVODiJAcOUVySvYG/B14EHAv8TpJjdznsbOAHVfVE4F3AhUPUtpgJ6/0ysLmqjgMuB/5q2Co7E9ZKkkcBfwp8ftgKNc56BNzpwKX940uBlyx2UJKnAYcAnxyorqWMrbeqvllV2/rH3wPuBh4zUH0nAtur6ltV9VPgg3Q1jxr9M1wOPD9JBqpvV2Prrar/qKof9U+vB44YuMYFk/zdQveL+ELgf4csTuOtR8AdUlV39o/voguxh0myF/BO4M1DFraEsfWOSnIisC9w61oX1jsc+O7I89v7fYseU1UPAfcBjx6kut1NUu+os4GPr2lFSxtba5ITgCOr6mNDFqbJ7LMWH5rkU8Chi7x0/uiTqqoki90rdh5wZVXdPsRAYxXqXficw4B/Bs6qqvnVrXLPk+T3gM3Ac9e7lsX0v4j/Bnj1OpeiJaxJwFXVyUu9luT7SQ6rqjv7QLh7kcOeBfxGkvOARwL7Jrm/qpa7Xree9ZLkAOBjwPlVdf1a1LmEO4AjR54f0e9b7Jjbk+wD/AJw7zDl7WaSeklyMt0vmOdW1U8Gqm1X42p9FPAU4DP9L+JDgY8mOa2qbhysSi1pPU5RPwqc1T8+C/jIrgdU1auq6vFVdTTdaer71yrcJjC23iT7AlfQ1Xn5gLUB3AAck+QJfR2vpKt51Oif4eXAp2v9VlkYW2+SXwf+ETitqhb9hTKQZWutqvuqalNVHd3/W72ermbDbYNYj4DbApySZBtwcv+cJJuTbF2HesaZpN4zgOcAr05yU78dP0Rx/TW11wFXAV8HLquqW5K8I8lp/WH/BDw6yXbgjSw/c72mJqz3IrqR+7/2f5e7BvZGqlUbWFwuSVKrvJNBUrMMOEnNMuAkNcuAk9QsA05Ss9Y94JK8dr1rWIlZqneWaoXZqneWat2TrXvAAbP2D2WW6p2lWmG26p2lWvdYGyHgJGlNrOiLvns/cv/a5+CDV7WAufsfYO9H7r+qn7mWZqneWaoVZqvetar1oR07mLv/galWmHjhSfvXvTvmJjr2izf/5KqqOnWan7eRrehm+30OPpjHvekNa1WLtMf73jsvnvoz7tkxx+evmmwJvZ877NZNU//ADWxNVhORtJ6KOVfrAgw4qTkFzOM95mDASU2axxEcGHBSc4riQU9RAQNOak4Bc56iAgac1CSvwXUMOKkxBcy5kC1gwElN8gpcx4CTGlOU1+B6BpzUmCp40HwDDDipQWGOtW+YPgsMOKkxBcw7ggMMOKlJjuA6BpzUmO6LvgYcuOCl1JwCHqy9JtqmkeTgJFcn2db/96AljjurP2ZbkrNG9j8tyVeTbE/yd0nS778gyc1JbkryySSP6/cflOSK/rUvJHnKuBoNOKkxRZhjr4m2Kb0FuKaqjgGu6Z8/TJKDgbcDzwBOBN4+EoT/APwhcEy/LSy8eVFVHVdVxwP/Dryt3/9W4KaqOg44E/jbcQUacFKD5isTbVM6Hbi0f3wp8JJFjnkhcHVV7aiqHwBXA6cmOQw4oKqur25Z8fcvvL+qfjjy/v1h55f6jgU+3R/zDeDoJIcsV6DX4KTGDHgN7pCqurN/fBewWNgcDnx35Pnt/b7D+8e77gcgyV/QjdLuA07qd38F+C3gs0lOBI4CjgC+v1SBjuCk5oS52muiDdiU5MaR7WHdwpJ8KsnXFtlOHz2uH4Wt2pdTqur8qjoS+ADwun73FuDAJDcBrwe+DCzbfMIRnNSYbkXficcu91TV5iU/q+rkpV5L8v0kh1XVnf0p592LHHYH8LyR50cAn+n3H7HL/jsWef8HgCuBt/enrq/pf3aAbwPfWqo+cAQnNacq/LT2nmib0keBhVnRs4CPLHLMVcAL+hnQg4AXAFf1p7Y/TPLMPqzOXHh/kmNG3n868I1+/4FJ9u33nwNcu8v1ut04gpMaND/MNbgtwGVJzgZuA84ASLIZOLeqzqmqHUkuAG7o3/OOqtrRPz4PeB+wH/DxfgPYkuSX6RZFuQ04t9//q8ClSQq4BTh7XIEGnNSYbpJh7U/Oqupe4PmL7L+RboS18Py9wHuXOG6377JV1cuW+HnXAU9aSY0GnNScLEwg7PEMOKkxK5xkaJoBJzVobvov8TbBgJMaU4QHy/+1wYCTmjPUJMMsMOCkxhTxFLVnwEkNcpKhY8BJjanCr4n0DDipMd0kw9S3YTXBgJMa5CRDx4CTGlOsymKWTTDgpAY5gusYcFJjur6oBhwYcFKD7Gy/wICTGtO1DXQWFQw4qTlV8RS159+C1KAVNJ35f1urxs8jr78pSSXZ1D9Pf9z2vvnzCeNqNOCkxnTrwWWibUpr1fiZJEfS9W/4zsjHvWjk2Nf271+WASc1Z0VtA6exJo2fe+8C/oyHtyI8HXh/da6nayF42HIFeg1Oakz3NZHZbfzc91y9o6q+sstZ61KfdSdLMOCkxqzwXtRNSW4ceX5JVV2y8CTJp4BDF3nf+Q/7mVXVd7uaSpKfB95Kd3o6NQNOatAMN37+JeAJwMLo7QjgS0lO7F8/cpH3LMlrcFJjuuWSMtE2pVVv/FxVX62qx1bV0VV1NN1p6AlVdVf/887sZ1OfCdw3coq8KEdwUoMGuga3Vo2fl3Il8GJgO/Aj4DXjCjTgpMZ0q4nMbuPnXY45euRxAX+8khoNOKkx3a1aXn0CA05qkLdqLTDgpAatwl0KTTDgpMYszKLKgJOa5Clqx4CTGmNPhp8x4KTGFPCQIzjAgJOa5Clqx4CTWlOeoi4w4KTGLCx4KQNOapIjuI4BJzVmwAUvNzwDTmpMER6ad5IBDDipSV6D6xhwUmvKU9QFBpzUGK/B/YwBJzXIgOt4JVJqTBHm5veaaJvGOnS2/5Uk1yX5SZI3T1KjASc1qNHO9juAPwH+etICDTipMdVPMkyyTWnQzvZVdXdV3QA8OGmBXoOTGlRtdrZfMQNOas6KRmd2tpc0W1YwgpuZzvZ98+cV8Rqc1JgqmJvPRNuUhu5sv2KO4KQGDXSr1qCd7ZMcCtwIHADMJ3kDcGxV/XCp9xhwUmOKYSYZ1qGz/V08/LR2LANOao4r+i4w4KQG1dTzmW0w4KQGDfQ9uA3PgJMa082i+gUJMOCkJnmK2jHgpAZ5itox4KTGFDHgegac1CDPUDsGnNSagpr+NqwmGHBSgzxF7RhwUoOcRe0YcFJjhroXdRYYcFJrCjDgAANOapKnqB0DTmpOnEXtGXBSixzBAQac1J5ykmGBSw5ILaoJtymsQ2f7VyW5uX/P55I8dVyNBpzUpEy4TWXozvbfBp5bVb8GXABcwhgGnNSi+Qm36Qzd2f5z/WcAXM8E/Rm8Bie1ZmXfg1u28fMY69nZ/mzGdOECA05q0gq+B7ds4+eN2Nk+yUl0AffscZ9nwEktWqWviWy0zvZJjgO2Ai/q2xYuy2twUosqk23TGbSzfZLHAx8Cfr+qvjlJgQac1KDUZNuUtgCnJNkGnNw/J8nmJFsB+i72C53tb2D3zvZbge3ArYy/pvY24NHAe5LctMu1w0V5iiq1pgID3Kq1Dp3tzxn93EkYcFKLvFULMOCkNhlwgAEntcmAAww4qT0ueLmTASc1aBVmSJtgwEktMuAAA05qkiO4jgEntchrcIABJ7VnFRazbIUBJ7XIgAMMOKlJmX4xyyYYcFKLHMEBBpzUnFVaKaQJBpzUImdRAQNOapMjOMCAk5rkKWrHFX2l1lQ3izrJNo11aPx8et/4+aYkNyYZ23TGgJNaNEBne4Zv/HwN8NSqOh74A7rlzpdlwEktGibghm78fH9/LMD+k/wJvAYnNWiga3CDN35O8lLgL4HHAr85rkADTtqzLdvZfqM1fq6qK4ArkjyHrlvXkn1bwYCT2rRKne03WuPnkbquTfKLSTZV1T1L1eg1OKk1A82iMnzj5ycuzLQmOQF4BLBsd3tHcFKLhrkGtwW4LMnZwG3AGdA1fgbOrapzqmpHkoXGz7B74+f3AfvRNX0e1/j5ZcCZSR4Efgy8YmTSYVEGnNSYMMwkwzo0fr4QuHAlNRpwUou8kwEw4KT2uJrITgac1CIXvAQMOKlJjuA6BpzUIgMOMOCk9thVaycDTmqQp6gdA05qkQEHGHBSk2wb2DHgpNZ4DW4nA05qTPpNBpzUJkdwgAEnNclZ1I4BJ7XIgAMMOKk95SzqAgNOapEjOMCAk5rkNbiOPRmkFg3QF3XozvYj+5+e5KEkLx9XowEnNSg12TaloTvbk2RvumXLPzlJgQac1JqiW/Bykm06g3a2770e+DcWb1G4G6/BSY0ZqukMA3e2T3I48FLgJODpkxRowEktmjzgZqmz/cXAn1fV/C6X65ZkwEkNyvLtQkfNTGd7YDPwwX7/JuDFSR6qqg8vVaPX4KTWTDqDOv1p7KCd7avqCSP7LwfOWy7cwICTmjTQLOoW4JQk24CT++ck2ZxkK0DfxX6hs/0N7N7ZfiuwHbiV8Z3tV8xTVKlBQ9yqNXRn+132v3qSGg04qUXeyQAYcFJ77Gy/kwEntciAAww4qTkDftF3wzPgpAZl3oQDA05qj121djLgpAa5om/HgJNa5AgOMOCkJjnJ0DHgpNYUMPnN9k0z4KQGeQ2uY8BJjfF7cD9jwEmtqfIUtWfASQ1yBNcx4KQWGXCAASc1yRFcxxV9pdYUMFeTbVMYuvFzkucluS/JTf32tnE1GnBSg1pt/Ax8tqqO77d3jCvQgJNatDCTOm6bzno0fl4RA05q0EAjuDVv/LzI5z0ryVeSfDzJk8cV6CSD1JqVLZc0S42fvwQcVVX3J3kx8GG6U9slGXBSYwJk8gmEmWn8XFV3jdR1ZZL3JNlUVfcsVaOnqFKDUjXRNqVBGz8nOXRhprXvdL8XcO9yBTqCk1oz3Iq+W4DLkpwN3AacAV3jZ+DcqjqnqnYkWWj8DLs3fn4fsB9d0+dxjZ9fDvxRkoeAHwOv7CcolmTASc0Z5l7UoRs/V9W7gXevpEYDTmqQdzJ0DDipRa4mAhhwUntqRbOoTTPgpBaZb4ABJzVpFb4C0gQDTmqRAQcYcFJ7CrDpDGDASc0Jq3KXQhMMOKlF8w7hwICT2uMp6k4GnNQgT1E7BpzUIgMOMOCkBtn4eYEBJ7VmoauWDDipRV6D6xhwUosMOMCAk9pTwLwBB/ZkkBo0YU/UKUd5Q3e27/c9r+9qf0uS/xxXowEntWiYxs+DdrZPciDwHuC0qnoy8NvjCjTgpNYUMDc/2TadoTvb/y7woar6DkBVLdam8GEMOKk5BTU/2TadoTvbPwk4KMlnknwxyZnjCnSSQWrR5Kefs9TZfh/gaXSdvPYDrktyfVV9c6nPM+Ck1qxsFnVmOtvTjfLuraoHgAeSXAs8FVgy4DxFlVo0zCTDoJ3t+89/dpJ9+pHeM4CvL1egASe1aJiA2wKckmQbcHL/nCSbk2ztyqgdwEJn+xvYvbP9VmA7cCtjOttX1deBTwA3A18AtlbV15Z7j6eoUmuqYG5ugB8zbGf7/vlFwEWT1mjASS3yVi3AgJPaZMABBpzUoPJe1J4BJ7WmoKb/Em8TDDipRdPfhtUEA05qTZVtA3sGnNQiJxkAA05qUjmCAww4qUF21VpgwEmtccnynQw4qTEF1AC3as0CA05qTdVqLGbZBANOalB5igpAagUXI5P8D3DbKtewCbhnlT9zLc1SvbNUK8xWvWtV61FV9ZhpPiDJJ+jqm8Q9VXXq+MNm04oCbk0KSG5cbkXRjWaW6p2lWmG26p2lWvdkLngpqVkGnKRmbYSAu2T8IRvKLNU7S7XCbNU7S7Xusdb9GpwkrZWNMIKTpDVhwElqlgEnqVkGnKRmGXCSmvV/XnVk4rWYoLwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising specific weights, biases, and activations\n",
    "from matplotlib import colors\n",
    "\n",
    "def show_mat_label(data, data2=None):\n",
    "    data_list = []\n",
    "    if data2 is not None:\n",
    "        vmin = data.min()\n",
    "        vmax = data.max()\n",
    "\n",
    "        fig, axs = plt.subplots(3,1)\n",
    "        data_list.append(axs[0].matshow(data))\n",
    "\n",
    "        vmin = min(vmin,data2.min())\n",
    "        vmax = max(vmax,data2.max())\n",
    "        \n",
    "        data_list.append(axs[1].matshow(data2))\n",
    "        axs[1].get_xaxis().set_visible(False)\n",
    "\n",
    "        vmin = min(vmin,np.abs(data-data2).min())\n",
    "        vmax = max(vmax,np.abs(data-data2).max())\n",
    "        data_list.append(axs[2].matshow(np.abs(data-data2)))\n",
    "        axs[2].get_xaxis().set_visible(False)\n",
    "        \n",
    "        norm = colors.Normalize(vmin=0, vmax=1)\n",
    "        \n",
    "        fig.colorbar(data_list[0], ax=axs)\n",
    "        \n",
    "        for d in data_list:\n",
    "            d.set_norm(norm)\n",
    "    else:\n",
    "        fig, axs = plt.subplots()\n",
    "        cax = axs.matshow(data)\n",
    "        if data.shape[0]==1:\n",
    "            axs.get_yaxis().set_visible(False)\n",
    "        fig.colorbar(cax)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "x = torch.tensor([[0,0,1]],dtype=torch.float)\n",
    "\n",
    "weights0 = network.layers[0].weight.data.numpy()\n",
    "bias0 = np.array([network.layers[0].bias.data.numpy()])\n",
    "\n",
    "weights1 = network.layers[1].weight.data.numpy()\n",
    "bias1 = np.array([network.layers[1].bias.data.numpy()])\n",
    "\n",
    "x = torch.tensor([[1,1,0]],dtype=torch.float)\n",
    "print(network(x))\n",
    "x2 = torch.tensor([[1,1,1]],dtype=torch.float)\n",
    "print(network(x2))\n",
    "\n",
    "print('Weights')\n",
    "show_mat_label(weights0)\n",
    "print('Bias')\n",
    "show_mat_label(bias0)\n",
    "print('Activations')\n",
    "show_mat_label(F.relu(network.layers[0](x)).data.numpy(),F.relu(network.layers[0](x2)).data.numpy())\n",
    "print(np.abs(F.relu(network.layers[0](x)).data.numpy()-F.relu(network.layers[0](x2)).data.numpy()))\n",
    "\n",
    "x = F.relu(network.layers[0](x))\n",
    "x2 = F.relu(network.layers[0](x2))\n",
    "\n",
    "print('Weights')\n",
    "show_mat_label(weights1)\n",
    "print('Bias')\n",
    "show_mat_label(bias1)\n",
    "print('Activations')\n",
    "\n",
    "show_mat_label(network.layers[1](x).data.numpy(),network.layers[1](x2).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change(initial_capacity, capacity, train_or):\n",
    "    common = []\n",
    "    new = []\n",
    "    total = []\n",
    "    common_bias = []\n",
    "    new_bias = []\n",
    "\n",
    "    for seed in range(100):  \n",
    "        # Set seeds\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialisation network\n",
    "        network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "        # optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "        optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if train_or:\n",
    "            for i in range(1000):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.rand() < 0.2:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        Xs, Ys = generate_or_XY(1)\n",
    "                    else:\n",
    "                        Xs, Ys = generate_xor_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "\n",
    "                Xs = torch.tensor(Xs)\n",
    "                Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "                prediction = network(Xs)\n",
    "                loss = criterion(prediction, Ys)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Evaluation\n",
    "                    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "                    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "                    loss = criterion(prediction, Ys)\n",
    "\n",
    "                if loss<0.05:\n",
    "                    break\n",
    "\n",
    "\n",
    "            nw_before = copy.deepcopy(network) \n",
    "        if capacity is not None:\n",
    "            network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "\n",
    "        nw_after_increase = copy.deepcopy(network)\n",
    "\n",
    "        iters = 1000\n",
    "        if not train_or:\n",
    "            iters * 2\n",
    "\n",
    "        for i in range(iters):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Uniform syllabus 20% of the time\n",
    "            if np.random.rand() < 0.2:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "            else:\n",
    "                Xs, Ys = generate_xor_XY(1)\n",
    "\n",
    "            Xs = torch.tensor(Xs)\n",
    "            Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "            prediction = network(Xs)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test or\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test xor\n",
    "            prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        common.append([torch.abs(nw_after_increase.layers[0].weight[0]-network.layers[0].weight[0]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][0]-network.layers[1].weight[0][0]).mean().data.numpy()])\n",
    "        new.append([torch.abs(nw_after_increase.layers[0].weight[1:]-network.layers[0].weight[1:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][1:]-network.layers[1].weight[0][1:]).mean().data.numpy()])\n",
    "        total.append([torch.abs(nw_after_increase.layers[0].weight[:]-network.layers[0].weight[:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][:]-network.layers[1].weight[0][:]).mean().data.numpy()])\n",
    "        \n",
    "        common_bias.append([torch.abs(nw_after_increase.layers[0].bias[0]-network.layers[0].bias[0]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].bias[0]-network.layers[1].bias[0]).mean().data.numpy()])\n",
    "        new_bias.append([torch.abs(nw_after_increase.layers[0].bias[1:]-network.layers[0].bias[1:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].bias[0]-network.layers[1].bias[0]).mean().data.numpy()])\n",
    "        \n",
    "    print(\"Common layer 0:\\t\", np.average(np.array(common)[:,0]))\n",
    "    print(\"New layer 0:\\t\", np.average(np.array(new)[:,0]))\n",
    "    print(\"Total layer 0:\\t\", np.average(np.array(total)[:,0]))\n",
    "    print(\"Common bias 0:\\t\", np.average(np.array(common_bias)[:,0]))\n",
    "    print(\"New bias 0:\\t\", np.average(np.array(new_bias)[:,0]))\n",
    "    \n",
    "    print(\"Common layer 1:\\t\", np.average(np.array(common)[:,1]))\n",
    "    print(\"New layer 1:\\t\", np.average(np.array(new)[:,1]))\n",
    "    print(\"Total layer 1:\\t\", np.average(np.array(total)[:,1]))\n",
    "    print(\"Common bias 1:\\t\", np.average(np.array(common_bias)[:,1]))\n",
    "    print(\"New bias 1:\\t\", np.average(np.array(new_bias)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-496-98b4062f53cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcapacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_or\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mweight_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_capacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_or\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minitial_capacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-495-1ed4b587f53a>\u001b[0m in \u001b[0;36mweight_change\u001b[0;34m(initial_capacity, capacity, train_or)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_capacity = [4]\n",
    "capacity = None\n",
    "train_or = True\n",
    "weight_change(initial_capacity, capacity, train_or)\n",
    "print('----')\n",
    "initial_capacity = [1]\n",
    "capacity = [3]\n",
    "train_or = True\n",
    "weight_change(initial_capacity, capacity, train_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.2,0.3]]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
