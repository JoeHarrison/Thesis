{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import rubiks\n",
    "import rubiks2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os \n",
    "import copy\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from replay_memories import ReplayMemory, PrioritizedReplayMemory\n",
    "from networks import DQN, DuelingDQN, DuelingDQNHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Torch Version:  1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "print(\"Torch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon decay\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 1000\n",
    "\n",
    "epsilon_by_exponential_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "\n",
    "epsilon_by_linear_step = lambda step_idx: epsilon_final + (epsilon_start-epsilon_final)*((epsilon_decay-step_idx)/epsilon_decay) if step_idx < epsilon_decay else epsilon_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fddb94e1828>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.title('Epsilon decay')\n",
    "plt.xlabel('Global steps')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.plot([epsilon_by_exponential_step(i) for i in range(10000)])\n",
    "plt.plot([epsilon_by_linear_step(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the q-values of an action in a state\n",
    "def compute_q_val(model, state, action):\n",
    "    qactions = model(state)\n",
    "    return torch.gather(qactions,1,action.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the target. When done, 0 is added to the reward as there is no next state.\n",
    "def compute_target_dqn(model, reward, next_state, done, gamma):\n",
    "    return reward + gamma * model(next_state).max(1)[0] * (1-done)\n",
    "\n",
    "# Computes the target. When done, 0 is added to the reward as there is no next state. But now for Double DQN\n",
    "def compute_target_ddqn(model, target_model, reward, next_state, done, gamma):\n",
    "    a = model(next_state)\n",
    "    return reward.view(-1,1) + gamma * torch.gather(target_model(next_state),1,model(next_state).max(1)[1].view(-1,1)) * (1-done).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(online_network, target_network, memory, optimizer, batch_size, gamma, local_steps, doubleDQN):\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "    \n",
    "    batch, indices, weights = memory.sample(batch_size, local_steps, device)\n",
    "\n",
    "    state, action, reward, next_state, done = zip(*batch)\n",
    "    \n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    action = torch.tensor(action, dtype=torch.long, device=device)\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float32, device=device)\n",
    "    reward = torch.tensor(reward, dtype=torch.float32, device=device)\n",
    "    done = torch.tensor(done, dtype=torch.float32, device=device)\n",
    "    \n",
    "    weights.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    q_val = compute_q_val(online_network, state, action)\n",
    "\n",
    "    with torch.no_grad():\n",
    "# Vanilla\n",
    "#         target = compute_target_dqn(q1, reward, next_state, done, gamma)\n",
    "        if doubleDQN:\n",
    "            target = compute_target_ddqn(online_network, target_network, reward, next_state, done, gamma)\n",
    "        else:\n",
    "            target = compute_target_dqn(target_network, reward, next_state, done, gamma)\n",
    "#     loss = F.mse_loss(q_val, target)\n",
    "    difference = (q_val - target.view(-1,1))\n",
    "    \n",
    "    # Weights is 1 for normal replay buffer so nothing changes\n",
    "    # McAleer divides the loss by the number of moves of the scramble here. Might not make sense in non-MCTS setting\n",
    "    loss = difference.pow(2) * weights\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Also taken from higgsfield\n",
    "    memory.update_priorities(indices, difference.detach().squeeze().abs().cpu().numpy().tolist())\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_capacity_keep_lr(network, capacity, optimizer, device):\n",
    "    # Store old ids\n",
    "    old_ids = [id(p) for p in network.parameters()]\n",
    "    old_param_sizes = [p.size() for p in network.parameters()]\n",
    "\n",
    "    network.increase_capacity(capacity)\n",
    "\n",
    "    # Store new ids\n",
    "    new_ids = [id(p) for p in network.parameters()]\n",
    "    new_param_sizes = [p.size() for p in network.parameters()]\n",
    "\n",
    "    # Store old state \n",
    "    opt_state_dict = optimizer.state_dict()\n",
    "    for old_id, new_id, new_param_size, old_param_size in zip(old_ids, new_ids, new_param_sizes, old_param_sizes):\n",
    "        # Store step, and exp_avgs\n",
    "        step = opt_state_dict['state'][old_id]['step']\n",
    "        old_exp_avg = opt_state_dict['state'][old_id]['exp_avg']\n",
    "        old_exp_avg_sq = opt_state_dict['state'][old_id]['exp_avg_sq']\n",
    "        old_max_exp_avg_sq = opt_state_dict['state'][old_id]['max_exp_avg_sq']\n",
    "\n",
    "        exp_avg = torch.zeros(new_param_size)\n",
    "        exp_avg_sq = torch.zeros(new_param_size)\n",
    "        max_exp_avg_sq =  torch.zeros(new_param_size)\n",
    "        # Extend exp_avgs to new shape depending on wether param is bias or weight\n",
    "        if exp_avg.dim()>1:\n",
    "            # Weights\n",
    "            exp_avg[0:old_param_size[0],0:old_param_size[1]] = old_exp_avg\n",
    "            exp_avg_sq[0:old_param_size[0],0:old_param_size[1]] = old_exp_avg_sq\n",
    "            max_exp_avg_sq[0:old_param_size[0],0:old_param_size[1]] = old_max_exp_avg_sq\n",
    "        else:\n",
    "            # Biases/last layer\n",
    "            exp_avg[0:old_param_size[0]] = old_exp_avg\n",
    "            exp_avg_sq[0:old_param_size[0]] = old_exp_avg_sq\n",
    "            max_exp_avg_sq[0:old_param_size[0]] = old_max_exp_avg_sq\n",
    "        \n",
    "        # Delete old id from state_dict and update new params and new id\n",
    "        del opt_state_dict['state'][old_id]\n",
    "        opt_state_dict['state'][new_id] = {\n",
    "            'step': step,\n",
    "            'exp_avg': exp_avg,\n",
    "            'exp_avg_sq': exp_avg_sq.to(device),\n",
    "            'max_exp_avg_sq' : max_exp_avg_sq.to(device)\n",
    "        }\n",
    "        opt_state_dict['param_groups'][0]['params'].remove(old_id)\n",
    "        opt_state_dict['param_groups'][0]['params'].append(new_id)\n",
    "\n",
    "    network.to(device)\n",
    "    optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "    optimizer.load_state_dict(opt_state_dict)\n",
    "    \n",
    "    return network, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_settings(architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, \n",
    "                        memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, \n",
    "                        threshold, evaluation_frequency, tau, curriculum, non_linearity,\n",
    "                        verbose=False, load_path=None, save_path=None, seed=None):\n",
    "    # If the directory does not exist, make one\n",
    "    if save_path:\n",
    "        if not os.path.isdir(save_path):\n",
    "            os.mkdir(save_path)\n",
    "    \n",
    "    # If a seed is set, set the seed for all sources of randomness\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "            \n",
    "    # Difficulty the problem starts with\n",
    "    difficulty = 0\n",
    "    # The maximum number of tries the agent gets at the start\n",
    "    max_tries_start = 1\n",
    "    max_tries = max_tries_start\n",
    "    # 3 is chosen because this allows the network to learn the difference between short and long paths from the beginning. Take for example a cube that has been scrambled as follows: U. The solution within 3 steps is eather U' (r=1) or U, U, U (r=-1)\n",
    "    \n",
    "    # Arrays to keep track of losses and accuracies over time\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Global steps keeps track of the total number of optimisation steps\n",
    "    global_steps = 0\n",
    "    # Local steps keeps track of number of optimisation steps within a level\n",
    "    local_steps = 0\n",
    "    # Total time keeps track of how long the training process takes\n",
    "    \n",
    "    # Epsilon exponential decay\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_final = 0.01\n",
    "    # Duration of decay dependent on difficulty\n",
    "#     epsilon_decay = 10000*(difficulty//12 + 1)\n",
    "    epsilon_decay = 1000\n",
    "    # Duration independent on dificulty\n",
    "    epsilon_by_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "    \n",
    "    # If a path with a model is provided certain variables are loaded\n",
    "    if load_path:\n",
    "        current_model = torch.load(load_path + 'model.pt')\n",
    "        target_model = copy.deepcopy(current_model)\n",
    "        max_tries = torch.load(load_path + 'max_tries')\n",
    "        epsilon_decay = torch.load(load_path + 'epsilon_decay')\n",
    "        global_steps = torch.load(load_path + 'global_steps')\n",
    "        local_steps = torch.load(load_path + 'local_steps')\n",
    "        difficulty = torch.load(load_path + 'difficulty')\n",
    "    else:\n",
    "        # n^2 per face, 6 faces, 6 colours one-hot encoded. 3x3x6x6=324, 2x2x6x6=144\n",
    "        state_size = env.size**2 * 6**2\n",
    "        \n",
    "        # The number of output nodes is different for the 2x2x2. The move L is the same as the move R, except the orientation changes.\n",
    "        output_nodes = 12\n",
    "        if env.size == 2:\n",
    "            output_nodes = 6\n",
    "        \n",
    "        # Initialising either a network with dueling architecture or regular network\n",
    "        if duelingDQN:\n",
    "            current_model = DuelingDQN(state_size, architecture, output_nodes, non_linearity)\n",
    "            target_model = DuelingDQN(state_size, copy.copy(architecture), output_nodes, non_linearity)\n",
    "        else:\n",
    "            current_model = DQN(state_size, architecture, output_nodes, non_linearity)\n",
    "            target_model = DQN(state_size, copy.copy(architecture), output_nodes, non_linearity)\n",
    "            \n",
    "    if torch.cuda.is_available():\n",
    "        current_model.to('cuda')\n",
    "        target_model.to('cuda')\n",
    "    else:\n",
    "        current_model.to('cpu')\n",
    "        target_model.to('cpu')\n",
    "    \n",
    "    # Uses prioritized replay sampling when set to true, otherwise uniform replay sampling is used\n",
    "    if prioritizedReplayMemory:\n",
    "        memory = PrioritizedReplayMemory(memoryCapacity, alpha)\n",
    "    else:\n",
    "        memory = ReplayMemory(memoryCapacity)\n",
    "    \n",
    "    # Initialise optimiser\n",
    "    optimizer = optim.Adam(current_model.parameters(), lr=lr, amsgrad=amsgrad)\n",
    "    \n",
    "    # This allows you to stop the training progress\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            # Different types of curricula decide what state to show the network next.\n",
    "            if curriculum is 'Naive':\n",
    "                state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Joe':\n",
    "                p = np.random.rand()\n",
    "                if p < 0.2:\n",
    "                    state = env.curriculum_reset(np.random.randint(1, difficulty + 12))\n",
    "                else:\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Sutskever':\n",
    "                p = np.random.rand()\n",
    "                if p < 0.2:\n",
    "                    state = env.reset(np.random.randint(1, 1000))\n",
    "                else:\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "            elif curriculum is 'Mixed':\n",
    "                state = env.curriculum_reset(np.random.randint(1,1000))\n",
    "            else:\n",
    "                state = env.reset(1000)\n",
    "\n",
    "            done = 0\n",
    "            tries = 0\n",
    "            while tries < max_tries and not done:\n",
    "                \n",
    "                epsilon = epsilon_by_step(local_steps)\n",
    "                action = current_model.act(state, epsilon, [0]*env.action_space.n, device)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                memory.push((state, action, reward, next_state, done))\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                tries += 1\n",
    "            \n",
    "            loss = train_dqn(current_model, target_model, memory, optimizer, batch_size, gamma, local_steps, doubleDQN)\n",
    "\n",
    "            if loss:\n",
    "                epoch_losses.append(loss)\n",
    "                \n",
    "            global_steps += 1\n",
    "            local_steps += 1\n",
    "                \n",
    "            if global_steps % tau == 0:\n",
    "                target_model.load_state_dict(current_model.state_dict())\n",
    "                if save_path:\n",
    "                    torch.save(current_model, save_path + \"model.pt\")\n",
    "                    torch.save(max_tries, save_path + \"max_tries\")\n",
    "                    torch.save(epsilon_decay, save_path + \"epsilon_decay\")\n",
    "                    torch.save(global_steps, save_path + \"global_steps\")\n",
    "                    torch.save(local_steps, save_path + \"local_steps\")\n",
    "                    torch.save(local_steps, save_path + \"difficulty\")\n",
    "                    \n",
    "            if global_steps % evaluation_frequency == 0 and curriculum is not None:\n",
    "                total_done = 0\n",
    "                for i in range(difficulty + 1):\n",
    "                    # Here the agent is forced to evaluate its ability to solve certain last moves\n",
    "                    hashes = defaultdict(list)\n",
    "                    state = env.force_last_action_reset(i)\n",
    "                    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "                    done = 0\n",
    "                    tries = 0\n",
    "                    while tries < max_tries and not done:\n",
    "                        mask = hashes[hash(state.tostring())]\n",
    "                        action = current_model.act(state, 0, mask, device)\n",
    "                        next_state, reward, done, info = env.step(action)\n",
    "                        # memory.push((state, action, reward, next_state, done))\n",
    "                        hstate = state.copy()\n",
    "                        state = next_state\n",
    "                        \n",
    "                        h = hash(state.tostring())\n",
    "                        if h in hashes.keys():\n",
    "                            hashes[hash(hstate.tostring())][action] = -999\n",
    "                        else:\n",
    "                            hashes[h] = [0]*env.action_space.n\n",
    "                        \n",
    "                        total_done += done\n",
    "                        tries += 1\n",
    "                        \n",
    "                # Here the agent evaluates the ability to solve puzzles that have the last move from a set of moves with the same difficulty\n",
    "                for i in range(1000):\n",
    "                    hashes = defaultdict(list)\n",
    "                    state = env.curriculum_reset(difficulty)\n",
    "                    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "                    done = 0\n",
    "                    tries = 0\n",
    "                    while tries < max_tries and not done:\n",
    "                        mask = hashes[hash(state.tostring())]\n",
    "                        action = current_model.act(state, 0, mask, device)\n",
    "                        next_state, reward, done, info = env.step(action)\n",
    "                        # memory.push((state, action, reward, next_state, done))\n",
    "                        hstate = state.copy()\n",
    "                        state = next_state\n",
    "                        \n",
    "                        h = hash(state.tostring())\n",
    "                        if h in hashes.keys():\n",
    "                            hashes[hash(hstate.tostring())][action] = -999\n",
    "                        else:\n",
    "                            hashes[h] = [0]*env.action_space.n\n",
    "                            \n",
    "                        \n",
    "                        total_done += done\n",
    "                        tries += 1\n",
    "                \n",
    "                accuracy = total_done/(1000 + difficulty + 1)\n",
    "                accuracies.append(accuracy)\n",
    "                \n",
    "                if accuracy >= threshold:\n",
    "                    difficulty += 1\n",
    "                    max_tries = difficulty // output_nodes + max_tries_start\n",
    "                    local_steps = 0\n",
    "                    \n",
    "                    epsilon_start = 1.0\n",
    "                    epsilon_final = 0.01\n",
    "#                     epsilon_decay = 10000*(difficulty//output_nodes + 1)\n",
    "                    epsilon_decay = 1000\n",
    "\n",
    "                    epsilon_by_step = lambda step_idx: epsilon_final + (epsilon_start - epsilon_final) * np.exp(-1. * step_idx / epsilon_decay)\n",
    "                \n",
    "                if local_steps > 1000:\n",
    "                    if capacity_increase:\n",
    "                        local_steps = 0\n",
    "                        capacity = [c(difficulty) for c in capacity_increase]\n",
    "\n",
    "                        current_model, optimizer = increase_capacity_keep_lr(current_model, capacity, optimizer, device)\n",
    "                        target_model.increase_capacity(capacity)\n",
    "\n",
    "                        target_model.to(device)\n",
    "\n",
    "                if verbose:\n",
    "                    clear_output(True)\n",
    "                    print(\"Epoch: \", epoch, \"Global steps: \", global_steps)\n",
    "                    print(\"Difficulty: \", difficulty, \"Max tries:\", max_tries)\n",
    "                    print(\"Memory: \", len(memory), \"epsilon: \", epsilon, \"local steps: \", local_steps)\n",
    "                    print(\"Accuracy: \", accuracy, \"Threshold: \", threshold)\n",
    "                    print(current_model)\n",
    "                    \n",
    "                losses.append(np.average(epoch_losses))\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    if save_path:\n",
    "        torch.save(current_model, save_path + \"model.pt\")\n",
    "        torch.save(max_tries, save_path + \"max_tries\")\n",
    "        torch.save(epsilon_decay, save_path + \"epsilon_decay\")\n",
    "        torch.save(global_steps, save_path + \"global_steps\")\n",
    "        torch.save(local_steps, save_path + \"local_steps\")\n",
    "        torch.save(local_steps, save_path + \"difficulty\")\n",
    "            \n",
    "    return difficulty, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50000\n",
    "experiments = []\n",
    "# experiments.append([\"Baseline3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, False, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Naive', F.relu])\n",
    "# experiments.append([\"Mixed3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Mixed', F.relu])\n",
    "# experiments.append([\"Joe3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Joe', F.relu])\n",
    "# experiments.append([\"Sutskever3\", [4096, 2048, 512], False, False, False, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.53\", [4096, 2048, 512], False, False, True, 0.5, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.73\", [4096, 2048, 512], False, False, True, 0.7, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Prioritised0.93\", [4096, 2048, 512], False, False, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Dueling3\", [4096, 2048, 512], True, False, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Double3\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Linear_all3\", [64, 32, 8], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 6], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "# experiments.append([\"Elu3\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, None, 0.95, 100, 1000, 'Sutskever', F.elu])\n",
    "experiments.append([\"Increasing_all\", [8, 4, 1], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 8, lambda x: 4, lambda x: 1], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Increasing_all\", [64, 32, 8], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 6], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Increasing_bottom\", [64, 32, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 48, lambda x: 24, lambda x: 0], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "experiments.append([\"Same\", [4096, 2048, 512], True, True, True, 0.9, 100000, 1e-3, True, epochs, 128, 0.99, [lambda x: 0, lambda x: 0, lambda x: 0], 0.95, 100, 1000, 'Sutskever', F.relu])\n",
    "\n",
    "for experiment in experiments:\n",
    "    architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, threshold, evaluation_frequency, tau, curriculum, non_linearity = experiment[1:]\n",
    "\n",
    "    env = rubiks2.RubiksEnv2(2, unsolved_reward = -1.0, seed= 420)\n",
    "\n",
    "    train_with_settings(architecture, duelingDQN, doubleDQN, prioritizedReplayMemory, alpha, memoryCapacity, lr, amsgrad, epochs, batch_size, gamma, capacity_increase, threshold, evaluation_frequency, tau, curriculum, non_linearity, save_path='models/'+experiment[0]+'/', seed=420, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def superflip_test(model):\n",
    "    eval_model = torch.load(model)\n",
    "    eval_model.to(device)\n",
    "    \n",
    "    max_tries = 100\n",
    "    solve_rate_per_difficulty = []\n",
    "    average_tries_per_difficulty = []\n",
    "    \n",
    "    for i in range(14):\n",
    "        solved = 0\n",
    "        tries_solved = []\n",
    "        cycles = 0\n",
    "        start_states = defaultdict(list)\n",
    "        \n",
    "        for sequence in superflip_set:\n",
    "            env = rubiks2.RubiksEnv2(2, unsolved_reward=-1.0)\n",
    "            goal = env.get_observation()\n",
    "            \n",
    "            for j in range(i + 1):\n",
    "                env.step(sequence[j])\n",
    "\n",
    "            \n",
    "            hashes = defaultdict(list)\n",
    "            state = env.get_observation()\n",
    "            \n",
    "            # Remove duplicate starting states\n",
    "            if hash(state.tostring()) in start_states.keys():\n",
    "                continue\n",
    "                \n",
    "            hashes[hash(state.tostring())] = [0,0,0,0,0,0]\n",
    "            done = 0\n",
    "            tries = 0\n",
    "            \n",
    "            while not done and tries < max_tries:\n",
    "                mask = hashes[hash(state.tostring())]\n",
    "                \n",
    "                action = eval_model.act(state, 0, mask, device)\n",
    "\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "\n",
    "                hstate = state.copy()\n",
    "                state = next_state\n",
    "\n",
    "                tries += 1\n",
    "\n",
    "                h = hash(state.tostring())\n",
    "                if h in hashes.keys():\n",
    "                    #hashes[hash(hstate.tostring())][action] = -999\n",
    "                    cycles += 1\n",
    "                else:\n",
    "                    hashes[h] = [0,0,0,0,0,0]\n",
    "            if done:\n",
    "                solved += 1\n",
    "            tries_solved.append(tries)   \n",
    "            \n",
    "        solve_rate_per_difficulty.append(solved / len(superflip_set))\n",
    "        average_tries_per_difficulty.append(np.average(tries_solved))\n",
    "        print('Level', i, 'accuracy:', solved / len(superflip_set))\n",
    "        print(np.average(tries_solved), np.median(tries_solved))\n",
    "        \n",
    "    score = 0\n",
    "    for target_tries, avg_tries in enumerate(average_tries_per_difficulty):\n",
    "        score += ((target_tries + 1)/avg_tries)*solve_rate_per_difficulty[target_tries]\n",
    "    score /= 14\n",
    "    return solve_rate_per_difficulty, average_tries_per_difficulty, score\n",
    "    \n",
    "\n",
    "print(superflip_test('./models/Increasing_all/model.pt'))\n",
    "print(superflip_test('./models/Increasing_bottom/model.pt'))\n",
    "print(superflip_test('./models/Same/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = rubiks2.RubiksEnv2(2, unsolved_reward = -1.0, seed= 42)\n",
    "\n",
    "# Which tests are failing?\n",
    "difficulty = 42\n",
    "max_tries = 16\n",
    "current_model = torch.load('./models/Same/model.pt')\n",
    "current_model.to(device)\n",
    "\n",
    "total = 0\n",
    "total_done = 0\n",
    "for i in range(difficulty + 1):\n",
    "    # Here the agent is forced to evaluate its ability to solve certain last moves\n",
    "    hashes = defaultdict(list)\n",
    "    state = env.force_last_action_reset(i)\n",
    "    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "    done = 0\n",
    "    tries = 0\n",
    "    while tries < max_tries and not done:\n",
    "        mask = hashes[hash(state.tostring())]\n",
    "        action = current_model.act(state, 0, mask, device)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        hstate = state.copy()\n",
    "        state = next_state\n",
    "\n",
    "        h = hash(state.tostring())\n",
    "        if h in hashes.keys():\n",
    "            hashes[hash(hstate.tostring())][action] = -999\n",
    "        else:\n",
    "            hashes[h] = [0]*env.action_space.n\n",
    "\n",
    "        total_done += done\n",
    "        tries += 1\n",
    "    total += 1\n",
    "print(total_done)\n",
    "total_done_2 = 0\n",
    "# Here the agent evaluates the ability to solve puzzles that have the last move from a set of moves with the same difficulty\n",
    "for i in range(1000):\n",
    "    hashes = defaultdict(list)\n",
    "    state = env.curriculum_reset(difficulty)\n",
    "    \n",
    "    hashes[hash(state.tostring())] = [0]*env.action_space.n\n",
    "    done = 0\n",
    "    tries = 0\n",
    "    while tries < max_tries and not done:\n",
    "        mask = hashes[hash(state.tostring())]\n",
    "        action = current_model.act(state, 0, mask, device)\n",
    "        q_val = current_model(torch.tensor(state, dtype=torch.float, device=device))\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        hstate = state.copy()\n",
    "        state = next_state\n",
    "\n",
    "        h = hash(state.tostring())\n",
    "        if h in hashes.keys():\n",
    "            hashes[hash(hstate.tostring())][action] = -999\n",
    "        else:\n",
    "            hashes[h] = [0]*env.action_space.n\n",
    "\n",
    "\n",
    "        total_done += done\n",
    "        total_done_2 += done\n",
    "        tries += 1\n",
    "\n",
    "    total+=1\n",
    "    \n",
    "    if not done:\n",
    "        print(q_val\n",
    "             )\n",
    "        print([env.ACTION_MEANING_QUARTER_METRIC[scr] for scr in env.last_scramble])\n",
    "\n",
    "print(total_done_2)\n",
    "print(total_done/total)\n",
    "accuracy = total_done/(1000 + difficulty + 1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superflip_set = [[4,0,5,1,5,4,5,5,1,3,2,1,3,3],\n",
    "[0,5,1,1,0,0,1,5,0,2,2,4,4,5],\n",
    "[1,2,2,3,3,5,0,4,0,2,4,3,5,0],\n",
    "[1,0,5,0,4,3,3,1,3,1,0,2,3,2],\n",
    "[5,0,5,1,5,1,5,1,5,1,5,3,1,5],\n",
    "[3,5,3,2,4,2,4,5,1,0,4,3,5,0],\n",
    "[2,4,2,0,0,2,4,5,3,1,0,0,4,4],\n",
    "[5,0,5,4,3,2,3,4,3,2,4,2,2,1],\n",
    "[2,0,4,0,4,0,4,0,4,5,3,5,4,5],\n",
    "[2,4,2,4,3,2,2,1,3,5,4,4,2,3],\n",
    "[4,4,0,4,0,5,4,5,0,0,1,3,1,2],\n",
    "[0,4,0,5,1,1,0,2,2,3,2,3,5,5],\n",
    "[0,1,0,4,2,4,2,4,0,2,4,5,4,3],\n",
    "[2,3,2,2,1,5,1,5,3,5,1,5,5,4],\n",
    "[4,0,5,4,0,4,3,2,3,5,1,0,5,0],\n",
    "[2,3,1,2,1,5,3,2,3,1,2,1,2,2],\n",
    "[5,4,0,5,3,1,2,4,2,1,5,1,0,2],\n",
    "[2,4,0,1,3,4,0,0,2,2,4,0,5,4],\n",
    "[5,1,2,3,4,3,5,3,2,4,2,0,2,0],\n",
    "[1,2,0,4,2,3,1,3,1,0,4,5,0,1],\n",
    "[4,2,1,5,0,2,3,5,4,2,3,1,5,3],\n",
    "[2,3,4,5,1,5,0,4,2,3,1,2,1,3],\n",
    "[0,5,1,3,2,4,0,0,4,0,4,0,5,0],\n",
    "[5,1,2,3,5,1,3,4,2,4,5,5,0,2],\n",
    "[0,4,3,5,1,0,5,0,2,3,4,4,3,1],\n",
    "[3,3,4,2,4,5,1,3,3,5,0,2,0,0],\n",
    "[5,3,1,3,5,1,0,0,1,0,1,5,4,4],\n",
    "[2,0,1,5,1,3,1,2,4,3,2,4,0,2],\n",
    "[1,0,4,3,5,3,5,1,5,0,4,3,2,1],\n",
    "[3,1,0,2,2,0,5,3,1,3,4,5,1,3],\n",
    "[1,3,5,4,0,2,2,3,1,3,4,0,2,3],\n",
    "[5,3,1,1,3,2,1,5,0,5,1,1,2,3],\n",
    "[4,3,2,1,3,5,1,5,4,4,2,4,3,4],\n",
    "[4,4,3,5,0,5,5,3,1,3,2,4,5,1],\n",
    "[4,4,5,0,5,3,2,1,1,3,1,0,1,1],\n",
    "[5,1,2,3,2,1,2,3,3,4,3,2,4,4],\n",
    "[3,3,1,2,4,0,4,2,4,3,3,4,2,2],\n",
    "[3,5,0,5,5,3,1,3,2,3,2,1,5,4],\n",
    "[3,4,2,2,4,5,1,5,0,5,1,2,4,5],\n",
    "[4,2,4,2,2,1,0,4,0,1,2,4,5,4],\n",
    "[4,0,4,0,5,1,2,1,3,2,1,0,5,3],\n",
    "[1,2,2,3,3,4,0,2,1,0,4,0,5,0],\n",
    "[2,3,3,5,1,3,2,3,1,5,4,4,2,2],\n",
    "[1,2,2,4,2,4,0,4,3,3,5,5,4,0],\n",
    "[4,0,4,4,5,4,4,2,4,0,5,5,0,4],\n",
    "[5,1,3,2,1,3,2,1,2,1,0,5,4,3],\n",
    "[4,4,2,0,1,1,5,3,1,3,2,0,4,5],\n",
    "[0,1,5,3,2,1,5,3,2,4,0,2,4,2],\n",
    "[1,3,2,3,5,0,1,5,0,1,3,4,0,0],\n",
    "[1,2,1,3,1,5,1,3,1,5,4,3,5,5],\n",
    "[3,1,3,4,2,3,4,3,4,4,0,2,3,1],\n",
    "[5,1,2,2,1,5,0,5,5,3,5,5,1,3],\n",
    "[5,3,2,4,0,5,4,3,2,4,5,3,2,3],\n",
    "[1,2,1,3,2,4,0,4,2,0,1,2,3,5],\n",
    "[3,5,5,3,5,0,5,4,2,2,4,2,3,2],\n",
    "[4,5,1,5,4,2,1,1,3,5,1,2,3,2],\n",
    "[3,5,1,3,3,1,2,3,2,3,1,2,4,2],\n",
    "[2,0,1,3,2,3,1,3,2,4,5,0,4,4],\n",
    "[1,2,4,2,0,0,4,3,1,3,2,2,0,0],\n",
    "[2,3,3,5,4,0,4,0,4,5,4,5,4,0],\n",
    "[2,1,3,2,2,3,1,3,2,0,4,3,3,2],\n",
    "[4,4,5,4,2,2,4,0,5,0,1,3,2,3],\n",
    "[3,2,4,4,3,5,0,4,0,4,5,5,1,0],\n",
    "[3,4,2,4,2,4,2,4,0,2,0,2,0,1],\n",
    "[4,5,3,4,0,4,5,0,1,3,1,2,1,2],\n",
    "[3,5,5,1,3,2,4,3,3,4,3,2,1,1],\n",
    "[3,4,4,3,1,2,3,1,5,0,5,4,5,0],\n",
    "[0,2,0,1,1,5,0,1,3,1,3,5,1,5],\n",
    "[3,1,5,1,2,0,5,3,1,5,5,4,2,4],\n",
    "[2,4,4,5,3,1,3,5,1,2,4,3,3,4],\n",
    "[3,1,3,4,3,5,1,5,0,5,4,4,0,4],\n",
    "[2,3,1,5,3,1,5,1,2,1,5,5,1,2],\n",
    "[3,3,4,0,1,5,3,2,3,3,2,3,1,3],\n",
    "[1,5,3,1,2,0,2,0,4,0,5,3,5,4],\n",
    "[0,1,1,5,0,4,5,0,2,4,5,1,5,4],\n",
    "[3,2,4,2,1,5,0,0,1,2,4,5,4,0],\n",
    "[0,4,0,5,0,4,2,4,2,2,4,2,3,2],\n",
    "[5,0,5,5,4,3,5,1,5,1,5,3,1,5],\n",
    "[0,5,4,5,0,4,0,4,0,1,5,3,3,2],\n",
    "[5,5,3,2,3,1,0,1,5,1,1,3,5,5],\n",
    "[0,5,1,0,5,3,3,5,1,2,0,5,5,4],\n",
    "[0,4,5,5,1,5,0,5,3,1,5,4,3,1],\n",
    "[5,1,0,4,2,2,0,1,2,2,1,5,1,1],\n",
    "[4,4,0,2,3,1,5,1,3,4,4,3,1,1],\n",
    "[0,5,1,5,1,2,2,0,0,1,1,2,4,2],\n",
    "[2,0,2,2,3,1,0,4,0,2,2,3,1,2],\n",
    "[4,0,2,3,1,5,3,1,5,0,2,4,0,4],\n",
    "[1,3,5,4,0,2,4,2,4,3,5,4,4,0],\n",
    "[5,4,3,5,1,5,1,1,2,4,2,0,4,3],\n",
    "[1,5,4,0,5,4,3,1,2,3,4,4,5,3],\n",
    "[0,2,3,2,0,2,3,1,3,1,5,1,0,0],\n",
    "[5,4,3,2,3,2,0,5,0,4,4,2,0,2],\n",
    "[2,1,5,1,2,4,4,0,2,1,2,4,3,3],\n",
    "[2,3,2,2,1,0,1,3,5,1,2,1,1,2],\n",
    "[5,0,4,3,1,3,4,0,1,5,1,0,1,3],\n",
    "[5,5,0,0,2,4,2,1,5,0,4,3,4,4],\n",
    "[1,0,5,0,1,2,4,5,1,3,5,0,2,3],\n",
    "[4,4,2,0,5,1,5,0,5,1,1,5,3,3],\n",
    "[0,2,4,5,5,4,5,3,1,3,3,2,3,1],\n",
    "[4,0,5,5,1,3,5,1,3,1,3,5,0,4],\n",
    "[0,2,2,4,2,4,3,2,2,3,3,1,0,2],\n",
    "[5,1,3,1,2,0,4,2,2,0,4,4,3,1],\n",
    "[1,2,1,1,0,5,0,5,1,2,0,5,3,5],\n",
    "[3,1,5,1,0,4,3,1,0,2,4,5,5,0],\n",
    "[5,5,1,0,4,2,3,2,4,5,5,1,2,2],\n",
    "[2,3,2,3,1,5,0,1,2,3,3,5,1,3],\n",
    "[4,2,4,4,0,4,5,0,5,0,4,3,1,3],\n",
    "[1,3,1,3,4,0,2,2,0,1,0,4,2,2],\n",
    "[3,1,5,1,5,0,4,3,4,5,5,1,3,1],\n",
    "[5,4,0,1,5,0,2,4,0,5,1,1,2,3],\n",
    "[2,1,0,4,5,0,4,2,3,2,4,2,1,0],\n",
    "[0,4,2,1,3,2,4,0,2,1,5,5,3,1],\n",
    "[0,5,3,4,4,3,2,0,5,0,4,5,4,3],\n",
    "[2,3,2,3,5,0,1,5,4,5,0,5,5,4],\n",
    "[4,0,5,5,0,2,0,4,2,0,4,5,0,4],\n",
    "[4,0,4,5,1,5,0,1,2,3,2,1,1,3],\n",
    "[3,4,4,2,1,5,1,3,2,4,4,5,1,1],\n",
    "[0,5,3,3,2,0,2,4,0,4,0,5,1,2],\n",
    "[2,1,5,1,3,1,0,5,0,2,2,3,3,1],\n",
    "[0,4,5,5,0,4,3,1,3,2,3,2,1,3],\n",
    "[1,0,0,5,0,5,1,3,3,1,2,3,2,2],\n",
    "[4,5,1,3,4,2,0,5,4,2,3,5,5,1],\n",
    "[3,2,1,5,3,2,3,4,5,4,4,2,1,3],\n",
    "[3,5,5,1,3,5,3,2,2,1,3,5,1,2],\n",
    "[3,4,2,1,1,2,3,4,3,5,3,5,5,1],\n",
    "[0,4,0,5,0,4,3,2,3,1,1,0,2,1],\n",
    "[2,1,5,0,4,3,4,2,3,3,1,0,0,1],\n",
    "[4,4,3,2,4,2,0,2,0,0,5,0,5,4],\n",
    "[2,0,4,0,4,5,4,2,0,0,2,4,5,0],\n",
    "[1,2,3,1,3,2,4,4,5,3,4,3,5,0],\n",
    "[4,2,3,5,3,2,3,5,3,1,2,3,5,0],\n",
    "[3,4,0,4,2,3,1,0,5,4,4,0,2,2],\n",
    "[4,2,2,4,0,2,3,1,5,1,1,0,4,4],\n",
    "[1,2,0,2,0,4,0,5,3,1,3,4,0,4],\n",
    "[0,1,3,1,1,5,0,1,3,2,4,4,0,5],\n",
    "[2,3,1,3,1,2,3,4,4,2,4,4,3,1],\n",
    "[4,0,5,5,4,5,1,5,0,4,5,3,1,0],\n",
    "[2,4,2,3,2,0,5,4,4,0,5,5,4,0],\n",
    "[5,3,1,5,0,2,1,3,4,2,1,5,1,3],\n",
    "[4,4,0,5,1,3,1,2,1,5,0,1,0,5],\n",
    "[5,1,1,5,1,2,3,1,3,5,5,1,0,0],\n",
    "[1,5,3,2,3,5,0,1,2,2,1,5,1,3],\n",
    "[5,4,0,0,2,1,0,4,2,3,1,3,1,2],\n",
    "[0,1,1,0,4,3,5,0,4,5,3,1,5,3],\n",
    "[5,4,2,4,2,3,2,1,0,0,4,5,0,0],\n",
    "[4,0,5,0,5,0,2,0,4,3,2,3,4,5],\n",
    "[2,0,5,0,4,4,5,4,2,4,0,0,4,4],\n",
    "[0,4,2,3,1,3,4,0,2,2,4,2,2,0],\n",
    "[2,3,4,5,0,1,2,3,2,1,3,5,3,3],\n",
    "[4,2,3,4,3,1,1,3,4,3,4,2,0,4],\n",
    "[0,4,3,2,4,5,5,1,3,2,1,3,5,5],\n",
    "[5,1,0,1,0,5,1,5,4,2,2,4,3,4],\n",
    "[5,5,4,5,4,0,1,5,3,2,1,3,4,4],\n",
    "[4,4,0,5,3,1,5,0,1,3,3,4,2,4],\n",
    "[5,3,2,1,5,1,3,4,5,0,4,4,5,5],\n",
    "[5,0,5,0,5,1,5,5,0,4,3,4,0,2],\n",
    "[0,2,3,4,5,1,5,1,1,3,2,0,4,0],\n",
    "[5,3,2,3,5,0,1,5,4,2,4,3,3,2],\n",
    "[2,4,4,0,4,0,4,2,3,1,2,0,4,5],\n",
    "[5,5,1,3,5,4,3,2,1,5,4,2,3,4],\n",
    "[5,5,4,2,3,1,5,1,2,0,4,3,4,5],\n",
    "[4,2,3,5,3,2,3,5,3,1,2,3,5,3],\n",
    "[1,3,2,4,5,3,3,1,0,2,3,1,0,2],\n",
    "[3,2,4,4,0,5,3,2,0,2,2,1,1,3],\n",
    "[1,0,4,2,1,3,2,2,3,4,5,1,5,5],\n",
    "[3,1,0,4,2,2,4,3,4,0,4,2,2,4],\n",
    "[2,3,1,2,2,4,2,1,5,0,5,1,5,3],\n",
    "[1,5,0,5,3,4,5,4,2,3,5,1,3,2],\n",
    "[0,4,0,4,0,4,5,0,4,5,0,1,2,2],\n",
    "[3,2,4,4,3,4,2,4,5,1,0,0,5,5],\n",
    "[1,3,4,4,5,1,3,5,0,4,2,3,5,3],\n",
    "[3,3,1,5,1,5,1,2,1,3,5,0,5,3],\n",
    "[3,1,0,4,2,3,2,0,2,4,4,3,2,4],\n",
    "[4,2,3,1,1,2,0,2,2,3,1,3,1,5],\n",
    "[5,3,1,5,1,5,3,4,4,2,4,5,4,2],\n",
    "[5,1,2,3,1,1,2,0,5,5,0,5,1,1],\n",
    "[2,4,0,1,3,1,3,2,0,1,1,0,2,2],\n",
    "[4,0,5,5,0,2,2,1,0,1,0,4,5,5],\n",
    "[3,2,1,5,0,5,0,1,5,1,2,0,4,0],\n",
    "[2,4,2,3,5,0,2,2,1,5,3,2,3,1],\n",
    "[3,3,5,1,2,3,3,5,1,3,4,2,2,3],\n",
    "[5,1,3,4,3,5,3,1,2,4,4,0,2,4],\n",
    "[4,4,3,4,5,0,2,3,2,3,4,2,1,2],\n",
    "[2,3,3,2,3,3,1,5,4,5,0,4,0,1],\n",
    "[4,2,3,1,3,5,4,0,1,3,4,2,1,1],\n",
    "[5,0,2,4,5,3,3,1,3,5,4,0,1,1],\n",
    "[3,4,0,1,5,0,0,1,2,4,0,4,4,3],\n",
    "[2,3,5,4,2,4,0,2,0,5,1,1,5,5],\n",
    "[4,2,3,5,1,3,2,1,5,4,3,1,5,3],\n",
    "[5,1,3,5,4,2,3,4,5,1,2,3,4,0],\n",
    "[5,5,3,2,3,4,0,4,3,1,0,5,4,5],\n",
    "[3,5,0,4,3,5,5,1,3,2,0,2,4,2],\n",
    "[3,1,2,0,5,1,0,2,3,5,1,0,4,5],\n",
    "[2,0,5,3,3,5,1,3,4,2,3,5,3,4],\n",
    "[1,0,5,1,2,3,1,1,2,4,4,2,2,0],\n",
    "[1,5,1,5,1,3,5,0,4,3,1,5,4,2],\n",
    "[0,1,3,3,2,3,4,5,1,5,1,0,0,4],\n",
    "[1,3,4,0,5,3,2,0,1,3,2,4,0,2],\n",
    "[3,2,3,2,2,1,2,1,3,1,3,1,2,4],\n",
    "[4,2,4,0,2,0,4,3,5,0,4,0,4,5],\n",
    "[3,1,2,2,4,0,4,2,3,1,0,1,5,1],\n",
    "[0,1,1,5,1,3,1,5,4,3,1,5,3,3],\n",
    "[3,3,2,2,3,1,2,0,4,2,3,4,3,1],\n",
    "[4,4,0,4,3,1,2,1,5,5,4,2,0,2],\n",
    "[2,4,0,0,1,2,4,2,3,1,2,4,4,3],\n",
    "[3,1,0,4,2,2,4,3,4,0,5,5,0,5],\n",
    "[5,3,1,1,0,5,1,2,1,0,2,2,1,2],\n",
    "[5,3,4,0,4,3,3,5,1,2,3,2,4,3],\n",
    "[2,3,5,1,3,3,5,4,2,2,4,2,0,0],\n",
    "[0,5,1,3,2,3,2,4,3,1,1,2,3,4],\n",
    "[4,2,4,4,3,5,0,4,3,2,3,3,1,1],\n",
    "[2,4,0,0,4,3,3,5,3,5,4,0,5,5],\n",
    "[2,3,2,2,1,5,4,2,3,4,5,3,2,4],\n",
    "[2,1,3,1,1,0,4,2,3,1,2,0,5,1],\n",
    "[0,5,0,5,1,3,2,4,5,4,2,1,3,5],\n",
    "[5,1,0,4,3,2,4,2,4,5,5,3,2,4],\n",
    "[5,0,4,0,4,5,0,2,0,4,0,5,0,1],\n",
    "[2,3,2,4,3,1,5,4,2,3,5,0,4,2],\n",
    "[1,5,0,5,1,2,3,2,4,0,0,4,3,4],\n",
    "[2,3,4,0,2,2,1,3,2,4,2,4,2,4],\n",
    "[2,0,1,5,0,0,4,2,4,3,2,0,0,1],\n",
    "[5,5,3,1,3,3,5,0,2,3,2,4,0,4],\n",
    "[0,2,2,4,2,3,2,4,4,2,1,3,4,4],\n",
    "[2,0,4,2,2,1,3,2,3,2,4,3,1,0],\n",
    "[3,1,2,3,5,1,5,5,3,3,1,0,4,0],\n",
    "[3,5,0,1,1,3,2,3,1,5,0,2,0,4],\n",
    "[4,5,1,3,2,2,1,1,3,1,5,0,5,3],\n",
    "[5,0,4,2,3,2,4,3,2,3,5,0,5,4],\n",
    "[3,2,1,2,4,2,1,2,4,4,0,2,4,3],\n",
    "[3,5,5,4,4,2,3,2,0,5,4,4,5,0],\n",
    "[1,0,2,4,2,0,0,5,0,5,1,0,4,2],\n",
    "[4,2,4,3,2,4,2,1,0,5,1,2,2,3],\n",
    "[2,1,0,0,5,0,1,3,2,3,1,1,2,0],\n",
    "[4,2,2,1,2,4,2,3,2,0,2,1,2,4],\n",
    "[2,3,5,4,4,0,1,2,1,5,0,0,1,1],\n",
    "[5,5,1,0,2,3,1,5,5,4,0,5,3,4],\n",
    "[3,1,5,4,2,3,2,0,2,4,0,0,4,0],\n",
    "[3,2,3,4,0,1,3,4,5,0,1,1,5,1],\n",
    "[5,3,1,2,0,4,0,2,4,2,0,1,2,2],\n",
    "[2,4,3,4,2,4,0,4,2,3,1,0,1,5],\n",
    "[3,3,1,2,2,1,0,5,1,3,1,0,5,0],\n",
    "[4,2,1,5,0,4,4,2,2,0,5,3,2,4],\n",
    "[0,5,1,2,2,1,0,1,3,5,0,4,0,1],\n",
    "[2,4,5,4,0,1,1,5,3,1,3,2,3,2],\n",
    "[5,0,4,0,4,5,4,2,1,0,4,0,4,4],\n",
    "[4,4,5,4,2,2,0,1,3,1,3,5,1,2],\n",
    "[2,1,3,5,0,2,3,4,5,1,3,4,5,1],\n",
    "[0,2,3,5,5,3,1,3,4,0,5,3,5,4],\n",
    "[4,3,1,3,2,4,0,4,2,4,5,0,1,1],\n",
    "[0,5,3,4,4,2,4,2,3,5,1,1,0,1],\n",
    "[3,4,4,2,4,0,1,0,0,1,0,0,2,1],\n",
    "[4,3,2,1,5,3,1,5,3,5,3,4,0,1],\n",
    "[2,4,2,3,1,0,2,3,3,4,3,4,5,1],\n",
    "[2,4,2,0,1,5,1,3,5,1,2,3,3,5],\n",
    "[3,4,0,4,4,0,4,2,0,1,1,0,5,5],\n",
    "[5,5,1,0,5,0,4,3,1,3,2,2,3,3],\n",
    "[3,1,5,3,1,5,1,3,5,1,5,1,1,2],\n",
    "[4,2,3,1,5,5,0,5,0,2,1,5,1,1],\n",
    "[5,4,2,1,5,0,4,0,5,4,5,5,4,5],\n",
    "[0,5,4,2,0,4,2,1,2,0,0,5,4,2],\n",
    "[5,0,0,2,2,1,5,4,2,4,4,3,3,4],\n",
    "[3,1,0,5,1,5,4,2,4,5,4,3,5,1],\n",
    "[4,4,5,0,4,5,3,3,5,1,0,4,2,1],\n",
    "[4,2,3,4,0,2,4,2,2,4,0,5,4,4],\n",
    "[2,4,5,4,0,1,5,1,5,3,5,0,0,1],\n",
    "[3,4,2,4,0,1,2,4,4,3,1,0,1,2],\n",
    "[5,1,2,2,3,5,0,5,4,0,5,5,4,4],\n",
    "[3,2,3,1,2,2,4,5,3,3,1,3,1,5],\n",
    "[3,4,3,2,4,0,4,0,1,2,1,5,0,5],\n",
    "[1,5,4,3,1,5,3,2,0,5,0,2,3,1],\n",
    "[4,5,1,3,5,0,4,2,3,2,0,2,4,4],\n",
    "[1,3,2,4,0,2,3,5,4,2,3,2,4,4],\n",
    "[2,0,1,1,5,0,2,3,2,4,2,2,0,2],\n",
    "[3,1,5,0,4,2,4,2,1,0,4,2,1,1],\n",
    "[3,4,2,4,0,5,3,1,1,3,1,2,4,2],\n",
    "[4,4,5,3,5,1,2,3,1,2,2,4,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_zero():\n",
    "    return random.uniform(0, 49) / 100\n",
    "\n",
    "def generate_one():\n",
    "    return random.uniform(50, 100) / 100\n",
    "\n",
    "def generate_both(num_data_points, p):\n",
    "    Xs, Ys = [], []\n",
    "    for _ in range(num_data_points):\n",
    "        if random.random() < p:\n",
    "            Xs.append([generate_zero(), generate_zero(), 0]); Ys.append([0])\n",
    "            # or(1, 0) -> 1\n",
    "            Xs.append([generate_one(), generate_zero(), 0]); Ys.append([1])\n",
    "            # or(0, 1) -> 1\n",
    "            Xs.append([generate_zero(), generate_one(), 0]); Ys.append([1])\n",
    "            # or(1, 1) -> 1\n",
    "            Xs.append([generate_one(), generate_one(), 0]); Ys.append([1])\n",
    "        else:\n",
    "            # xor(0, 0) -> 0\n",
    "            Xs.append([generate_zero(), generate_zero(), 1]); Ys.append([0])\n",
    "            # xor(1, 0) -> 1\n",
    "            Xs.append([generate_one(), generate_zero(), 1]); Ys.append([1])\n",
    "            # xor(0, 1) -> 1\n",
    "            Xs.append([generate_zero(), generate_one(), 1]); Ys.append([1])\n",
    "            # xor(1, 1) -> 0\n",
    "            Xs.append([generate_one(), generate_one(), 1]); Ys.append([0])\n",
    "    return Xs, Ys\n",
    "\n",
    "def generate_or_XY(num_data_points):\n",
    "    Xs, Ys = [], []\n",
    "    for _ in range(num_data_points):\n",
    "        # or(0, 0) -> 0 \n",
    "        Xs.append([generate_zero(), generate_zero(), 0]); Ys.append([0])\n",
    "        # or(1, 0) -> 1\n",
    "        Xs.append([generate_one(), generate_zero(), 0]); Ys.append([1])\n",
    "        # or(0, 1) -> 1\n",
    "        Xs.append([generate_zero(), generate_one(), 0]); Ys.append([1])\n",
    "        # or(1, 1) -> 1\n",
    "        Xs.append([generate_one(), generate_one(), 0]); Ys.append([1])\n",
    "    return Xs, Ys\n",
    "\n",
    "def generate_xor_XY(num_data_points):\n",
    "    Xs, Ys = [], []\n",
    "    for _ in range(num_data_points):\n",
    "        # xor(0, 0) -> 0 \n",
    "        Xs.append([generate_zero(), generate_zero(), 1]); Ys.append([0])\n",
    "        # xor(1, 0) -> 1\n",
    "        Xs.append([generate_one(), generate_zero(), 1]); Ys.append([1])\n",
    "        # xor(0, 1) -> 1\n",
    "        Xs.append([generate_zero(), generate_one(), 1]); Ys.append([1])\n",
    "        # xor(1, 1) -> 0\n",
    "        Xs.append([generate_one(), generate_one(), 1]); Ys.append([0])\n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-df2355e0b176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowest_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mxor_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0mxor_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mxor_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-df2355e0b176>\u001b[0m in \u001b[0;36mxor_experiments\u001b[0;34m(initial_capacity, train_or, capacity)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def xor_experiments(initial_capacity, train_or, capacity):\n",
    "    lowest_loss = 0\n",
    "    lowest_settings = []    \n",
    "    losses_xor = []\n",
    "    losses_or = []\n",
    "    for seed in range(100):\n",
    "        # Set seeds\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialisation network\n",
    "        network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "        # optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "        optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        if train_or:\n",
    "            for i in range(500):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                Xs, Ys = generate_both(25,0.1)\n",
    "                    \n",
    "                Xs = torch.tensor(Xs)\n",
    "                Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "                prediction = network(Xs)\n",
    "                loss = criterion(prediction, Ys)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Evaluation\n",
    "                    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "                    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "                    loss = 1.0/(1.0+criterion(prediction, Ys))\n",
    "\n",
    "                if loss>0.95:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        if capacity is not None:\n",
    "            network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "        \n",
    "        \n",
    "        iters = 500\n",
    "        if not train_or:\n",
    "            iters * 2\n",
    "            \n",
    "        for i in range(iters):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Uniform syllabus 20% of the time\n",
    "            Xs, Ys = generate_both(25,0.9)\n",
    "                \n",
    "            Xs = torch.tensor(Xs)\n",
    "            Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "            prediction = network(Xs)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        average_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Test or\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = 1.0/(1.0+criterion(prediction, Ys))\n",
    "        \n",
    "        average_loss += loss.item()\n",
    "        losses_or.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test xor\n",
    "            prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "            loss = 1.0/(1.0+criterion(prediction, Ys))\n",
    "        \n",
    "        average_loss += loss.item()\n",
    "        average_loss /= 2\n",
    "        losses_xor.append(loss.item())\n",
    "        \n",
    "        if average_loss > lowest_loss:\n",
    "            lowest_loss = copy.copy(average_loss)\n",
    "            lowest_settings = [average_loss, losses_or[-1], losses_xor[-1], seed, initial_capacity, train_or, capacity]\n",
    "        \n",
    "        if loss>0.95:\n",
    "            break\n",
    "        \n",
    "    # Print statistics\n",
    "    print(initial_capacity, train_or, capacity)\n",
    "    print('Average loss or: ', np.average(losses_or))\n",
    "    print('Average loss xor: ', np.average(losses_xor))\n",
    "    print('Average loss: ', (np.average(losses_or) +  np.average(losses_xor))/2)\n",
    "    print(lowest_settings)\n",
    "    \n",
    "xor_experiments([2],False, None)\n",
    "xor_experiments([2], True, None)\n",
    "xor_experiments([1], True, [1])\n",
    "\n",
    "xor_experiments([3],False,None)\n",
    "xor_experiments([3], True, None)\n",
    "xor_experiments([2], True, [1])\n",
    "xor_experiments([1], True, [2])\n",
    "\n",
    "xor_experiments([4],False,None)\n",
    "xor_experiments([4], True, None)\n",
    "xor_experiments([1], True, [3])\n",
    "xor_experiments([2], True, [2])\n",
    "xor_experiments([3], True, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capacity = [4]\n",
    "capacity = None\n",
    "train_or = True\n",
    "# Set seeds\n",
    "random.seed(99)\n",
    "np.random.seed(99)\n",
    "torch.manual_seed(99)\n",
    "\n",
    "# Initialisation network\n",
    "network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "# optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if train_or:\n",
    "    for i in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if np.random.rand() < 0.2:\n",
    "            if np.random.rand() < 0.5:\n",
    "                Xs, Ys = generate_or_XY(1)\n",
    "            else:\n",
    "                Xs, Ys = generate_xor_XY(1)\n",
    "        else:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "\n",
    "        Xs = torch.tensor(Xs)\n",
    "        Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "        prediction = network(Xs)\n",
    "        loss = criterion(prediction, Ys)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Evaluation\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        if loss<0.05:\n",
    "            break\n",
    "\n",
    "\n",
    "    nw_before = copy.deepcopy(network) \n",
    "if capacity is not None:\n",
    "    network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "\n",
    "nw_after_increase = copy.deepcopy(network)\n",
    "\n",
    "iters = 1000\n",
    "if not train_or:\n",
    "    iters * 2\n",
    "\n",
    "for i in range(iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Uniform syllabus 20% of the time\n",
    "    if np.random.rand() < 0.2:\n",
    "        if np.random.rand() < 0.5:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "        else:\n",
    "            Xs, Ys = generate_or_XY(1)\n",
    "    else:\n",
    "        Xs, Ys = generate_xor_XY(1)\n",
    "\n",
    "    Xs = torch.tensor(Xs)\n",
    "    Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "    prediction = network(Xs)\n",
    "    loss = criterion(prediction, Ys)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test or\n",
    "    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "    loss = criterion(prediction, Ys)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test xor\n",
    "    prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "    Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "    loss = criterion(prediction, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6208]], grad_fn=<AddmmBackward>)\n",
      "Weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.10118818 0.07070756 0.9919069 ]]\n",
      "Weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising specific weights, biases, and activations\n",
    "from matplotlib import colors\n",
    "\n",
    "def show_mat_label(data, data2=None):\n",
    "    data_list = []\n",
    "    if data2 is not None:\n",
    "        vmin = data.min()\n",
    "        vmax = data.max()\n",
    "\n",
    "        fig, axs = plt.subplots(3,1)\n",
    "        data_list.append(axs[0].matshow(data))\n",
    "\n",
    "        vmin = min(vmin,data2.min())\n",
    "        vmax = max(vmax,data2.max())\n",
    "        \n",
    "        data_list.append(axs[1].matshow(data2))\n",
    "        axs[1].get_xaxis().set_visible(False)\n",
    "\n",
    "        vmin = min(vmin,np.abs(data-data2).min())\n",
    "        vmax = max(vmax,np.abs(data-data2).max())\n",
    "        data_list.append(axs[2].matshow(np.abs(data-data2)))\n",
    "        axs[2].get_xaxis().set_visible(False)\n",
    "        \n",
    "        norm = colors.Normalize(vmin=0, vmax=1)\n",
    "        \n",
    "        fig.colorbar(data_list[0], ax=axs)\n",
    "        \n",
    "        for d in data_list:\n",
    "            d.set_norm(norm)\n",
    "    else:\n",
    "        fig, axs = plt.subplots()\n",
    "        cax = axs.matshow(data)\n",
    "        if data.shape[0]==1:\n",
    "            axs.get_yaxis().set_visible(False)\n",
    "        fig.colorbar(cax)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "x = torch.tensor([[0,0,1]],dtype=torch.float)\n",
    "\n",
    "weights0 = network.layers[0].weight.data.numpy()\n",
    "bias0 = np.array([network.layers[0].bias.data.numpy()])\n",
    "\n",
    "weights1 = network.layers[1].weight.data.numpy()\n",
    "bias1 = np.array([network.layers[1].bias.data.numpy()])\n",
    "\n",
    "x = torch.tensor([[1,1,0]],dtype=torch.float)\n",
    "print(network(x))\n",
    "x2 = torch.tensor([[1,1,1]],dtype=torch.float)\n",
    "print(network(x2))\n",
    "\n",
    "print('Weights')\n",
    "show_mat_label(weights0)\n",
    "print('Bias')\n",
    "show_mat_label(bias0)\n",
    "print('Activations')\n",
    "show_mat_label(F.relu(network.layers[0](x)).data.numpy(),F.relu(network.layers[0](x2)).data.numpy())\n",
    "print(np.abs(F.relu(network.layers[0](x)).data.numpy()-F.relu(network.layers[0](x2)).data.numpy()))\n",
    "\n",
    "x = F.relu(network.layers[0](x))\n",
    "x2 = F.relu(network.layers[0](x2))\n",
    "\n",
    "print('Weights')\n",
    "show_mat_label(weights1)\n",
    "print('Bias')\n",
    "show_mat_label(bias1)\n",
    "print('Activations')\n",
    "\n",
    "show_mat_label(network.layers[1](x).data.numpy(),network.layers[1](x2).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change(initial_capacity, capacity, train_or):\n",
    "    common = []\n",
    "    new = []\n",
    "    total = []\n",
    "    common_bias = []\n",
    "    new_bias = []\n",
    "\n",
    "    for seed in range(100):  \n",
    "        # Set seeds\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Initialisation network\n",
    "        network = DQN(3,initial_capacity.copy(),1,F.relu)\n",
    "        # optimizer = optim.Adam(network.parameters(), amsgrad=False)\n",
    "        optimizer = optim.Adam(network.parameters(), amsgrad=True)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if train_or:\n",
    "            for i in range(1000):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.rand() < 0.2:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        Xs, Ys = generate_or_XY(1)\n",
    "                    else:\n",
    "                        Xs, Ys = generate_xor_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "\n",
    "                Xs = torch.tensor(Xs)\n",
    "                Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "                prediction = network(Xs)\n",
    "                loss = criterion(prediction, Ys)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Evaluation\n",
    "                    prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "                    Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "                    loss = criterion(prediction, Ys)\n",
    "\n",
    "                if loss<0.05:\n",
    "                    break\n",
    "\n",
    "\n",
    "            nw_before = copy.deepcopy(network) \n",
    "        if capacity is not None:\n",
    "            network, optimizer = increase_capacity_keep_lr(network, capacity, optimizer, 'cpu')\n",
    "\n",
    "        nw_after_increase = copy.deepcopy(network)\n",
    "\n",
    "        iters = 1000\n",
    "        if not train_or:\n",
    "            iters * 2\n",
    "\n",
    "        for i in range(iters):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Uniform syllabus 20% of the time\n",
    "            if np.random.rand() < 0.2:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "                else:\n",
    "                    Xs, Ys = generate_or_XY(1)\n",
    "            else:\n",
    "                Xs, Ys = generate_xor_XY(1)\n",
    "\n",
    "            Xs = torch.tensor(Xs)\n",
    "            Ys = torch.tensor(Ys, dtype=torch.float)\n",
    "\n",
    "            prediction = network(Xs)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test or\n",
    "            prediction = network(torch.tensor([[0,0,0],[0,1,0],[1,0,0],[1,1,0]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[1]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Test xor\n",
    "            prediction = network(torch.tensor([[0,0,1],[0,1,1],[1,0,1],[1,1,1]], dtype=torch.float))\n",
    "            Ys = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "            loss = criterion(prediction, Ys)\n",
    "\n",
    "        common.append([torch.abs(nw_after_increase.layers[0].weight[0]-network.layers[0].weight[0]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][0]-network.layers[1].weight[0][0]).mean().data.numpy()])\n",
    "        new.append([torch.abs(nw_after_increase.layers[0].weight[1:]-network.layers[0].weight[1:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][1:]-network.layers[1].weight[0][1:]).mean().data.numpy()])\n",
    "        total.append([torch.abs(nw_after_increase.layers[0].weight[:]-network.layers[0].weight[:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].weight[0][:]-network.layers[1].weight[0][:]).mean().data.numpy()])\n",
    "        \n",
    "        common_bias.append([torch.abs(nw_after_increase.layers[0].bias[0]-network.layers[0].bias[0]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].bias[0]-network.layers[1].bias[0]).mean().data.numpy()])\n",
    "        new_bias.append([torch.abs(nw_after_increase.layers[0].bias[1:]-network.layers[0].bias[1:]).mean().data.numpy(), torch.abs(nw_after_increase.layers[1].bias[0]-network.layers[1].bias[0]).mean().data.numpy()])\n",
    "        \n",
    "    print(\"Common layer 0:\\t\", np.average(np.array(common)[:,0]))\n",
    "    print(\"New layer 0:\\t\", np.average(np.array(new)[:,0]))\n",
    "    print(\"Total layer 0:\\t\", np.average(np.array(total)[:,0]))\n",
    "    print(\"Common bias 0:\\t\", np.average(np.array(common_bias)[:,0]))\n",
    "    print(\"New bias 0:\\t\", np.average(np.array(new_bias)[:,0]))\n",
    "    \n",
    "    print(\"Common layer 1:\\t\", np.average(np.array(common)[:,1]))\n",
    "    print(\"New layer 1:\\t\", np.average(np.array(new)[:,1]))\n",
    "    print(\"Total layer 1:\\t\", np.average(np.array(total)[:,1]))\n",
    "    print(\"Common bias 1:\\t\", np.average(np.array(common_bias)[:,1]))\n",
    "    print(\"New bias 1:\\t\", np.average(np.array(new_bias)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-496-98b4062f53cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcapacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_or\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mweight_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_capacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_or\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minitial_capacity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-495-1ed4b587f53a>\u001b[0m in \u001b[0;36mweight_change\u001b[0;34m(initial_capacity, capacity, train_or)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_capacity = [4]\n",
    "capacity = None\n",
    "train_or = True\n",
    "weight_change(initial_capacity, capacity, train_or)\n",
    "print('----')\n",
    "initial_capacity = [1]\n",
    "capacity = [3]\n",
    "train_or = True\n",
    "weight_change(initial_capacity, capacity, train_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.2,0.3]]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
