{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from collections import OrderedDict, defaultdict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - Add Bias term\n",
    "    - Custom weights\n",
    "    - Drop out connections (set weight to 0)\n",
    "    - Custom activation per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return F.leaky_relu(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return F.Tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return F.relu(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return F.Sigmoid(x)\n",
    "\n",
    "string_to_activation = {\n",
    "    'leaky_relu' : leaky_relu,\n",
    "    'relu' : relu,\n",
    "    'sigmoid' : sigmoid,\n",
    "    'tanh' : tanh\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,layer_sizes):\n",
    "        super(Model, self).__init__()\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        previous_layer_size = layer_sizes[0]\n",
    "        for idx, current_layer_size in enumerate(layer_sizes[1:]):\n",
    "            layers[str(idx)] = nn.Linear(previous_layer_size, current_layer_size)\n",
    "            previous_layer_size = current_layer_size\n",
    "            \n",
    "        self.layers = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genotype(object):\n",
    "    def __init__(self, inputs, \n",
    "                 outputs, \n",
    "                 nonlinearities, \n",
    "                 feedforward,\n",
    "                 p_add_neuron, \n",
    "                 p_add_connection, \n",
    "                 p_mutate_weight, \n",
    "                 p_reenable_connection,\n",
    "                 p_disable_connection, \n",
    "                 p_reenable_parent, \n",
    "                 p_mutate_bias,\n",
    "                 distance_excess_weight, \n",
    "                 distance_disjoint_weight, \n",
    "                 distance_weight):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.nonlinearities = nonlinearities\n",
    "        self.feedforward = feedforward\n",
    "        \n",
    "        # Mutation Probabilities\n",
    "        self.p_add_neuron = p_add_neuron\n",
    "        self.p_add_connection = p_add_connection\n",
    "        self.p_mutate_weight = p_mutate_weight\n",
    "        self.p_reenable_connection = p_reenable_connection\n",
    "        self.p_disable_connection = p_disable_connection\n",
    "        self.p_reenable_parent = p_reenable_parent\n",
    "        self.p_mutate_bias = p_mutate_bias\n",
    "        \n",
    "        # Distance weights\n",
    "        self.distance_excess_weight = distance_excess_weight\n",
    "        self.distance_disjoint_weight = distance_disjoint_weight\n",
    "        self.distance_weight = distance_weight\n",
    "        \n",
    "        # Tuples of: id, non_linearity, layer\n",
    "        self.neuron_genes = []\n",
    "        # Tuples of: innovation number, input, output, weight, enabled\n",
    "        self.connection_genes = {}\n",
    "        # Hyperparameter genes\n",
    "        self.hyperparameter_genes = []\n",
    "        \n",
    "        self._initialise_topology()\n",
    "        \n",
    "    def _initialise_topology(self):\n",
    "        # Initialise inputs\n",
    "        for i in range(self.inputs):\n",
    "            self.neuron_genes.append([i * 2048, random.choice(self.nonlinearities),0])\n",
    "        \n",
    "        # Initialise outputs\n",
    "        for i in range(self.outputs):\n",
    "            self.neuron_genes.append([(self.inputs + i) * 2048, random.choice(self.nonlinearities)])\n",
    "        \n",
    "        # Initialiase connections\n",
    "        innovation_number = 0\n",
    "        for i in range(self.inputs):\n",
    "            for j in range(self.outputs,self.inputs + self.outputs):\n",
    "                weight = self._initialise_weight(self.inputs,self.outputs)\n",
    "                self.connection_genes[(i,j)] = [innovation_number, i, j, weight ,True]\n",
    "                innovation_number += 1\n",
    "                \n",
    "    def _initialise_weight(self, input_neurons, output_neurons):\n",
    "        weight = np.random.rand()*np.sqrt(1/(input_neurons + output_neurons))\n",
    "        \n",
    "#     def translate_to_pytorch(self):\n",
    "#         self.model = Model([self.inputs, 5, self.outputs])\n",
    "        \n",
    "#         print(self.model.layers[0].weight)\n",
    "#         raise NotImplementedError\n",
    "        \n",
    "#     def get_weight_matrix(self,layer_1, layer_2):\n",
    "#         raise NotImplementedError\n",
    "        \n",
    "    def recombinate(self, other):\n",
    "        child = deepcopy(self)\n",
    "        child.neuron_genes = []\n",
    "        child.connection_genes = {}\n",
    "        \n",
    "        max_neurons = max(len(self.neuron_genes), len(other.neruon_genes))\n",
    "        min_neurons = min(len(self.neuron_genes), len(other.neuron_genes))\n",
    "        \n",
    "        for i in range(max_neurons):\n",
    "            neuron_gene = None\n",
    "            if i < min_neurons:\n",
    "                neuron_gene = random.choice((self.neuron_genes[i], other.neuron_genes[i]))\n",
    "            else:\n",
    "                try:\n",
    "                    neuron_gene = self.neuron_genes[i]\n",
    "                except IndexError:\n",
    "                    neuron_gene = other.neuron_genes[i]\n",
    "            child.neurons_genes.append(deepcopy(neuron_gene))\n",
    "            \n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "        max_innovation_number = max(self_connections.keys() + other_connections.keys())\n",
    "        \n",
    "        for i in range(max_innovation_number + 1):\n",
    "            connection_gene = None\n",
    "            if i in self_connections and i in other_connections:\n",
    "                connection_gene = random.choice((self_connections[i],other_connections[i]))\n",
    "                enabled = self_connections[i][4] and other_connections[i][4]\n",
    "            else:\n",
    "                if i in self_connections:\n",
    "                    connection_gene = self_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "                elif i in other_connections:\n",
    "                    connection_gene = other_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "            if connection_gene is not None:\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])] = deepcopy(connection_gene)\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])][4] = enabled or rand() < self.p_reenable_parent\n",
    "\n",
    "            def is_feedforward(item):\n",
    "                ((fr, to), cg) = item\n",
    "                return child.node_genes[fr][0] < child.node_genes[to][0]\n",
    "\n",
    "            if self.feedforward:\n",
    "                child.conn_genes = dict(filter(is_feedforward, child.conn_genes.items()))\n",
    "            \n",
    "        return child\n",
    "        \n",
    "    def mutate(self):\n",
    "        # TODO: move to separate functions\n",
    "        if np.random.rand() < self.p_add_neuron:\n",
    "            # Choose connection to split\n",
    "            split_neuron = self.connection_genes[random.choice(self.connection_genes.keys())]\n",
    "            # Disable old connection\n",
    "            split_neuron[4] = False\n",
    "            \n",
    "            input_neuron, output_neuron, weight = split_neuron[1:4]\n",
    "            neuron_id = (self.neuron_genes[input_neuron][0] + self.neuron_genes[input_neuron][0]) * 0.5\n",
    "            nonlinearity = random.choice(self.nonlinearities)\n",
    "            layer = self.neuron_genes[input_neuron][2] + 1\n",
    "            \n",
    "            neuron = [neuron_id, nonlinearity, layer]\n",
    "            \n",
    "            neuron_id = len(self.node_genes) - 1\n",
    "            \n",
    "            self.neuron_genes.append(neuron)\n",
    "            # 1.0 to initialise_weight?\n",
    "            # TODO: get innovation number\n",
    "            self.connection_genes[(input_neuron, neuron_id)] = [innovation_number, input_neuron, neuron_id, 1.0, True]\n",
    "            \n",
    "            self.connection_genes[(neuron_id, output_neuron)] = [innovation_number, neuron_id, output_neuron, weight, True]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def distance(self, other):\n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "        \n",
    "        all_innovations = self_connections.keys() + other_connections.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species(object):\n",
    "    def __init__(self, initial_member):\n",
    "        self.members = [initial_member]\n",
    "        self.representative = initial_member\n",
    "        self.offspring = 0\n",
    "        self.age = 0\n",
    "        self.avg_fitness = 0.\n",
    "        self.max_fitness = 0.\n",
    "        self.max_fitness_previous = 0.0\n",
    "        self.stagnation = 0\n",
    "        self.has_best = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population(object):\n",
    "    def __init__(self, genome_factory,\n",
    "                population_size,\n",
    "                elitism,\n",
    "                stop_when_solved,\n",
    "                tournament_selection_k,\n",
    "                verbose,\n",
    "                max_cores,\n",
    "                compatibility_threshold,\n",
    "                compatibility_threshold_delta,\n",
    "                target_species,\n",
    "                minimum_elitism_size,\n",
    "                young_age,\n",
    "                young_multiplier,\n",
    "                old_age,\n",
    "                old_multiplier,\n",
    "                stagnation_age,\n",
    "                reset_innovations,\n",
    "                survival):\n",
    "        \n",
    "        self.genome_factory = genome_factory\n",
    "        self.population_size = population_size\n",
    "        self.elitism = elitism\n",
    "        self.stop_when_solved = stop_when_solved\n",
    "        self.tournament_selection_k = tournament_selection_k\n",
    "        self.verbose = verbose\n",
    "        self.max_cores = max_cores\n",
    "        \n",
    "        cpus = multiprocessing.cpu_count()\n",
    "        use_cores = min(self.max_cores, cpus-1)\n",
    "        if use_cores > 1:\n",
    "            self.pool = multiprocessing.pool(processing=use_cores, maxtasksperchild=5)\n",
    "        else:\n",
    "            self.pool = None\n",
    "        \n",
    "        self.compatibility_threshold = compatibility_threshold\n",
    "        self.compatibility_threshold_delta = compatibility_threshold_delta\n",
    "        \n",
    "        self.target_species = target_species\n",
    "        self.minimum_elitism_size = minimum_elitism_size\n",
    "        \n",
    "        self.young_age = young_age\n",
    "        self.young_multiplier = young_multiplier\n",
    "        self.old_age = old_age\n",
    "        self.old_multiplier = old_multiplier\n",
    "        \n",
    "        self.stagnation_age = stagnation_age\n",
    "        \n",
    "        self.reset_innovations = reset_innovations\n",
    "        self.survival = survival\n",
    "        \n",
    "    def _evaluate_all(self, population, evaluator):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.champions = []\n",
    "        self.generation = 0\n",
    "        self.solved_at = None\n",
    "        self.stats = defaulftdict(list)\n",
    "        \n",
    "        self.species = []\n",
    "        self.global_innovation_number = 0\n",
    "        self.innovations = {}\n",
    "        self.current_compatibility_threshold = self.compatibility_threshold\n",
    "        \n",
    "    def _evolve(self, evaluator, solution=None):\n",
    "        population = list(self.population)\n",
    "        \n",
    "        while len(population) < self.population_size:\n",
    "            individual = self.genome_factory()\n",
    "            pop.append(individual)\n",
    "            \n",
    "        population = self._evaluate_all(population, evaluator)\n",
    "        \n",
    "        # Speciation\n",
    "        for specie in self.species:\n",
    "            # Choose random specie representative for distance comparison\n",
    "            specie.representative = random.choice(specie.members)\n",
    "            specie.members = []\n",
    "            specie.age += 1\n",
    "            \n",
    "        # Add each individual to a species\n",
    "        for individual in population:\n",
    "            found = False\n",
    "            for specie in self.species:\n",
    "                if individual.distance(specie.representative) <= self.current_compatibility_threshold:\n",
    "                    specie.members.append(individual)\n",
    "                    found = True\n",
    "                    break\n",
    "                if not found:\n",
    "                    s = Species(individual)\n",
    "                    self.species.append(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 3\n",
    "outputs = 4\n",
    "nonlinearities = ['relu','sigmoid']\n",
    "feedforward = True\n",
    "\n",
    "p_add_node = 0.03\n",
    "p_add_connection = 0.3\n",
    "p_mutate_weight = 0.8\n",
    "p_reenable_connection = 0.01\n",
    "p_disable_connection = 0.01\n",
    "p_reenable_parent=0.25\n",
    "p_mutate_bias = 0.2\n",
    "\n",
    "distance_excess_weight = 1.0\n",
    "distance_disjoint_weight = 1.0\n",
    "distance_weight = 0.4\n",
    "\n",
    "genotype = Genotype(inputs, outputs, nonlinearities, feedforward, \n",
    "                    p_add_node, p_add_connection, p_mutate_weight, p_reenable_connection,\n",
    "                   p_disable_connection, p_reenable_parent, p_mutate_bias,\n",
    "                   distance_excess_weight, distance_disjoint_weight, distance_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_evolve() missing 1 required positional argument: 'evaluator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-da37dfa0c49b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melitism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_when_solved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament_selection_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatibility_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatibility_threshold_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_species\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_elitism_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myoung_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myoung_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstagnation_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_innovations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurvival\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: _evolve() missing 1 required positional argument: 'evaluator'"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "elitism = True\n",
    "stop_when_solved = False \n",
    "tournament_selection_k = 3 \n",
    "verbose = True\n",
    "max_cores = 1\n",
    "compatibility_threshold = 3.0\n",
    "compatibility_threshold_delta = 0.4 \n",
    "target_species = 12\n",
    "minimum_elitism_size = 5 \n",
    "young_age = 10\n",
    "young_multiplier = 1.2 \n",
    "old_age = 30\n",
    "old_multiplier = 0.2 \n",
    "stagnation_age = 15\n",
    "reset_innovations = False\n",
    "survival = 0.2\n",
    "\n",
    "genome_factory = lambda: Genotype(inputs, outputs, nonlinearities, feedforward, \n",
    "                    p_add_node, p_add_connection, p_mutate_weight, p_reenable_connection,\n",
    "                   p_disable_connection, p_reenable_parent, p_mutate_bias,\n",
    "                   distance_excess_weight, distance_disjoint_weight, distance_weight)\n",
    "\n",
    "population = Population(population_size, elitism, stop_when_solved, tournament_selection_k, verbose, max_cores, compatibility_threshold, compatibility_threshold_delta, target_species, minimum_elitism_size, young_age, young_multiplier, old_age, old_multiplier, stagnation_age, reset_innovations, survival)\n",
    "population._evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2442, -0.6035,  0.8889,  0.5022, -0.4859],\n",
       "        [-0.2921,  1.2088,  0.4895, -0.8608,  0.1795],\n",
       "        [ 1.1595, -0.7377, -0.1698,  0.0373,  1.0230]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(inputs):\n",
    "    ((fr, to), cg) =inputs\n",
    "    print(fr)\n",
    "\n",
    "conns = {}\n",
    "conns[(1,5)] = [2,2,3]\n",
    "dict(filter(f, conns.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
