{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import multiprocessing\n",
    "from collections import OrderedDict, defaultdict\n",
    "from itertools import product\n",
    "from copy import deepcopy, copy\n",
    "from namegenerator import NameGenerator\n",
    "\n",
    "import gym\n",
    "import rubiks\n",
    "\n",
    "# Debugging and profiling\n",
    "import cProfile\n",
    "import ipdb\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - Add Bias term\n",
    "    - Custom weights\n",
    "    - Drop out connections (set weight to 0)\n",
    "    - Custom activation per node\n",
    "    \n",
    "    - Add function that resets stagnation for all species\n",
    "    - Network Visualisation\n",
    "    - Species Visualisation\n",
    "    - Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return F.leaky_relu(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return F.relu(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "string_to_activation = {\n",
    "    'leaky_relu' : leaky_relu,\n",
    "    'relu' : relu,\n",
    "    'sigmoid' : sigmoid,\n",
    "    'tanh' : tanh,\n",
    "    'identity' : identity\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,layer_sizes):\n",
    "        super(Model, self).__init__()\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        previous_layer_size = layer_sizes[0]\n",
    "        for idx, current_layer_size in enumerate(layer_sizes[1:]):\n",
    "            layers[str(idx)] = nn.Linear(previous_layer_size, current_layer_size)\n",
    "            previous_layer_size = current_layer_size\n",
    "            \n",
    "        self.layers = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_generator = NameGenerator('names.csv', 3, 12)\n",
    "new_individual_name = firstname_generator.generate_name()\n",
    "previous_names = []\n",
    "surname_generator = NameGenerator('surnames.csv', 3, 12)\n",
    "new_specie_name = surname_generator.generate_name()\n",
    "previous_surnames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genotype(object):\n",
    "    def __init__(self, \n",
    "                 inputs = 144, \n",
    "                 outputs = 12, \n",
    "                 nonlinearities = ['relu','sigmoid','tanh'],\n",
    "                 topology = None,\n",
    "                 feedforward = True,\n",
    "                 max_depth = None,\n",
    "                 max_nodes = float('inf'),\n",
    "                 response_default = 4.924273,\n",
    "                 initial_weight_stdev = 2.0,\n",
    "                 bias_as_node = False,\n",
    "                 p_add_neuron = 0.03, \n",
    "                 p_add_connection = 0.3, \n",
    "                 p_mutate_weight = 0.8,\n",
    "                 p_reset_weight = 0.1,\n",
    "                 p_reenable_connection = 0.01,\n",
    "                 p_disable_connection = 0.01, \n",
    "                 p_reenable_parent = 0.25, \n",
    "                 p_mutate_bias = 0.2,\n",
    "                 p_mutate_response = 0.0,\n",
    "                 p_mutate_type = 0.2,\n",
    "                 stdev_mutate_weight = 1.5,\n",
    "                 stdev_mutate_bias = 0.5,\n",
    "                 stdev_mutate_response = 0.5,\n",
    "                 weight_range = (-50.,50.),\n",
    "                 distance_excess_weight = 1.0, \n",
    "                 distance_disjoint_weight = 1.0, \n",
    "                 distance_weight = 0.4):\n",
    "        \n",
    "        self.name = next(new_individual_name)\n",
    "        self.specie = None\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.nonlinearities = nonlinearities\n",
    "        self.feedforward = feedforward\n",
    "        self.bias_as_node = bias_as_node\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.max_nodes = max_nodes\n",
    "        \n",
    "        self.response_default = response_default\n",
    "        self.initial_weight_stdev = initial_weight_stdev\n",
    "        self.stdev_mutate_weight = stdev_mutate_weight\n",
    "        self.stdev_mutate_bias = stdev_mutate_bias\n",
    "        self.stdev_mutate_response = stdev_mutate_response\n",
    "        self.weight_range = weight_range\n",
    "        \n",
    "        # Mutation Probabilities\n",
    "        self.p_add_neuron = p_add_neuron\n",
    "        self.p_add_connection = p_add_connection\n",
    "        self.p_mutate_weight = p_mutate_weight\n",
    "        self.p_reset_weight = p_reset_weight\n",
    "        self.p_reenable_connection = p_reenable_connection\n",
    "        self.p_disable_connection = p_disable_connection\n",
    "        self.p_reenable_parent = p_reenable_parent\n",
    "        self.p_mutate_bias = p_mutate_bias\n",
    "        self.p_mutate_response = p_mutate_response\n",
    "        self.p_mutate_type = p_mutate_type\n",
    "        \n",
    "        # Distance weights\n",
    "        self.distance_excess_weight = distance_excess_weight\n",
    "        self.distance_disjoint_weight = distance_disjoint_weight\n",
    "        self.distance_weight = distance_weight\n",
    "        \n",
    "        # Tuples of: id, non_linearity, bias, layer, ff_order, response\n",
    "        self.neuron_genes = []\n",
    "        # Tuples of: innovation number, input, output, weight, enabled\n",
    "        self.connection_genes = {}\n",
    "        # Hyperparameter genes\n",
    "        self.hyperparameter_genes = []\n",
    "        \n",
    "        self.input_keys = []\n",
    "        self.output_keys = []\n",
    "        \n",
    "        self._initialise_topology(topology)\n",
    "    \n",
    "    def change_specie(self,specie):\n",
    "        self.specie = specie\n",
    "        \n",
    "    def _initialise_topology(self, topology):\n",
    "#         if self.bias_as_node:\n",
    "#             self.inputs += 1\n",
    "        \n",
    "        self.max_layer = 2048 if (self.max_depth is None) else (self.max_depth - 1)\n",
    "        \n",
    "        if topology is None:\n",
    "            # Initialise inputs\n",
    "            for i in range(self.inputs):\n",
    "                self.neuron_genes.append([i, random.choice(self.nonlinearities),1.0,0, i * 2048, self.response_default])\n",
    "                self.input_keys.append(i)\n",
    "            # Initialise outputs\n",
    "            for i in range(self.outputs):\n",
    "                self.neuron_genes.append([(self.inputs + i), random.choice(self.nonlinearities),1.0,self.max_layer, (self.inputs + i) * 2048, self.response_default])\n",
    "                self.output_keys.append((self.inputs + i))\n",
    "            # Initialise connections\n",
    "            innovation_number = 0\n",
    "            for i in range(self.inputs):\n",
    "                for j in range(self.inputs,self.inputs + self.outputs):\n",
    "                    weight = self._initialise_weight(self.inputs,self.outputs)\n",
    "                    self.connection_genes[(i,j)] = [innovation_number, i, j, weight ,True]\n",
    "                    innovation_number += 1\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "                \n",
    "    def _initialise_weight(self, input_neurons, output_neurons):\n",
    "        weight = np.random.rand()*np.sqrt(1/(input_neurons + output_neurons))\n",
    "        return weight\n",
    "        \n",
    "    def recombinate(self, other):\n",
    "        child = deepcopy(self)\n",
    "        child.neuron_genes = []\n",
    "        child.connection_genes = {}\n",
    "        \n",
    "        max_neurons = max(len(self.neuron_genes), len(other.neuron_genes))\n",
    "        min_neurons = min(len(self.neuron_genes), len(other.neuron_genes))\n",
    "        \n",
    "        for i in range(max_neurons):\n",
    "            neuron_gene = None\n",
    "            if i < min_neurons:\n",
    "                neuron_gene = random.choice((self.neuron_genes[i], other.neuron_genes[i]))\n",
    "            else:\n",
    "                try:\n",
    "                    neuron_gene = self.neuron_genes[i]\n",
    "                except IndexError:\n",
    "                    neuron_gene = other.neuron_genes[i]\n",
    "            child.neuron_genes.append(deepcopy(neuron_gene))\n",
    "            \n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "        max_innovation_number = max(list(self_connections.keys()) + list(other_connections.keys()))\n",
    "        \n",
    "        for i in range(max_innovation_number + 1):\n",
    "            connection_gene = None\n",
    "            if i in self_connections and i in other_connections:\n",
    "                connection_gene = random.choice((self_connections[i],other_connections[i]))\n",
    "                enabled = self_connections[i][4] and other_connections[i][4]\n",
    "            else:\n",
    "                if i in self_connections:\n",
    "                    connection_gene = self_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "                elif i in other_connections:\n",
    "                    connection_gene = other_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "            if connection_gene is not None:\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])] = deepcopy(connection_gene)\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])][4] = enabled or np.random.rand() < self.p_reenable_parent\n",
    "\n",
    "            def is_feedforward(item):\n",
    "                ((fr, to), cg) = item\n",
    "                return child.neuron_genes[fr][3] < child.neuron_genes[to][3] and child.neuron_genes[fr][4] < child.neuron_genes[to][4]\n",
    "\n",
    "            if self.feedforward:\n",
    "                child.connection_genes = dict(filter(is_feedforward, child.connection_genes.items()))\n",
    "        return child\n",
    "    \n",
    "    def add_neuron(self, maximum_innovation_number, innovations):\n",
    "        possible_to_split = self.connection_genes.keys()\n",
    "            \n",
    "        if self.max_depth is not None:\n",
    "            possible_to_split = [(fr, to) for (fr, to) in possible_to_split if self.neuron_genes[fr][3] + 1 < self.neuron_genes[to][3]]\n",
    "        else:\n",
    "            possible_to_split = list(possible_to_split)\n",
    "        #possible_to_split = [(fr,to) for (fr, to) in possible_to_split if self.neuron_genes[fr][3] + 1 < self.neuron_genes[to][3]]\n",
    "        \n",
    "        \n",
    "        if possible_to_split:\n",
    "            # Choose connection to split\n",
    "            split_neuron = self.connection_genes[random.choice(possible_to_split)]\n",
    "            # Disable old connection\n",
    "            split_neuron[4] = False\n",
    "\n",
    "            input_neuron, output_neuron, weight = split_neuron[1:4]\n",
    "            fforder = (self.neuron_genes[input_neuron][4] + self.neuron_genes[output_neuron][4]) * 0.5\n",
    "            nonlinearity = random.choice(self.nonlinearities)\n",
    "            layer = self.neuron_genes[input_neuron][3] + 1\n",
    "            \n",
    "\n",
    "            new_id = len(self.neuron_genes)\n",
    "\n",
    "            neuron = [new_id, nonlinearity, 1.0, layer, fforder, self.response_default]\n",
    "\n",
    "            self.neuron_genes.append(neuron)\n",
    "\n",
    "            if (input_neuron, new_id) in innovations:\n",
    "                innovation_number = innovations[(input_neuron,new_id)]\n",
    "            else:\n",
    "                maximum_innovation_number += 1\n",
    "                innovation_number = innovations[(input_neuron,new_id)] = maximum_innovation_number\n",
    "\n",
    "            # 1.0 to initialise_weight?\n",
    "            self.connection_genes[(input_neuron, new_id)] = [innovation_number, input_neuron, new_id, 1.0, True]\n",
    "\n",
    "            if (new_id, output_neuron) in innovations:\n",
    "                innovation_number = innovations[(new_id, output_neuron)]\n",
    "            else:\n",
    "                maximum_innovation_number += 1\n",
    "                innovation_number = innovations[(new_id, output_neuron)] = maximum_innovation_number\n",
    "\n",
    "            self.connection_genes[(new_id, output_neuron)] = [innovation_number, new_id, output_neuron, weight, True]\n",
    "    \n",
    "    def add_connection(self, maximum_innovation_number, innovations):\n",
    "        potential_connections = product(range(len(self.neuron_genes)),range(self.inputs, len(self.neuron_genes)))\n",
    "        potential_connections = (connection for connection in potential_connections if connection not in self.connection_genes)\n",
    "\n",
    "        if self.feedforward:\n",
    "            potential_connections = ((f, t) for (f, t) in potential_connections if self.neuron_genes[f][3] < self.neuron_genes[t][3] and self.neuron_genes[f][4] < self.neuron_genes[t][4])\n",
    "\n",
    "        potential_connections = list(potential_connections)\n",
    "        \n",
    "        if potential_connections:\n",
    "            (fr, to) = random.choice(potential_connections)\n",
    "            if (fr, to) in innovations:\n",
    "                innovation = innovations[(fr, to)]\n",
    "            else:\n",
    "                maximum_innovation_number += 1\n",
    "                innovation = innovations[(fr, to)] = maximum_innovation_number\n",
    "            # get number of neurons in layers of fr and to\n",
    "            connection_gene = [innovation, fr, to, self._initialise_weight(2,2), True]\n",
    "            self.connection_genes[(fr, to)] = connection_gene\n",
    "    \n",
    "    def mutate(self, innovations = {}, global_innovation_number = 0):\n",
    "        \n",
    "        maximum_innovation_number = max(global_innovation_number, max(cg[0] for cg in self.connection_genes.values()))\n",
    "        # TODO: move to separate functions\n",
    "        if len(self.neuron_genes) < self.max_nodes and np.random.rand() < self.p_add_neuron:\n",
    "            self.add_neuron(maximum_innovation_number, innovations)\n",
    "                \n",
    "        elif np.random.rand() < self.p_add_connection:\n",
    "            self.add_connection(global_innovation_number, innovations)\n",
    "            \n",
    "        else:\n",
    "            for cg in self.connection_genes.values():\n",
    "                if np.random.rand() < self.p_mutate_weight:\n",
    "                    cg[3] += np.random.normal(0.0, self.stdev_mutate_weight)\n",
    "                    cg[3] = np.clip(cg[3], self.weight_range[0], self.weight_range[1])\n",
    "                    # clipping?\n",
    "                if np.random.rand() < self.p_reset_weight:\n",
    "                    cg[3] = np.random.normal(0.0,self.stdev_mutate_weight)\n",
    "                    \n",
    "                # bigger chance to disable in this way\n",
    "                if np.random.rand() < self.p_reenable_connection:\n",
    "                    cg[4] = True\n",
    "                    \n",
    "                if np.random.rand() < self.p_disable_connection:\n",
    "                    cg[4] = False\n",
    "                    \n",
    "            for neuron_gene in self.neuron_genes[self.inputs:]:\n",
    "                if np.random.rand() < self.p_mutate_bias:\n",
    "                    neuron_gene[2] += np.random.normal(0.0, 1)\n",
    "\n",
    "                    neuron_gene[2] = np.clip(neuron_gene[2], self.weight_range[0], self.weight_range[1])\n",
    "                \n",
    "                if np.random.rand() < self.p_mutate_type:\n",
    "                    neuron_gene[1] = random.choice(self.nonlinearities)\n",
    "                    \n",
    "                if np.random.rand() < self.p_mutate_response:\n",
    "                    neuron_gene[5] += np.random.normal(0.0, self.stdev_mutate_response)\n",
    "                    \n",
    "        return self\n",
    "        \n",
    "    def distance(self, other):\n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "\n",
    "        all_innovations = list(self_connections.keys()) + list(other_connections.keys())\n",
    "\n",
    "        minimum_innovation = min(all_innovations)\n",
    "        \n",
    "        e = 0\n",
    "        d = 0\n",
    "        w = 0.0\n",
    "        m = 0\n",
    "        \n",
    "        for innovation_key in all_innovations:\n",
    "            if innovation_key in self_connections and innovation_key in other_connections:\n",
    "                w += np.abs(self_connections[innovation_key][3] - other_connections[innovation_key][3])\n",
    "                m += 1\n",
    "            elif innovation_key in self_connections or innovation_key in other_connections:\n",
    "                # Disjoint genes\n",
    "                if innovation_key < minimum_innovation:\n",
    "                    d += 1\n",
    "                # Excess genes\n",
    "                else:\n",
    "                    e += 1\n",
    "                    \n",
    "        # Average weight differences of matching genes\n",
    "        w = (w/m) if m>0 else w\n",
    "        \n",
    "        return (self.distance_excess_weight * e +\n",
    "               self.distance_disjoint_weight * d +\n",
    "               self.distance_weight * w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species(object):\n",
    "    def __init__(self, initial_member):\n",
    "        self.name = next(new_specie_name)\n",
    "        self.members = [initial_member]\n",
    "        self.representative = initial_member\n",
    "        self.offspring = 0\n",
    "        self.age = 0\n",
    "        self.average_fitness = 0.\n",
    "        self.max_fitness = 0.\n",
    "        self.max_fitness_previous = 0.0\n",
    "        self.stagnation = 0\n",
    "        self.has_best = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_individual(item):\n",
    "    (individual, evaluator) = item\n",
    "    if callable(evaluator):\n",
    "        individual.stats = evaluator(individual)\n",
    "    elif hasattr(evaluator, 'evaluate'):\n",
    "        individual.stats = evaluator.evaluate(individual)\n",
    "    else:\n",
    "        raise Exception(\"Evaluator must be a callable or object\" \\\n",
    "                    \"with a callable attribute 'evaluate'.\")\n",
    "    return individual\n",
    "\n",
    "class Population(object):\n",
    "    def __init__(self, genome_factory,\n",
    "                population_size = 100,\n",
    "                elitism = True,\n",
    "                stop_when_solved = False,\n",
    "                tournament_selection_k = 3,\n",
    "                verbose = True,\n",
    "                max_cores = 1,\n",
    "                compatibility_threshold = 3.0,\n",
    "                compatibility_threshold_delta = 0.4,\n",
    "                target_species = 12,\n",
    "                minimum_elitism_size = 5,\n",
    "                young_age = 10,\n",
    "                young_multiplier = 1.2,\n",
    "                old_age = 30,\n",
    "                old_multiplier = 0.2,\n",
    "                stagnation_age = 15,\n",
    "                reset_innovations = False,\n",
    "                survival = 0.2):\n",
    "        \n",
    "        self.genome_factory = genome_factory\n",
    "        self.population_size = population_size\n",
    "        self.elitism = elitism\n",
    "        self.stop_when_solved = stop_when_solved\n",
    "        self.tournament_selection_k = tournament_selection_k\n",
    "        self.verbose = verbose\n",
    "        self.max_cores = max_cores\n",
    "        \n",
    "        cpus = multiprocessing.cpu_count()\n",
    "        use_cores = min(self.max_cores, cpus-1)\n",
    "        if use_cores > 1:\n",
    "            self.pool = multiprocessing.Pool(processes=use_cores, maxtasksperchild=5)\n",
    "        else:\n",
    "            self.pool = None\n",
    "        \n",
    "        self.compatibility_threshold = compatibility_threshold\n",
    "        self.compatibility_threshold_delta = compatibility_threshold_delta\n",
    "        \n",
    "        self.target_species = target_species\n",
    "        self.minimum_elitism_size = minimum_elitism_size\n",
    "        \n",
    "        self.young_age = young_age\n",
    "        self.young_multiplier = young_multiplier\n",
    "        self.old_age = old_age\n",
    "        self.old_multiplier = old_multiplier\n",
    "        \n",
    "        self.stagnation_age = stagnation_age\n",
    "        \n",
    "        self.reset_innovations = reset_innovations\n",
    "        self.survival = survival\n",
    "        \n",
    "    def _evaluate_all(self, population, evaluator):\n",
    "        to_eval = [(individual, evaluator) for individual in population]\n",
    "        if self.pool is not None:\n",
    "            population = list(self.pool.map(evaluate_individual, to_eval))\n",
    "        else:\n",
    "            population = list(map(evaluate_individual, to_eval))\n",
    "        \n",
    "        return population\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.champions = []\n",
    "        self.generation = 0\n",
    "        self.solved_at = None\n",
    "        self.stats = defaultdict(list)\n",
    "        self.species = []\n",
    "        self.global_innovation_number = 0\n",
    "        self.innovations = {}\n",
    "        self.current_compatibility_threshold = self.compatibility_threshold\n",
    "        \n",
    "    def _find_best(self, population, solution = None):\n",
    "        self.champions.append(max(population, key=lambda individual: individual.stats['fitness']))\n",
    "        \n",
    "        if solution is not None:\n",
    "            if isinstance(solution, (int, float)):\n",
    "                solved = (self.champions[-1].stats['fitness'] >= solution)\n",
    "            elif callable(solution):\n",
    "                solved = solution(self.champions[-1])\n",
    "            elif hasattr(solution, 'solve'):\n",
    "                solved = solution.solve(self.champions[-1])\n",
    "                \n",
    "            if solved and self.solved_at is None:\n",
    "                self.solved_at = self.generation + 1\n",
    "            \n",
    "    @property\n",
    "    def population(self):\n",
    "        for specie in self.species:\n",
    "            for member in specie.members:\n",
    "                yield member\n",
    "    \n",
    "    def _evolve(self, evaluator, solution=None):\n",
    "        population = list(self.population)\n",
    "        \n",
    "        while len(population) < self.population_size:\n",
    "            individual = self.genome_factory()\n",
    "            population.append(individual)        \n",
    "            \n",
    "        population = self._evaluate_all(population, evaluator)\n",
    "        \n",
    "        # Speciation\n",
    "        for specie in self.species:\n",
    "            # Choose random specie representative for distance comparison\n",
    "            specie.representative = random.choice(specie.members)\n",
    "            specie.name = specie.representative.specie\n",
    "            specie.members = []\n",
    "            specie.age += 1\n",
    "            \n",
    "        # Add each individual to a species\n",
    "        for individual in population:\n",
    "            found = False\n",
    "            for specie in self.species:\n",
    "                if individual.distance(specie.representative) <= self.current_compatibility_threshold:\n",
    "                    specie.members.append(individual)\n",
    "                    individual.change_specie(specie.name)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                s = Species(individual)\n",
    "                individual.change_specie(s.name)\n",
    "                self.species.append(s)\n",
    "        \n",
    "        # Remove empty species\n",
    "        self.species = list(filter(lambda s: len(s.members) > 0, self.species))\n",
    "        \n",
    "        # Adjust compatibility threshold\n",
    "        if len(self.species) < self.target_species:\n",
    "            self.current_compatibility_threshold -= self.compatibility_threshold_delta\n",
    "        elif len(self.species) > self.target_species:\n",
    "            self.current_compatibility_threshold += self.compatibility_threshold_delta\n",
    "        \n",
    "        # Find champion and check for solution\n",
    "        self._find_best(population, solution)\n",
    "        \n",
    "        # Recombination\n",
    "        \n",
    "        for specie in self.species:\n",
    "            specie.max_fitness_previous = specie.max_fitness\n",
    "            specie.average_fitness = np.mean([individual.stats['fitness'] for individual in specie.members])\n",
    "            specie.max_fitness = np.max([individual.stats['fitness'] for individual in specie.members])\n",
    "            if specie.max_fitness <= specie.max_fitness_previous:\n",
    "                specie.stagnation += 1\n",
    "            else:\n",
    "                specie.stagnation = 0\n",
    "            specie.has_best = self.champions[-1] in specie.members\n",
    "        \n",
    "        # Keep species that have the best or within stagnation age range\n",
    "        self.species = list(filter(lambda s: s.stagnation < self.stagnation_age or s.has_best, self.species))\n",
    "        \n",
    "        average_fitness = np.array([specie.average_fitness for specie in self.species])\n",
    "        \n",
    "        # Adjust fitness based on age\n",
    "        age = np.array([specie.age for specie in self.species])\n",
    "        for specie in self.species:\n",
    "            if specie.age < self.young_age:\n",
    "                specie.average_fitness *= self.young_multiplier\n",
    "            if specie.age > self.old_age:\n",
    "                specie.average_fitness *= self.old_multiplier\n",
    "                \n",
    "        # Compute offspring size\n",
    "        total_fitness = sum(specie.average_fitness for specie in self.species)\n",
    "        for specie in self.species:\n",
    "            specie.offspring = int(round(self.population_size * specie.average_fitness / total_fitness))\n",
    "            \n",
    "        \n",
    "        \n",
    "        # Remove species without offspring\n",
    "        self.species = list(filter(lambda s: s.offspring > 0, self.species))\n",
    "\n",
    "        for specie in self.species:\n",
    "            specie.members.sort(key=lambda individual: individual.stats['fitness'], reverse = True)\n",
    "            keep = max(1, int(round(len(specie.members)*self.survival)))\n",
    "            pool = specie.members[:keep]\n",
    "            \n",
    "            if self.elitism and len(specie.members) > self.minimum_elitism_size:\n",
    "                specie.members = specie.members[:1]\n",
    "            else:\n",
    "                specie.members = []\n",
    "                \n",
    "            while len(specie.members) < specie.offspring:\n",
    "                k = min(len(pool), self.tournament_selection_k)\n",
    "                p1 = max(random.sample(pool,k), key=lambda individual: individual.stats['fitness'])\n",
    "                p2 = max(random.sample(pool,k), key=lambda individual: individual.stats['fitness'])\n",
    "                \n",
    "                child = p1.recombinate(p2)\n",
    "                child.mutate(innovations=self.innovations, global_innovation_number = self.global_innovation_number)\n",
    "                specie.members.append(child)\n",
    "                \n",
    "        if self.innovations:\n",
    "            self.global_innovation_number = max(self.innovations.values())\n",
    "            \n",
    "        self._gather_stats(population)\n",
    "            \n",
    "    def epoch(self, evaluator, generations, solution=None, reset=True, callback= None):\n",
    "        if reset:\n",
    "            self._reset()\n",
    "            \n",
    "        for i in range(generations):\n",
    "            self.time = time.time()\n",
    "            self._evolve(evaluator, solution)\n",
    "            self.generation += 1\n",
    "            \n",
    "            if self.verbose:\n",
    "                self._status_report()\n",
    "                \n",
    "            if callback is not None:\n",
    "                callback(self)\n",
    "            \n",
    "            if self.solved_at is not None and self.stop_when_solved:\n",
    "                break\n",
    "        \n",
    "        return {'stats': self.stats, 'champions': self.champions}\n",
    "    \n",
    "    def _gather_stats(self, population):\n",
    "        for key in population[0].stats:\n",
    "            self.stats[key+'_avg'].append(np.mean([individual.stats[key] for individual in population]))\n",
    "            self.stats[key+'_max'].append(np.max([individual.stats[key] for individual in population]))\n",
    "            self.stats[key+'_min'].append(np.min([individual.stats[key] for individual in population]))\n",
    "        self.stats['solved'].append( self.solved_at is not None )\n",
    "    \n",
    "    def _status_report(self):\n",
    "        print(\"\\n****** Running Generation %d ******\" % self.generation)\n",
    "        print(\"****** Difficulty %d ******\" % self.champions[-1].stats['info'])\n",
    "        fitness_list = np.array([i.stats['fitness'] for i in self.population])\n",
    "        number_neurons = len(self.champions[-1].neuron_genes)\n",
    "        number_enabled_connections = np.sum([1 for conn in self.champions[-1].connection_genes.values() if conn[4]])\n",
    "        print(\"Population's average fitness: %.5f stdev: %.5f\" % (np.average(fitness_list), np.std(fitness_list)))\n",
    "        print(\"Best individual: %s %s\" % (self.champions[-1].name, self.champions[-1].specie))\n",
    "        print(\"Best fitness: %.2f - #neurons: %i - #enabled connections: %i\" % (self.champions[-1].stats['fitness'],number_neurons,number_enabled_connections))\n",
    "        print(\"Population of %i members in %i species:\" % (len(list(self.population)), len(self.species)))\n",
    "        print(\"Species         age    size    fitness    stag\")\n",
    "        print(\"============    ===    ====    =======    ====\")\n",
    "        for specie in self.species:\n",
    "            print(\"{: >12}    {: >3}    {: >4}    {:.5f}    {: >4}\".format(specie.name,specie.age,len(specie.members),specie.max_fitness,specie.stagnation))\n",
    "        print(\"Generation time: %d seconds\" % (time.time()-self.time))\n",
    "        print(\"Solved in generation: %s\" % (self.solved_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_from_coo(shape, conns, dtype=torch.float64):\n",
    "    mat = torch.zeros(shape, dtype=dtype)\n",
    "    idxs, weights, activations = conns\n",
    "    if len(idxs) == 0:\n",
    "        return mat, activations\n",
    "    rows, cols = np.array(idxs).transpose()\n",
    "    mat[torch.tensor(rows), torch.tensor(cols)] = torch.tensor(\n",
    "        weights, dtype=dtype)\n",
    "    return mat, activations\n",
    "\n",
    "class MaskedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, mask =  None, weights = None, bias = None):\n",
    "        super(MaskedLinear, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias = False)\n",
    "        \n",
    "        if mask is None:\n",
    "            mask = torch.ones((out_features, in_features))\n",
    "            \n",
    "        if weights is not None:\n",
    "            self.linear.weight.data = weights\n",
    "            \n",
    "#         if bias is not None:\n",
    "#             self.linear.bias.data = bias\n",
    "            \n",
    "        self.linear.weight.data *= mask\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def required_for_output(inputs, outputs, connections):\n",
    "    \"\"\"\n",
    "    Collect the nodes whose state is required to compute the final network output(s).\n",
    "    :param inputs: list of the input identifiers\n",
    "    :param outputs: list of the output node identifiers\n",
    "    :param connections: list of (input, output) connections in the network.\n",
    "    NOTE: It is assumed that the input identifier set and the node identifier set are disjoint.\n",
    "    By convention, the output node ids are always the same as the output index.\n",
    "    Returns a set of identifiers of required nodes.\n",
    "    \"\"\"\n",
    "    required = set(outputs)\n",
    "    s = set(outputs)\n",
    "    while 1:\n",
    "        # Find nodes not in S whose output is consumed by a node in s.\n",
    "        t = set(a for (a, b) in connections if b in s and a not in s)\n",
    "\n",
    "        if not t:\n",
    "            break\n",
    "\n",
    "        layer_nodes = set(x for x in t if x not in inputs)\n",
    "        if not layer_nodes:\n",
    "            break\n",
    "\n",
    "        required = required.union(layer_nodes)\n",
    "        s = s.union(t)\n",
    "\n",
    "    return list(required)\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs,\n",
    "                 input_to_hidden, hidden_to_hidden, output_to_hidden,\n",
    "                 input_to_output, hidden_to_output, output_to_output,\n",
    "                 hidden_responses, output_responses,\n",
    "                 hidden_biases, output_biases,\n",
    "                 batch_size=1,\n",
    "                 activation = 'relu',\n",
    "                 use_current_activs=False,\n",
    "                 n_internal_steps=1,\n",
    "                 dtype=torch.float32):\n",
    "\n",
    "        self.use_current_activs = use_current_activs\n",
    "        self.activation = string_to_activation[activation]\n",
    "        self.n_internal_steps = n_internal_steps\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.output_responses = torch.tensor(output_responses, dtype=dtype)\n",
    "        self.output_biases = torch.tensor(output_biases, dtype=dtype)\n",
    "            \n",
    "        self.input_to_output, self.i2o_nonlinearity = dense_from_coo((n_outputs, n_inputs), input_to_output, dtype=dtype)\n",
    "        self.output_to_output, self.o2o_nonlinearity = dense_from_coo((n_outputs, n_outputs), output_to_output, dtype=dtype)\n",
    "        \n",
    "        if n_hidden > 0:\n",
    "            self.hidden_responses = torch.tensor(hidden_responses, dtype=dtype)\n",
    "            self.hidden_biases = torch.tensor(hidden_biases, dtype=dtype)\n",
    "        \n",
    "        if n_hidden > 0:\n",
    "            self.input_to_hidden, self.i2h_nonlinearity = dense_from_coo((n_hidden, n_inputs), input_to_hidden, dtype=dtype)\n",
    "            self.hidden_to_hidden, self.h2hnonlinearity = dense_from_coo((n_hidden, n_hidden), hidden_to_hidden, dtype=dtype)\n",
    "            self.output_to_hidden, self.o2h_nonlinearity = dense_from_coo((n_hidden, n_outputs), output_to_hidden, dtype=dtype)\n",
    "            self.hidden_to_output, self.h2o_nonlinearity = dense_from_coo((n_outputs, n_hidden), hidden_to_output, dtype=dtype)\n",
    "            \n",
    "            self.lin_input_to_hidden = MaskedLinear(n_inputs, n_hidden, weights = self.input_to_hidden, bias = self.hidden_biases)\n",
    "            self.lin_hidden_to_hidden = MaskedLinear(n_hidden, n_hidden, weights = self.hidden_to_hidden, bias = self.hidden_biases)\n",
    "            self.lin_output_to_hidden = MaskedLinear(n_outputs, n_hidden, weights = self.output_to_hidden, bias = self.hidden_biases)\n",
    "            self.lin_hidden_to_output = MaskedLinear(n_hidden, n_outputs, weights = self.hidden_to_output, bias = self.output_biases)\n",
    "        \n",
    "        self.lin_input_to_output = MaskedLinear(n_inputs, n_outputs, weights = self.input_to_output, bias = self.output_biases)\n",
    "        self.lin_output_to_output = MaskedLinear(n_outputs, n_outputs, weights = self.output_to_output, bias = self.output_biases)\n",
    "\n",
    "        self.reset(batch_size)\n",
    "\n",
    "    def reset(self, batch_size=1):\n",
    "        if self.n_hidden > 0:\n",
    "            self.activs = torch.zeros(\n",
    "                batch_size, self.n_hidden, dtype=self.dtype)\n",
    "        else:\n",
    "            self.activs = None\n",
    "        self.outputs = torch.zeros(\n",
    "            batch_size, self.n_outputs, dtype=self.dtype)\n",
    "        \n",
    "    def activate(self, inputs):\n",
    "        '''\n",
    "        inputs: (batch_size, n_inputs)\n",
    "        returns: (batch_size, n_outputs)\n",
    "        '''\n",
    "        inputs = torch.tensor(inputs, dtype=self.dtype, requires_grad=True)\n",
    "        print('i2h',self.i2h_nonlinearity)\n",
    "        print('i2o',self.i2o_nonlinearity)\n",
    "        print(inputs)\n",
    "        \n",
    "        activs_for_output = self.activs\n",
    "        if self.n_hidden > 0:\n",
    "            for _ in range(self.n_internal_steps):\n",
    "#                 print(self.input_to_hidden.mm(inputs.t()).t() + self.hidden_biases)\n",
    "#                 print(self.lin_input_to_hidden(inputs) + self.hidden_biases)\n",
    "#                 raise NotImplementedError\n",
    "#                 self.activs = self.activation(self.hidden_responses * (\n",
    "#                     self.input_to_hidden.mm(inputs.t()).t() +\n",
    "#                     self.hidden_to_hidden.mm(self.activs.t()).t() +\n",
    "#                     self.output_to_hidden.mm(self.outputs.t()).t()) +\n",
    "#                     self.hidden_biases)\n",
    "\n",
    "#                 input_nonlinearities = [string_to_activation[neuron_gene[1]] for neuron_gene in self.layers[0]]\n",
    "#                 input_after_non_linearity = torch.cat(([input_nonlinearities[i](input_x).view(1) for i, input_x in enumerate(original_input)]), dim = 0)\n",
    "                print('i2h',self.lin_input_to_hidden(inputs))\n",
    "                print('i2o',self.lin_input_to_output(inputs))\n",
    "                \n",
    "                self.activs = self.activation(self.hidden_responses * (\n",
    "                    self.lin_input_to_hidden(inputs) +\n",
    "                    self.lin_hidden_to_hidden(self.activs) +\n",
    "                    self.lin_output_to_hidden(self.outputs)\n",
    "                ) + self.hidden_biases)\n",
    "            if self.use_current_activs:\n",
    "                activs_for_output = self.activs\n",
    "\n",
    "#         output_inputs = (self.input_to_output.mm(inputs.t()).t() +\n",
    "#                          self.output_to_output.mm(self.outputs.t()).t())\n",
    "        output_inputs = self.lin_input_to_output(inputs) + self.lin_output_to_output(self.outputs)\n",
    "        if self.n_hidden > 0:\n",
    "#             output_inputs += self.hidden_to_output.mm(\n",
    "#                 activs_for_output.t()).t()\n",
    "            output_inputs += self.lin_hidden_to_output(activs_for_output)\n",
    "        self.outputs = self.activation(\n",
    "            self.output_responses * output_inputs + self.output_biases)\n",
    "            \n",
    "        return self.outputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def create(genome, batch_size = 1, activation = 'tanh', use_current_activs = False, n_internal_steps = 1):\n",
    "        # Only use node that are connected tot the output.\n",
    "        required = required_for_output(genome.input_keys, genome.output_keys, genome.connection_genes)\n",
    "        \n",
    "        # Make list of input, hidden and output keys\n",
    "        input_keys = genome.input_keys\n",
    "        hidden_keys = [k[0] for k in genome.neuron_genes if k[0] not in genome.output_keys and k[0] not in genome.input_keys]\n",
    "        output_keys = genome.output_keys\n",
    "        \n",
    "        # Make list of hidden and output reponses\n",
    "        hidden_responses = [genome.neuron_genes[k][5] for k in hidden_keys]\n",
    "        output_responses = [genome.neuron_genes[k][5] for k in output_keys]\n",
    "        \n",
    "        # Make list of hidden and output biases\n",
    "        hidden_biases = [genome.neuron_genes[k][2] for k in hidden_keys]\n",
    "        output_biases = [genome.neuron_genes[k][2] for k in output_keys]\n",
    "        \n",
    "        # Number of inputs\n",
    "        n_inputs = len(input_keys)\n",
    "        n_hidden = len(hidden_keys)\n",
    "        n_outputs = len(output_keys)\n",
    "        \n",
    "        # Key to index\n",
    "        input_key_to_idx = {k: i for i, k in enumerate(input_keys)}\n",
    "        hidden_key_to_idx = {k: i for i, k in enumerate(hidden_keys)}\n",
    "        output_key_to_idx = {k: i for i, k in enumerate(output_keys)}\n",
    "        \n",
    "        def key_to_idx(key):\n",
    "            if key in input_keys:\n",
    "                return input_key_to_idx[key]\n",
    "            elif key in hidden_keys:\n",
    "                return hidden_key_to_idx[key]\n",
    "            elif key in output_keys:\n",
    "                return output_key_to_idx[key]\n",
    "            \n",
    "        input_to_hidden = ([], [], [])\n",
    "        hidden_to_hidden = ([], [], [])\n",
    "        output_to_hidden = ([], [], [])\n",
    "        input_to_output = ([], [], [])\n",
    "        hidden_to_output = ([], [], [])\n",
    "        output_to_output = ([], [], [])\n",
    "        \n",
    "        for connection in genome.connection_genes.values():\n",
    "            if not connection[4]:\n",
    "                continue        \n",
    "            \n",
    "            if connection[2] not in required and connection[1] not in required:\n",
    "                continue\n",
    "            \n",
    "            input_key = connection[1]\n",
    "            output_key = connection[2]\n",
    "                \n",
    "            if input_key in input_keys and output_key in hidden_keys:\n",
    "                idxs, vals, activations = input_to_hidden\n",
    "            elif input_key in hidden_keys and output_key in hidden_keys:\n",
    "                idxs, vals, activations = hidden_to_hidden\n",
    "            elif input_key in output_keys and output_key in hidden_keys:\n",
    "                idxs, vals, activations = output_to_hidden\n",
    "            elif input_key in input_keys and output_key in output_keys:\n",
    "                idxs, vals, activations = input_to_output\n",
    "            elif input_key in hidden_keys and output_key in output_keys:\n",
    "                idxs, vals, activations = hidden_to_output\n",
    "            elif input_key in output_keys and output_key in output_keys:\n",
    "                idxs, vals, activations = output_to_output\n",
    "                \n",
    "            idxs.append((key_to_idx(connection[2]), key_to_idx(connection[1])))  # to, from\n",
    "            vals.append(connection[3])\n",
    "            activations.append(genome.neuron_genes[input_key][1])\n",
    "        \n",
    "        return NeuralNetwork(n_inputs, n_hidden, n_outputs,\n",
    "                            input_to_hidden, hidden_to_hidden, output_to_hidden,\n",
    "                            input_to_output, hidden_to_output, output_to_output,\n",
    "                            hidden_responses, output_responses,\n",
    "                            hidden_biases, output_biases,\n",
    "                            batch_size,\n",
    "                            activation,\n",
    "                            use_current_activs,\n",
    "                            n_internal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'sigmoid', 1.0, 0, 0, 4.924273], [1, 'tanh', 1.0, 0, 2048, 4.924273], [2, 'sigmoid', 1.0, 2048, 4096, 4.924273], [3, 'tanh', 1.0, 1, 2048.0, 4.924273], [4, 'sigmoid', 1.0, 1, 2048.0, 4.924273]]\n",
      "{(0, 2): [0, 0, 2, 0.40884933601461015, False], (1, 2): [1, 1, 2, 0.1679539293199262, True], (0, 3): [2, 0, 3, 1.0, True], (3, 2): [3, 3, 2, 0.40884933601461015, True], (0, 4): [4, 0, 4, 1.0, True], (4, 2): [5, 4, 2, 0.40884933601461015, True]}\n",
      "i2h ['sigmoid', 'sigmoid']\n",
      "i2o ['tanh']\n",
      "tensor([[0., 1.]], requires_grad=True)\n",
      "i2h tensor([[0., 0.]], grad_fn=<MmBackward>)\n",
      "i2o tensor([[0.1680]], grad_fn=<MmBackward>)\n",
      "tensor([[0.9495]], grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"361pt\" height=\"570pt\"\n",
       " viewBox=\"0.00 0.00 360.50 570.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 566)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-566 356.5,-566 356.5,4 -4,4\"/>\n",
       "<!-- 139846904385608 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139846904385608</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"299,-21 209,-21 209,0 299,0 299,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TanhBackward</text>\n",
       "</g>\n",
       "<!-- 139846907220600 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139846907220600</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"304,-78 204,-78 204,-57 304,-57 304,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139846907220600&#45;&gt;139846904385608 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139846907220600&#45;&gt;139846904385608</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254,-56.7787C254,-49.6134 254,-39.9517 254,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.5001,-31.1732 254,-21.1732 250.5001,-31.1732 257.5001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 139846907221720 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139846907221720</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"305,-135 203,-135 203,-114 305,-114 305,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 139846907221720&#45;&gt;139846907220600 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139846907221720&#45;&gt;139846907220600</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254,-113.7787C254,-106.6134 254,-96.9517 254,-88.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.5001,-88.1732 254,-78.1732 250.5001,-88.1732 257.5001,-88.1732\"/>\n",
       "</g>\n",
       "<!-- 139846907222952 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139846907222952</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"303,-192 205,-192 205,-171 303,-171 303,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThMulBackward</text>\n",
       "</g>\n",
       "<!-- 139846907222952&#45;&gt;139846907221720 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139846907222952&#45;&gt;139846907221720</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254,-170.7787C254,-163.6134 254,-153.9517 254,-145.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.5001,-145.1732 254,-135.1732 250.5001,-145.1732 257.5001,-145.1732\"/>\n",
       "</g>\n",
       "<!-- 139846907220040 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139846907220040</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"305,-249 203,-249 203,-228 305,-228 305,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 139846907220040&#45;&gt;139846907222952 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139846907220040&#45;&gt;139846907222952</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254,-227.7787C254,-220.6134 254,-210.9517 254,-202.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.5001,-202.1732 254,-192.1732 250.5001,-202.1732 257.5001,-202.1732\"/>\n",
       "</g>\n",
       "<!-- 139846907223456 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139846907223456</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"304,-306 204,-306 204,-285 304,-285 304,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139846907223456&#45;&gt;139846907220040 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139846907223456&#45;&gt;139846907220040</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M254,-284.7787C254,-277.6134 254,-267.9517 254,-259.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.5001,-259.1732 254,-249.1732 250.5001,-259.1732 257.5001,-259.1732\"/>\n",
       "</g>\n",
       "<!-- 139846907834440 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139846907834440</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"249,-363 149,-363 149,-342 249,-342 249,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThAddBackward</text>\n",
       "</g>\n",
       "<!-- 139846907834440&#45;&gt;139846907223456 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139846907834440&#45;&gt;139846907223456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M209.3451,-341.7787C217.0272,-333.8173 227.6831,-322.7739 236.6589,-313.4717\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.2763,-315.7997 243.7013,-306.1732 234.2389,-310.9391 239.2763,-315.7997\"/>\n",
       "</g>\n",
       "<!-- 139846861762288 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139846861762288</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"145.5,-420 60.5,-420 60.5,-399 145.5,-399 145.5,-420\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139846861762288&#45;&gt;139846907834440 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139846861762288&#45;&gt;139846907834440</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M121.0569,-398.7787C135.4043,-390.26 155.6944,-378.2127 171.9761,-368.5454\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.2124,-371.2881 181.0241,-363.1732 170.6386,-365.2691 174.2124,-371.2881\"/>\n",
       "</g>\n",
       "<!-- 139846861761784 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139846861761784</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-491 0,-491 0,-456 54,-456 54,-491\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-463.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 2)</text>\n",
       "</g>\n",
       "<!-- 139846861761784&#45;&gt;139846861762288 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139846861761784&#45;&gt;139846861762288</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.1702,-455.6724C58.8445,-446.6836 71.7391,-435.825 82.3411,-426.897\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.8713,-429.342 90.2659,-420.2234 80.3623,-423.9876 84.8713,-429.342\"/>\n",
       "</g>\n",
       "<!-- 139846861758648 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139846861758648</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"145.5,-484 72.5,-484 72.5,-463 145.5,-463 145.5,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-470.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139846861758648&#45;&gt;139846861762288 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139846861758648&#45;&gt;139846861762288</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M108.0092,-462.9317C107.1804,-454.0913 105.973,-441.2122 104.9513,-430.3135\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.4305,-429.9275 104.0123,-420.2979 101.4611,-430.581 108.4305,-429.9275\"/>\n",
       "</g>\n",
       "<!-- 139846861760160 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139846861760160</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"136,-562 82,-562 82,-527 136,-527 136,-562\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-534.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 2)</text>\n",
       "</g>\n",
       "<!-- 139846861760160&#45;&gt;139846861758648 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139846861760160&#45;&gt;139846861758648</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M109,-526.9494C109,-517.058 109,-504.6435 109,-494.2693\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"112.5001,-494.0288 109,-484.0288 105.5001,-494.0289 112.5001,-494.0288\"/>\n",
       "</g>\n",
       "<!-- 139846861759152 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>139846861759152</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"248.5,-420 163.5,-420 163.5,-399 248.5,-399 248.5,-420\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139846861759152&#45;&gt;139846907834440 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139846861759152&#45;&gt;139846907834440</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M204.6834,-398.7787C203.8034,-391.6134 202.6169,-381.9517 201.5556,-373.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"205.0036,-372.672 200.3107,-363.1732 198.0558,-373.5253 205.0036,-372.672\"/>\n",
       "</g>\n",
       "<!-- 139846861760216 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>139846861760216</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"242.5,-484 169.5,-484 169.5,-463 242.5,-463 242.5,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-470.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139846861760216&#45;&gt;139846861759152 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>139846861760216&#45;&gt;139846861759152</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M206,-462.9317C206,-454.0913 206,-441.2122 206,-430.3135\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.5001,-430.2979 206,-420.2979 202.5001,-430.2979 209.5001,-430.2979\"/>\n",
       "</g>\n",
       "<!-- 139846861761728 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>139846861761728</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"233,-562 179,-562 179,-527 233,-527 233,-562\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-534.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 1)</text>\n",
       "</g>\n",
       "<!-- 139846861761728&#45;&gt;139846861760216 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>139846861761728&#45;&gt;139846861760216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M206,-526.9494C206,-517.058 206,-504.6435 206,-494.2693\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.5001,-494.0288 206,-484.0288 202.5001,-494.0289 209.5001,-494.0288\"/>\n",
       "</g>\n",
       "<!-- 139846861759824 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>139846861759824</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"352.5,-363 267.5,-363 267.5,-342 352.5,-342 352.5,-363\"/>\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139846861759824&#45;&gt;139846907223456 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>139846861759824&#45;&gt;139846907223456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M299.4668,-341.7787C291.645,-333.8173 280.7954,-322.7739 271.6564,-313.4717\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"273.9909,-310.8537 264.4859,-306.1732 268.9975,-315.7595 273.9909,-310.8537\"/>\n",
       "</g>\n",
       "<!-- 139846861761560 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>139846861761560</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"346.5,-420 273.5,-420 273.5,-399 346.5,-399 346.5,-420\"/>\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-406.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139846861761560&#45;&gt;139846861759824 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>139846861761560&#45;&gt;139846861759824</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M310,-398.7787C310,-391.6134 310,-381.9517 310,-373.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.5001,-373.1732 310,-363.1732 306.5001,-373.1732 313.5001,-373.1732\"/>\n",
       "</g>\n",
       "<!-- 139846861761056 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>139846861761056</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"337,-491 283,-491 283,-456 337,-456 337,-491\"/>\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-463.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 2)</text>\n",
       "</g>\n",
       "<!-- 139846861761056&#45;&gt;139846861761560 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>139846861761056&#45;&gt;139846861761560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M310,-455.6724C310,-447.8405 310,-438.5893 310,-430.4323\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.5001,-430.2234 310,-420.2234 306.5001,-430.2235 313.5001,-430.2234\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f30a50f12e8>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "random.seed(3)\n",
    "\n",
    "genome = Genotype(2,1)\n",
    "genome.add_neuron(1,{(0,2):0,(1,2):1})\n",
    "genome.add_neuron(3,{(0,2):0,(1,2):1,(0,3):2,(3,2):3})\n",
    "#genome.add_neuron(5,{(0,2):0,(1,2):1,(0,3):2,(3,2):3,(1,4):4,(4,3):5})\n",
    "print(genome.neuron_genes)\n",
    "print(genome.connection_genes)\n",
    "\n",
    "network = NeuralNetwork.create(genome)\n",
    "output = network.activate(np.array([[0,1]]))\n",
    "print(output)\n",
    "make_dot(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORTask(object):\n",
    "    \n",
    "    # Default XOR input/output pairs\n",
    "    INPUTS  = [(0,0), (0,1), (1,0), (1,1)]\n",
    "    OUTPUTS = [(-1,), (1,), (1,), (-1,)]\n",
    "    EPSILON = 1e-100\n",
    "    \n",
    "    def __init__(self, do_all=True):\n",
    "        self.do_all = do_all\n",
    "        self.INPUTS = np.array(self.INPUTS, dtype=float)\n",
    "        self.OUTPUTS = np.array(self.OUTPUTS, dtype=float)\n",
    "    \n",
    "    def evaluate(self, network, verbose=False):\n",
    "        if not isinstance(network, NeuralNetwork):\n",
    "            network = NeuralNetwork.create(network)\n",
    "            \n",
    "#             network = NeuralNetwork2(network)\n",
    "        \n",
    "        pairs = list(zip(self.INPUTS, self.OUTPUTS))\n",
    "        random.shuffle(pairs)\n",
    "        if not self.do_all:\n",
    "            pairs = [random.choice(pairs)]\n",
    "        rmse = 0.0\n",
    "        for (i, target) in pairs:\n",
    "            # Feed with bias\n",
    "#             output = network(torch.Tensor(i))\n",
    "            output = network.activate(np.array([i]))\n",
    "            err = (target - output.item())\n",
    "            err[abs(err) < self.EPSILON] = 0;\n",
    "            err = (err ** 2).mean()\n",
    "            # Add error\n",
    "            if verbose:\n",
    "                print(\"%r -> %r (%.2f)\" % (i, output, err))\n",
    "            rmse += err \n",
    "\n",
    "        score = 1/(1+np.sqrt(rmse / len(pairs)))\n",
    "        return {'fitness': score, 'info' : 0}\n",
    "        \n",
    "    def solve(self, network):\n",
    "        return int(self.evaluate(network)['fitness'] > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RubiksTask(object):\n",
    "    def __init__(self):\n",
    "        self.difficulty = 1\n",
    "        self.env = rubiks.RubiksEnv(2)\n",
    "    \n",
    "    def _increase_difficulty(self):\n",
    "        self.difficulty += 1\n",
    "    \n",
    "    def evaluate(self, network, verbose=False):\n",
    "        if not isinstance(network, NeuralNetwork):\n",
    "            network = NeuralNetwork.create(network)\n",
    "        \n",
    "        fitness = 0.000001\n",
    "        \n",
    "        for i in range(100):\n",
    "            done = False\n",
    "            tries = 0\n",
    "            \n",
    "            max_tries = self.difficulty\n",
    "            state = self.env.reset(self.difficulty)\n",
    "            \n",
    "            while tries < max_tries and not done:\n",
    "\n",
    "                action_probabilities = network.activate(np.array([state]))\n",
    "                action = np.argmax(action_probabilities)\n",
    "                \n",
    "                next_state, reward, done, info = self.env.step(int(action))\n",
    "                \n",
    "                tries += 1\n",
    "                state = next_state\n",
    "            if done:\n",
    "                fitness += 1.0\n",
    "                \n",
    "        fitness = fitness / 100\n",
    "        \n",
    "        if fitness > 0.7:\n",
    "            self._increase_difficulty()\n",
    "        \n",
    "        return {'fitness' : fitness, 'info' : self.difficulty}\n",
    "        \n",
    "    def solve(self, network):\n",
    "        return int(self.evaluate(network)['fitness'] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 2\n",
    "outputs = 1\n",
    "nonlinearities = ['tanh','relu','sigmoid']\n",
    "topology = None\n",
    "feedforward = False\n",
    "max_depth = None\n",
    "max_nodes = float('inf')\n",
    "response_default = 4.924273\n",
    "bias_as_node = False\n",
    "initial_weight_stdev = 2.0\n",
    "p_add_neuron = 0.03\n",
    "p_add_connection = 0.3\n",
    "p_mutate_weight = 0.8\n",
    "p_reset_weight = 0.1\n",
    "p_reenable_connection = 0.01\n",
    "p_disable_connection = 0.01\n",
    "p_reenable_parent=0.25\n",
    "p_mutate_bias = 0.2\n",
    "p_mutate_response = 0.0\n",
    "p_mutate_type = 0.2\n",
    "stdev_mutate_weight = 1.5\n",
    "stdev_mutate_bias = 0.5\n",
    "stdev_mutate_response = 0.5\n",
    "weight_range = (-50.,50.)\n",
    "\n",
    "distance_excess_weight = 1.0\n",
    "distance_disjoint_weight = 1.0\n",
    "distance_weight = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Running Generation 1 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.43195 stdev: 0.00307\n",
      "Best individual: vaughn kue\n",
      "Best fitness: 0.44 - #neurons: 3 - #enabled connections: 2\n",
      "Population of 100 members in 1 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      0     100    0.43986       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 2 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.44234 stdev: 0.01294\n",
      "Best individual: milla kue\n",
      "Best fitness: 0.46 - #neurons: 3 - #enabled connections: 2\n",
      "Population of 100 members in 2 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      1      50    0.46382       0\n",
      "       drapi      0      50    0.43106       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 3 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.46989 stdev: 0.02956\n",
      "Best individual: guad kue\n",
      "Best fitness: 0.50 - #neurons: 4 - #enabled connections: 4\n",
      "Population of 101 members in 3 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      2      34    0.50000       0\n",
      "       drapi      1      33    0.49999       0\n",
      "      rettis      0      34    0.43196       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 4 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.52461 stdev: 0.13885\n",
      "Best individual: guad mu\n",
      "Best fitness: 0.89 - #neurons: 5 - #enabled connections: 4\n",
      "Population of 101 members in 7 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      3      14    0.84249       0\n",
      "       drapi      2      14    0.50262       0\n",
      "      rettis      1      14    0.43307       0\n",
      "        sime      0      16    0.48049       0\n",
      "        mccr      0      14    0.47159       0\n",
      "          ev      0      14    0.42285       0\n",
      "          mu      0      15    0.89349       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 5 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.68518 stdev: 0.21162\n",
      "Best individual: ned sime\n",
      "Best fitness: 1.00 - #neurons: 4 - #enabled connections: 4\n",
      "Population of 101 members in 11 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      4       9    0.53301       1\n",
      "       drapi      3       9    0.90626       0\n",
      "      rettis      2       8    0.49997       0\n",
      "        sime      1       9    0.99797       0\n",
      "        mccr      1       9    0.47159       1\n",
      "          ev      1      10    0.91660       0\n",
      "          mu      1      10    0.89349       1\n",
      "          gi      0       8    0.45932       0\n",
      "      saulki      0       9    0.47130       0\n",
      "        seku      0      10    0.49312       0\n",
      "       muran      0      10    0.80781       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 6 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.58421 stdev: 0.17294\n",
      "Best individual: guad drapi\n",
      "Best fitness: 1.00 - #neurons: 4 - #enabled connections: 5\n",
      "Population of 100 members in 17 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      5       5    0.51248       2\n",
      "       drapi      4       8    1.00000       0\n",
      "      rettis      3       6    0.50000       0\n",
      "        sime      2       6    0.72284       1\n",
      "        mccr      2       5    0.47094       2\n",
      "          ev      2       6    0.91660       0\n",
      "          mu      2       6    0.53169       2\n",
      "      saulki      1       6    0.45663       1\n",
      "        seku      1       6    0.49312       1\n",
      "        grit      0       6    0.62790       0\n",
      "       thori      0       6    0.61944       0\n",
      "      selodt      0       6    0.47082       0\n",
      "          me      0       6    0.58481       0\n",
      "    wrashion      0       6    0.49962       0\n",
      "          ma      0       6    0.44888       0\n",
      "        heri      0       5    0.48784       0\n",
      "          mi      0       5    0.36609       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 7 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.62909 stdev: 0.23113\n",
      "Best individual: guad delliever\n",
      "Best fitness: 1.00 - #neurons: 4 - #enabled connections: 3\n",
      "Population of 97 members in 21 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      6       6    0.99999       0\n",
      "       drapi      5       4    0.49974       1\n",
      "      rettis      4       5    0.57527       0\n",
      "        sime      3       5    0.99224       0\n",
      "        mccr      3       4    0.47282       0\n",
      "          ev      3       5    0.91660       1\n",
      "          mu      3       4    0.50000       3\n",
      "      saulki      2       4    0.48394       0\n",
      "        seku      2       4    0.49993       0\n",
      "        grit      1       4    0.42887       1\n",
      "       thori      1       4    0.50000       1\n",
      "      selodt      1       4    0.47159       0\n",
      "          me      1       4    0.41421       1\n",
      "          ma      1       4    0.41421       1\n",
      "        heri      1       4    0.43748       1\n",
      "          mi      1       5    0.51469       0\n",
      "       spark      0       4    0.50000       0\n",
      "   delliever      0       7    1.00000       0\n",
      "       gelin      0       4    0.41421       0\n",
      " periearriel      0       5    0.47159       0\n",
      "       lesei      0       7    0.93164       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 8 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.50701 stdev: 0.14947\n",
      "Best individual: guad kue\n",
      "Best fitness: 1.00 - #neurons: 4 - #enabled connections: 6\n",
      "Population of 100 members in 21 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      7       7    1.00000       0\n",
      "       drapi      6       5    0.49972       2\n",
      "      rettis      5       4    0.58481       0\n",
      "        sime      4       4    0.41421       1\n",
      "        mccr      4       5    0.56321       0\n",
      "          ev      4       4    0.45720       2\n",
      "          mu      4       5    0.49534       4\n",
      "        seku      3       4    0.40238       1\n",
      "        grit      2       5    0.47159       0\n",
      "       thori      2       5    0.63262       0\n",
      "          me      2       4    0.41724       0\n",
      "          ma      2       5    0.47159       0\n",
      "        heri      2       4    0.38740       2\n",
      "          mi      2       5    0.41927       1\n",
      "       spark      1       4    0.36623       1\n",
      "   delliever      1       5    0.50000       1\n",
      "       gelin      1       5    0.41421       0\n",
      " periearriel      1       5    0.41421       1\n",
      "       lesei      1       5    0.49576       1\n",
      "       okand      0       5    0.44916       0\n",
      "        halk      0       5    0.49002       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n",
      "\n",
      "****** Running Generation 9 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.52546 stdev: 0.09928\n",
      "Best individual: ned sime\n",
      "Best fitness: 0.86 - #neurons: 4 - #enabled connections: 4\n",
      "Population of 101 members in 17 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      8       6    0.50000       1\n",
      "       drapi      7       6    0.53169       0\n",
      "      rettis      6       6    0.50000       1\n",
      "        sime      5       7    0.85809       0\n",
      "        mccr      5       6    0.49991       1\n",
      "          mu      5       6    0.50000       0\n",
      "        seku      4       5    0.49564       0\n",
      "        grit      3       5    0.50000       0\n",
      "       thori      3       6    0.46374       1\n",
      "          me      3       6    0.58481       0\n",
      "          mi      3       6    0.41931       0\n",
      "       spark      2       6    0.50000       0\n",
      "   delliever      2       7    0.50000       2\n",
      " periearriel      2       5    0.41421       2\n",
      "       lesei      2       6    0.56878       0\n",
      "       okand      1       6    0.51842       0\n",
      "        halk      1       6    0.49933       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Running Generation 10 ******\n",
      "****** Difficulty 0 ******\n",
      "Population's average fitness: 0.52157 stdev: 0.15206\n",
      "Best individual: guad rettis\n",
      "Best fitness: 1.00 - #neurons: 6 - #enabled connections: 7\n",
      "Population of 102 members in 17 species:\n",
      "Species         age    size    fitness    stag\n",
      "============    ===    ====    =======    ====\n",
      "         kue      9       6    0.99143       0\n",
      "       drapi      8       6    0.50000       1\n",
      "      rettis      7       6    0.99990       0\n",
      "        sime      6       6    0.41642       1\n",
      "        mccr      6       6    0.49991       0\n",
      "          mu      6       6    0.50000       0\n",
      "        seku      5       7    0.50000       0\n",
      "        grit      4       7    0.49824       1\n",
      "       thori      4       5    0.41421       2\n",
      "          me      4       6    0.46377       1\n",
      "          mi      4       5    0.41421       1\n",
      "       spark      3       6    0.50000       1\n",
      "   delliever      3       5    0.37116       3\n",
      "       lesei      3       6    0.50000       1\n",
      "       okand      2       6    0.50004       1\n",
      "        halk      2       6    0.49998       0\n",
      "      puruns      0       7    0.49312       0\n",
      "Generation time: 0 seconds\n",
      "Solved in generation: 10\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "elitism = True\n",
    "stop_when_solved = True \n",
    "tournament_selection_k = 3 \n",
    "verbose = True\n",
    "max_cores = 1\n",
    "compatibility_threshold = 3.0\n",
    "compatibility_threshold_delta = 0.4 \n",
    "target_species = 12\n",
    "minimum_elitism_size = 5 \n",
    "young_age = 10\n",
    "young_multiplier = 1.2 \n",
    "old_age = 30\n",
    "old_multiplier = 0.2 \n",
    "stagnation_age = 15\n",
    "reset_innovations = False\n",
    "survival = 0.2\n",
    "\n",
    "genome_factory = lambda: Genotype(inputs, outputs, nonlinearities, topology, feedforward,\n",
    "                                  max_depth, max_nodes, response_default, initial_weight_stdev,\n",
    "                                  bias_as_node, p_add_neuron, p_add_connection, p_mutate_weight, \n",
    "                                  p_reset_weight, p_reenable_connection, p_disable_connection,\n",
    "                                  p_reenable_parent, p_mutate_bias, p_mutate_response, p_mutate_type,\n",
    "                                  stdev_mutate_weight, stdev_mutate_bias, stdev_mutate_response,\n",
    "                                  weight_range, distance_excess_weight, distance_disjoint_weight,\n",
    "                                  distance_weight)\n",
    "\n",
    "np.random.seed(420)\n",
    "torch.manual_seed(420)\n",
    "\n",
    "population = Population(genome_factory, population_size, elitism, stop_when_solved, tournament_selection_k, verbose, max_cores, compatibility_threshold, compatibility_threshold_delta, target_species, minimum_elitism_size, young_age, young_multiplier, old_age, old_multiplier, stagnation_age, reset_innovations, survival)\n",
    "task = XORTask()\n",
    "#task = RubiksTask()\n",
    "\n",
    "# cProfile.run('population.epoch(evaluator = task, generations = 1, solution = task)', 'restats')\n",
    "# import pstats\n",
    "# p = pstats.Stats('restats')\n",
    "# p.strip_dirs().sort_stats('cumtime').print_stats()\n",
    "result = population.epoch(evaluator = task, generations = 1000, solution = task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, mask =  None, weights = None):\n",
    "        super(MaskedLinear, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "        if mask is None:\n",
    "            mask = torch.ones((out_features, in_features))\n",
    "            \n",
    "        if weights is not None:\n",
    "            self.linear.weight.data = weights\n",
    "            \n",
    "        self.linear.weight.data *= mask\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "class NeuralNetwork2(nn.Module):\n",
    "    def __init__(self, genome):\n",
    "        super(NeuralNetwork2, self).__init__()\n",
    "        self.genome = genome\n",
    "        # Set maximum layer\n",
    "        self.max_layer = genome.max_layer\n",
    "        self.layers = defaultdict(list)\n",
    "        \n",
    "        # How many neurons in each layer?\n",
    "        for neuron_gene in genome.neuron_genes:\n",
    "            self.layers[neuron_gene[3]].append(neuron_gene)\n",
    "            \n",
    "        input_keys = genome.input_keys\n",
    "        output_keys = genome.output_keys\n",
    "        \n",
    "        # Hidden neuron id to layer\n",
    "        hidden_key_to_layer = defaultdict(int)\n",
    "        \n",
    "        all_hidden_keys = [k[0] for k in genome.neuron_genes if k[0] not in output_keys and k[0] not in input_keys]\n",
    "        self.hidden_keys = defaultdict(list)\n",
    "        for k in genome.neuron_genes:\n",
    "            if k[0] not in output_keys and k[0] not in input_keys:\n",
    "                self.hidden_keys[k[3]].append(k[0])\n",
    "                hidden_key_to_layer[k[0]] = k[3]\n",
    "        \n",
    "        input_key_to_idx = {k: i for i, k in enumerate(input_keys)}\n",
    "        hidden_key_to_idx = defaultdict(list)\n",
    "        \n",
    "        for hk in self.layers.keys():\n",
    "            if hk is not 0 and hk is not self.max_layer:\n",
    "                hidden_key_to_idx[hk].append({k: i for i, k in enumerate(self.hidden_keys[hk])})\n",
    "        \n",
    "        output_key_to_idx = {k: i for i, k in enumerate(output_keys)}\n",
    "    \n",
    "        def key_to_idx(key, layer = None):\n",
    "            if layer is None and key in input_keys:\n",
    "                return input_key_to_idx[key]\n",
    "            elif layer is not None and key in self.hidden_keys[layer]:\n",
    "                return hidden_key_to_idx[layer][0][key]\n",
    "            elif layer is None and key in output_keys:\n",
    "                return output_key_to_idx[key]\n",
    "        \n",
    "        self.i2o_mask = None\n",
    "        self.i2h_masks = defaultdict(list)\n",
    "        self.h2h_masks = defaultdict(list)\n",
    "        self.h2o_masks = defaultdict(list)\n",
    "        \n",
    "        self.i2o_weights = None\n",
    "        self.i2h_weights = defaultdict(list)\n",
    "        self.h2h_weights = defaultdict(list)\n",
    "        self.h2o_weights = defaultdict(list)\n",
    "        \n",
    "#         self.i2o_bias = None\n",
    "#         self.i2h_bias = defaultdict(list)\n",
    "#         self.h2h_bias = defaultdict(list)\n",
    "#         self.h2o_bias = defaultdict(list)\n",
    "        \n",
    "        for connection_gene in genome.connection_genes:\n",
    "            # Format (input_key, output_key)\n",
    "            input_key, output_key = connection_gene\n",
    "            # Format innovation_number, input, output, weight, enabled\n",
    "            weight, enabled = genome.connection_genes[connection_gene][3:]\n",
    "            \n",
    "            # Input to Output (I2O)\n",
    "            if input_key in input_keys and output_key in output_keys:\n",
    "                input_key_idx = key_to_idx(input_key)\n",
    "                output_key_idx = key_to_idx(output_key)\n",
    "                \n",
    "                if self.i2o_mask is None:\n",
    "                    self.i2o_mask = torch.zeros((len(self.layers[self.max_layer]),len(self.layers[0])))\n",
    "                \n",
    "                if self.i2o_weights is None:\n",
    "                    self.i2o_weights = torch.zeros((len(self.layers[self.max_layer]),len(self.layers[0])))\n",
    "                    \n",
    "#                 if self.i2o_bias is None:\n",
    "#                     self.i2o_bias = torch.zeros([1])\n",
    "                    \n",
    "                if enabled:\n",
    "                    self.i2o_mask[output_key_idx,input_key_idx] = 1\n",
    "                self.i2o_weights[output_key_idx,input_key_idx] = weight\n",
    "#                 self.i2o_bias = bias\n",
    "                \n",
    "            # Input to Hidden (I2H)\n",
    "            if input_key in input_keys and output_key in all_hidden_keys:\n",
    "                input_key_idx = key_to_idx(input_key)\n",
    "                layer = hidden_key_to_layer[output_key]\n",
    "                output_key_idx = key_to_idx(output_key, layer)\n",
    "                \n",
    "                if not self.i2h_masks[layer]:\n",
    "                    self.i2h_masks[layer].append(torch.zeros((len(self.layers[layer]), len(self.layers[0]))))\n",
    "                    \n",
    "                if not self.i2h_weights[layer]:\n",
    "                    self.i2h_weights[layer].append(torch.zeros((len(self.layers[layer]),len(self.layers[0]))))\n",
    "                    \n",
    "                if enabled:\n",
    "                    self.i2h_masks[layer][0][output_key_idx,input_key_idx] = 1\n",
    "                    \n",
    "                self.i2h_weights[layer][0][output_key_idx,input_key_idx] = weight\n",
    "                \n",
    "            # Hidden to Output (H2O)\n",
    "            if input_key in all_hidden_keys and output_key in output_keys:\n",
    "                layer = hidden_key_to_layer[input_key]\n",
    "                input_key_idx = key_to_idx(input_key, layer)\n",
    "                output_key_idx = key_to_idx(output_key)\n",
    "                \n",
    "                if not self.h2o_masks[layer]:\n",
    "                    self.h2o_masks[layer].append(torch.zeros((len(self.layers[self.max_layer]), len(self.layers[layer]))))\n",
    "                    \n",
    "                if not self.h2o_weights[layer]:\n",
    "                    self.h2o_weights[layer].append(torch.zeros((len(self.layers[self.max_layer]),len(self.layers[layer]))))\n",
    "                    \n",
    "                if enabled:\n",
    "                    self.h2o_masks[layer][0][output_key_idx,input_key_idx] = 1\n",
    "                \n",
    "                self.h2o_weights[layer][0][output_key_idx,input_key_idx] = weight\n",
    "                \n",
    "            # Hidden to Hidden (H2H)\n",
    "            if input_key in all_hidden_keys and output_key in all_hidden_keys:\n",
    "                layer = hidden_key_to_layer[input_key]\n",
    "                layer_output = hidden_key_to_layer[output_key]\n",
    "                input_key_idx = key_to_idx(input_key, layer)\n",
    "                output_key_idx = key_to_idx(output_key, layer_output)\n",
    "                \n",
    "                if not self.h2h_masks[(layer, layer_output)]:\n",
    "                    self.h2h_masks[(layer, layer_output)].append(torch.zeros((len(self.layers[layer_output]), len(self.layers[layer]))))\n",
    "                    \n",
    "                if not self.h2h_weights[(layer, layer_output)]:\n",
    "                    self.h2h_weights[(layer, layer_output)].append(torch.zeros((len(self.layers[layer_output]), len(self.layers[layer]))))\n",
    "                    \n",
    "                if enabled:\n",
    "                    self.h2h_masks[(layer, layer_output)][0][output_key_idx,input_key_idx] = 1\n",
    "                \n",
    "                self.h2h_weights[(layer, layer_output)][0][output_key_idx,input_key_idx] = weight\n",
    "        \n",
    "        self.input_to_output = MaskedLinear(len(self.layers[0]), len(self.layers[self.max_layer]), self.i2o_mask, self.i2o_weights)\n",
    "        \n",
    "        self.input_to_hidden = {layer: MaskedLinear(len(self.layers[0]), len(self.layers[layer]), self.i2h_masks[layer][0], self.i2h_weights[layer][0]) for layer in sorted(list(self.hidden_keys.keys())) if self.i2h_masks[layer]}\n",
    "        \n",
    "        self.hidden_to_hidden = {keys : MaskedLinear(len(self.layers[keys[0]]), len(self.layers[keys[1]]), self.h2h_masks[keys][0], self.h2h_weights[keys][0]) for keys in self.h2h_masks.keys()}\n",
    "        \n",
    "        self.hidden_to_output = {layer: MaskedLinear(len(self.layers[layer]), len(self.layers[self.max_layer]), self.h2o_masks[layer][0], self.h2o_weights[layer][0]) for layer in sorted(list(self.hidden_keys.keys())) if self.h2o_masks[layer]}     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #order layers\n",
    "        sorted_layer_keys = sorted(self.layers.keys())\n",
    "        \n",
    "        original_input = x\n",
    "        \n",
    "        input_nonlinearities = [string_to_activation[neuron_gene[1]] for neuron_gene in self.layers[0]]\n",
    "        input_after_non_linearity = torch.cat(([input_nonlinearities[i](input_x).view(1) for i, input_x in enumerate(original_input)]), dim = 0)\n",
    "        \n",
    "        past_hidden_activations = defaultdict(list)\n",
    "        # Iterate over each hidden layer\n",
    "        for idx, l in enumerate(sorted_layer_keys[1:-1]):\n",
    "            hidden_nonlinearities = [string_to_activation[neuron_gene[1]] for neuron_gene in self.layers[l]]\n",
    "            \n",
    "            total = torch.zeros([len(self.hidden_keys[l])])\n",
    "            \n",
    "            if l in self.input_to_hidden.keys():\n",
    "                total += self.input_to_hidden[l](input_after_non_linearity)\n",
    "            \n",
    "            for keys in self.hidden_to_hidden:\n",
    "                if keys[1] == l:\n",
    "\n",
    "                    total += self.hidden_to_hidden[keys](past_hidden_activations[keys[0]])\n",
    "            \n",
    "            hidden_after_nonlinearity = torch.cat(([hidden_nonlinearities[i](input_x).view(1) for i, input_x in enumerate(total)]), dim = 0)\n",
    "            past_hidden_activations[l] = hidden_after_nonlinearity\n",
    "\n",
    "        total = torch.zeros([len(self.layers[self.max_layer])])    \n",
    "        total += self.input_to_output(input_after_non_linearity)\n",
    "        \n",
    "        for keys in self.hidden_to_output:\n",
    "            total += self.hidden_to_output[keys](past_hidden_activations[keys])\n",
    "        \n",
    "        output_nonlinearities = [string_to_activation[neuron_gene[1]] for neuron_gene in self.layers[self.max_layer]]\n",
    "        final_output = torch.cat(([output_nonlinearities[i](input_x).view(1) for i, input_x in enumerate(total)]), dim = 0)    \n",
    "        \n",
    "        return final_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
