{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - Add Bias term\n",
    "    - Custom weights\n",
    "    - Drop out connections (set weight to 0)\n",
    "    - Custom activation per node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return F.leaky_relu(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return F.Tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return F.relu(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return F.Sigmoid(x)\n",
    "\n",
    "string_to_activation = {\n",
    "    'leaky_relu' : leaky_relu,\n",
    "    'relu' : relu,\n",
    "    'sigmoid' : sigmoid,\n",
    "    'tanh' : tanh\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,layer_sizes):\n",
    "        super(Model, self).__init__()\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        previous_layer_size = layer_sizes[0]\n",
    "        for idx, current_layer_size in enumerate(layer_sizes[1:]):\n",
    "            layers[str(idx)] = nn.Linear(previous_layer_size, current_layer_size)\n",
    "            previous_layer_size = current_layer_size\n",
    "            \n",
    "        self.layers = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genotype(object):\n",
    "    def __init__(self, inputs, outputs, nonlinearities,\n",
    "                 p_add_neuron, p_add_connection, p_mutate_weight, p_reenable_connection,\n",
    "                 p_disable_connection, p_mutate_bias,\n",
    "                distance_excess_weight, distance_disjoint_weight, distance_weight):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.nonlinearities = nonlinearities\n",
    "        \n",
    "        # Mutation Probabilities\n",
    "        self.p_add_neuron = p_add_neuron\n",
    "        self.p_add_connection = p_add_connection\n",
    "        self.p_mutate_weight = p_mutate_weight\n",
    "        self.p_reenable_connection = p_reenable_connection\n",
    "        self.p_disable_connection = p_disable_connection\n",
    "        self.p_mutate_bias = p_mutate_bias\n",
    "        \n",
    "        # Distance weights\n",
    "        self.distance_excess_weight = distance_excess_weight\n",
    "        self.distance_disjoint_weight = distance_disjoint_weight\n",
    "        self.distance_weight = distance_weight\n",
    "        \n",
    "        # Tuples of: id, non_linearity, layer\n",
    "        self.neuron_genes = []\n",
    "        # Tuples of: innovation number, input, output, weight, enabled\n",
    "        self.connection_genes = {}\n",
    "        # Hyperparameter genes\n",
    "        self.hyperparameter_genes = []\n",
    "        \n",
    "        self.initialise_topology()\n",
    "        \n",
    "    def initialise_topology(self):\n",
    "        # Initialise inputs\n",
    "        for i in range(self.inputs):\n",
    "            self.neuron_genes.append([i * 2048, random.choice(self.nonlinearities),0])\n",
    "        \n",
    "        # Initialise outputs\n",
    "        for i in range(self.outputs):\n",
    "            self.neuron_genes.append([(self.inputs + i) * 2048, random.choice(self.nonlinearities)])\n",
    "        \n",
    "        # Initialiase connections\n",
    "        innovation_number = 0\n",
    "        for i in range(self.inputs):\n",
    "            for j in range(self.outputs,self.inputs + self.outputs):\n",
    "                weight = self.initialise_weight(self.inputs,self.outputs)\n",
    "                self.connection_genes[(i,j)] = [innovation_number, i, j, weight ,True]\n",
    "                innovation_number += 1\n",
    "                \n",
    "    def initialise_weight(self, input_neurons, output_neurons):\n",
    "        weight = np.random.rand()*np.sqrt(1/(input_neurons + output_neurons))\n",
    "        \n",
    "#     def translate_to_pytorch(self):\n",
    "#         self.model = Model([self.inputs, 5, self.outputs])\n",
    "        \n",
    "#         print(self.model.layers[0].weight)\n",
    "#         raise NotImplementedError\n",
    "        \n",
    "    def get_weight_matrix(self,layer_1, layer_2):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def recombinate(self, other):\n",
    "        child = deepcopy(self)\n",
    "        child.neuron_genes = []\n",
    "        child.connection_genes = {}\n",
    "        \n",
    "    def mutate(self):\n",
    "        # TODO: move to separate functions\n",
    "        if np.random.rand() < self.p_add_neuron:\n",
    "            # Choose connection to split\n",
    "            split_neuron = self.connection_genes[random.choice(self.connection_genes.keys())]\n",
    "            # Disable old connection\n",
    "            split_neuron[4] = False\n",
    "            \n",
    "            input_neuron, output_neuron, weight = split_neuron[1:4]\n",
    "            neuron_id = (self.neuron_genes[input_neuron][0] + self.neuron_genes[input_neuron][0]) * 0.5\n",
    "            nonlinearity = random.choice(self.nonlinearities)\n",
    "            layer = self.neuron_genes[input_neuron][2] + 1\n",
    "            \n",
    "            neuron = [neuron_id, nonlinearity, layer]\n",
    "            \n",
    "            neuron_id = len(self.node_genes) - 1\n",
    "            \n",
    "            self.neuron_genes.append(neuron)\n",
    "            # 1.0 to initialise_weight?\n",
    "            # TODO: get innovation number\n",
    "            self.connection_genes[(input_neuron, neuron_id)] = [innovation_number, input_neuron, neuron_id, 1.0, True]\n",
    "            \n",
    "            self.connection_genes[(neuron_id, output_neuron)] = [innovation_number, neuron_id, output_neuron, weight, True]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def distance(self, other):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species(object):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population(object):\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 3\n",
    "outputs = 4\n",
    "nonlinearities = ['relu','sigmoid']\n",
    "\n",
    "p_add_node = 0.03\n",
    "p_add_connection = 0.3\n",
    "p_mutate_weight = 0.8\n",
    "p_reenable_connection = 0.01\n",
    "p_disable_connection = 0.01\n",
    "p_mutate_bias = 0.2\n",
    "\n",
    "distance_excess_weight = 1.0\n",
    "distance_disjoint_weight = 1.0\n",
    "distance_weight = 0.4\n",
    "\n",
    "genotype = Genotype(inputs, outputs, nonlinearities, \n",
    "                    p_add_node, p_add_connection, p_mutate_weight, p_reenable_connection,\n",
    "                   p_disable_connection, p_mutate_bias,\n",
    "                   distance_excess_weight, distance_disjoint_weight, distance_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2442, -0.6035,  0.8889,  0.5022, -0.4859],\n",
       "        [-0.2921,  1.2088,  0.4895, -0.8608,  0.1795],\n",
       "        [ 1.1595, -0.7377, -0.1698,  0.0373,  1.0230]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
