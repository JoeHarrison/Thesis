{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from collections import OrderedDict, defaultdict\n",
    "from itertools import product\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    - Add Bias term\n",
    "    - Custom weights\n",
    "    - Drop out connections (set weight to 0)\n",
    "    - Custom activation per node\n",
    "    \n",
    "    - Add function that resets stagnation for all species\\\n",
    "    - Network Visualisation\n",
    "    - Species Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return F.leaky_relu(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return F.Tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return F.relu(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return F.Sigmoid(x)\n",
    "\n",
    "string_to_activation = {\n",
    "    'leaky_relu' : leaky_relu,\n",
    "    'relu' : relu,\n",
    "    'sigmoid' : sigmoid,\n",
    "    'tanh' : tanh\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,layer_sizes):\n",
    "        super(Model, self).__init__()\n",
    "        layers = OrderedDict()\n",
    "        \n",
    "        previous_layer_size = layer_sizes[0]\n",
    "        for idx, current_layer_size in enumerate(layer_sizes[1:]):\n",
    "            layers[str(idx)] = nn.Linear(previous_layer_size, current_layer_size)\n",
    "            previous_layer_size = current_layer_size\n",
    "            \n",
    "        self.layers = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genotype(object):\n",
    "    def __init__(self, inputs = 144, \n",
    "                 outputs = 12, \n",
    "                 nonlinearities = ['relu','sigmoid','tanh'],\n",
    "                 topology = None,\n",
    "                 feedforward = True,\n",
    "                 max_depth=None,\n",
    "                 max_nodes = float('inf'),\n",
    "                 initial_weight_stdev = 2.0,\n",
    "                 bias_as_node = False,\n",
    "                 p_add_neuron = 0.03, \n",
    "                 p_add_connection = 0.3, \n",
    "                 p_mutate_weight = 0.1, \n",
    "                 p_reenable_connection = 0.01,\n",
    "                 p_disable_connection = 0.01, \n",
    "                 p_reenable_parent = 0.25, \n",
    "                 p_mutate_bias = 0.2,\n",
    "                 p_mutate_type = 0.2,\n",
    "                 stdev_mutate_weight = 1.5,\n",
    "                 stdev_mutate_bias = 0.5,\n",
    "                 weight_Range = (-50.,50.),\n",
    "                 distance_excess_weight = 1.0, \n",
    "                 distance_disjoint_weight = 1.0, \n",
    "                 distance_weight = 0.4):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.nonlinearities = nonlinearities\n",
    "        self.feedforward = feedforward\n",
    "        self.bias_as_node = bias_as_node\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.max_nodes = max_nodes\n",
    "        \n",
    "        # Mutation Probabilities\n",
    "        self.p_add_neuron = p_add_neuron\n",
    "        self.p_add_connection = p_add_connection\n",
    "        self.p_mutate_weight = p_mutate_weight\n",
    "        self.p_reenable_connection = p_reenable_connection\n",
    "        self.p_disable_connection = p_disable_connection\n",
    "        self.p_reenable_parent = p_reenable_parent\n",
    "        self.p_mutate_bias = p_mutate_bias\n",
    "        self.p_mutate_type = p_mutate_type\n",
    "        \n",
    "        # Distance weights\n",
    "        self.distance_excess_weight = distance_excess_weight\n",
    "        self.distance_disjoint_weight = distance_disjoint_weight\n",
    "        self.distance_weight = distance_weight\n",
    "        \n",
    "        # Tuples of: id, non_linearity, layer\n",
    "        self.neuron_genes = []\n",
    "        # Tuples of: innovation number, input, output, weight, enabled\n",
    "        self.connection_genes = {}\n",
    "        # Hyperparameter genes\n",
    "        self.hyperparameter_genes = []\n",
    "        \n",
    "        self._initialise_topology(topology)\n",
    "        \n",
    "    def _initialise_topology(self, topology):\n",
    "        if topology is None:\n",
    "            # Initialise inputs\n",
    "            for i in range(self.inputs):\n",
    "                self.neuron_genes.append([i * 2048, random.choice(self.nonlinearities),1.0,0])\n",
    "\n",
    "            # Initialise outputs\n",
    "            for i in range(self.outputs):\n",
    "                self.neuron_genes.append([(self.inputs + i) * 2048, random.choice(self.nonlinearities),1.0,0])\n",
    "\n",
    "            # Initialise connections\n",
    "            innovation_number = 0\n",
    "            for i in range(self.inputs):\n",
    "                for j in range(self.inputs,self.inputs + self.outputs):\n",
    "                    weight = self._initialise_weight(self.inputs,self.outputs)\n",
    "                    self.connection_genes[(i,j)] = [innovation_number, i, j, weight ,True]\n",
    "                    innovation_number += 1\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "                \n",
    "    def _initialise_weight(self, input_neurons, output_neurons):\n",
    "        weight = np.random.rand()*np.sqrt(1/(input_neurons + output_neurons))\n",
    "        return weight\n",
    "        \n",
    "    def recombinate(self, other):\n",
    "        child = deepcopy(self)\n",
    "        child.neuron_genes = []\n",
    "        child.connection_genes = {}\n",
    "        \n",
    "        max_neurons = max(len(self.neuron_genes), len(other.neuron_genes))\n",
    "        min_neurons = min(len(self.neuron_genes), len(other.neuron_genes))\n",
    "        \n",
    "        for i in range(max_neurons):\n",
    "            neuron_gene = None\n",
    "            if i < min_neurons:\n",
    "                neuron_gene = random.choice((self.neuron_genes[i], other.neuron_genes[i]))\n",
    "            else:\n",
    "                try:\n",
    "                    neuron_gene = self.neuron_genes[i]\n",
    "                except IndexError:\n",
    "                    neuron_gene = other.neuron_genes[i]\n",
    "            child.neuron_genes.append(deepcopy(neuron_gene))\n",
    "            \n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "        max_innovation_number = max(list(self_connections.keys()) + list(other_connections.keys()))\n",
    "        \n",
    "        for i in range(max_innovation_number + 1):\n",
    "            connection_gene = None\n",
    "            if i in self_connections and i in other_connections:\n",
    "                connection_gene = random.choice((self_connections[i],other_connections[i]))\n",
    "                enabled = self_connections[i][4] and other_connections[i][4]\n",
    "            else:\n",
    "                if i in self_connections:\n",
    "                    connection_gene = self_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "                elif i in other_connections:\n",
    "                    connection_gene = other_connections[i]\n",
    "                    enabled = connection_gene[4]\n",
    "            if connection_gene is not None:\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])] = deepcopy(connection_gene)\n",
    "                child.connection_genes[(connection_gene[1],connection_gene[2])][4] = enabled or np.random.rand() < self.p_reenable_parent\n",
    "\n",
    "            def is_feedforward(item):\n",
    "                ((fr, to), cg) = item\n",
    "                return child.neuron_genes[fr][0] < child.neuron_genes[to][0]\n",
    "\n",
    "            if self.feedforward:\n",
    "                child.connection_genes = dict(filter(is_feedforward, child.connection_genes.items()))\n",
    "            \n",
    "        return child\n",
    "        \n",
    "    def mutate(self, innovations = {}, global_innovation_number = 0):\n",
    "        maximum_innovation_number = max(global_innovation_number, max(cg[0] for cg in self.connection_genes.values()))\n",
    "        # TODO: move to separate functions\n",
    "        if len(self.neuron_genes) < self.max_nodes and np.random.rand() < self.p_add_neuron:\n",
    "            possible_to_split = self.connection_genes.keys()\n",
    "            \n",
    "            if self.max_depth is not None:\n",
    "                possible_to_split = [(fr, to) for (fr, to) in possible_to_split if self.neuron_genes[fr][4] + 1 < self.neuron_genes[to][4]]\n",
    "            \n",
    "            if possible_to_split:\n",
    "\n",
    "                # Choose connection to split\n",
    "                split_neuron = self.connection_genes[random.choice(list(self.connection_genes.keys()))]\n",
    "                # Disable old connection\n",
    "                split_neuron[4] = False\n",
    "\n",
    "                input_neuron, output_neuron, weight = split_neuron[1:4]\n",
    "                neuron_id = (self.neuron_genes[input_neuron][0] + self.neuron_genes[input_neuron][0]) * 0.5\n",
    "                nonlinearity = random.choice(self.nonlinearities)\n",
    "                layer = self.neuron_genes[input_neuron][3] + 1\n",
    "\n",
    "                neuron = [neuron_id, nonlinearity, 1.0, layer]\n",
    "\n",
    "                new_id = len(self.neuron_genes)\n",
    "\n",
    "                self.neuron_genes.append(neuron)\n",
    "                \n",
    "                if (input_neuron, new_id) in innovations:\n",
    "                    innovation_number = innovations[(input_neuron,new_id)]\n",
    "                else:\n",
    "                    maximum_innovation_number += 1\n",
    "                    innovation_number = innovations[(input_neuron,new_id)] = maximum_innovation_number\n",
    "                    \n",
    "                # 1.0 to initialise_weight?\n",
    "                self.connection_genes[(input_neuron, new_id)] = [innovation_number, input_neuron, new_id, 1.0, True]\n",
    "                \n",
    "                if (new_id, output_neuron) in innovations:\n",
    "                    innovation_number = innovations[(new_id, output_neuron)]\n",
    "                else:\n",
    "                    maximum_innovation_number += 1\n",
    "                    innovation_number = innovations[(new_id, output_neuron)] = maximum_innovation_number\n",
    "                    \n",
    "                self.connection_genes[(new_id, output_neuron)] = [innovation_number, new_id, output_neuron, weight, True]\n",
    "\n",
    "        elif np.random.rand() < self.p_add_connection:\n",
    "            potential_connections = product(range(len(self.neuron_genes)),range(self.inputs, len(self.neuron_genes)))\n",
    "            potential_connections = (connection for connection in potential_connections if connection not in self.connection_genes)\n",
    "            \n",
    "            if self.feedforward:\n",
    "                potential_connections = ((f, t) for (f, t) in potential_connections if self.neuron_genes[f][0] < self.neuron_genes[t][0])\n",
    "            \n",
    "            potential_connections = list(potential_connections)\n",
    "            if potential_connections:\n",
    "                (fr, to) = random.choice(potential_connections)\n",
    "                if (fr, to) in innovations:\n",
    "                    innovation = innovations[(fr, to)]\n",
    "                else:\n",
    "                    maximum_innovation_number += 1\n",
    "                    innovation = innovations[(fr, to)] = maximum_innovation_number\n",
    "                # get number of neurons in layers of fr and to\n",
    "                connection_gene = [innovation, fr, to, self._initialise_weight(2,2), True]\n",
    "                self.connection_genes[(fr, to)] = connection_gene\n",
    "        else:\n",
    "            for cg in self.connection_genes.values():\n",
    "                if np.random.rand() < self.p_mutate_weight:\n",
    "                    cg[3] += np.random.normal(0, 1)\n",
    "                    # clipping?\n",
    "#                 if np.random.rand() < self.p_reset_weight:\n",
    "#                     cg[3] = np.random.normal(0,1)\n",
    "                    \n",
    "                # bigger chance to disable in this way\n",
    "                if np.random.rand() < self.p_reenable_connection:\n",
    "                    cg[4] = True\n",
    "                    \n",
    "                if np.random.rand() < self.p_disable_connection:\n",
    "                    cg[4] = False\n",
    "                    \n",
    "            for neuron_gene in self.neuron_genes[self.inputs:]:\n",
    "                if np.random.rand() < self.p_mutate_bias:\n",
    "                    neuron_gene[2] += np.random.normal(0, 1)\n",
    "                \n",
    "                if np.random.rand() < self.p_mutate_type:\n",
    "                    neuron_gene[1] = random.choice(self.nonlinearities)\n",
    "                    \n",
    "        \n",
    "            \n",
    "            \n",
    "                    \n",
    "                \n",
    "                    \n",
    "        return self\n",
    "        \n",
    "    def distance(self, other):\n",
    "        self_connections = dict(((c[0], c) for c in self.connection_genes.values()))\n",
    "        other_connections = dict(((c[0], c) for c in other.connection_genes.values()))\n",
    "\n",
    "        all_innovations = list(self_connections.keys()) + list(other_connections.keys())\n",
    "\n",
    "        minimum_innovation = min(all_innovations)\n",
    "        \n",
    "        e = 0\n",
    "        d = 0\n",
    "        w = 0.0\n",
    "        m = 0\n",
    "        \n",
    "        for innovation_key in all_innovations:\n",
    "            if innovation_key in self_connections and innovation_key in other_connections:\n",
    "                w += np.abs(self_connections[innovation_key][3] - other_connections[innovation_key][3])\n",
    "                m += 1\n",
    "            elif innovation_key in self_connections or innovation_key in other_connections:\n",
    "                # Disjoint genes\n",
    "                if i < minimum_innovation:\n",
    "                    d += 1\n",
    "                # Excess genes\n",
    "                else:\n",
    "                    e += 1\n",
    "                    \n",
    "        # Average weight differences of matching genes\n",
    "        w = (w/m) if m>0 else w\n",
    "        \n",
    "        return (self.distance_excess_weight * e +\n",
    "               self.distance_disjoint_weight * d +\n",
    "               self.distance_weight * w)\n",
    "    \n",
    "    def get_network_data(self):\n",
    "        \"\"\" Returns a tuple of (connection_matrix, node_types) \n",
    "            that is reordered by the \"feed-forward order\" of the network,\n",
    "            Such that if feedforward was set to true, the matrix will be\n",
    "            lower-triangular.\n",
    "            The node bias is inserted as \"node 0\", the leftmost column\n",
    "            of the matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Assemble connectivity matrix\n",
    "        cm = np.zeros((len(self.neuron_genes), len(self.neuron_genes)))\n",
    "        cm.fill(np.nan)\n",
    "        \n",
    "        for (_, fr, to, weight, enabled) in self.connection_genes.values():\n",
    "            if enabled:\n",
    "                cm[to, fr] = weight\n",
    "        \n",
    "        # Reorder the nodes/connections\n",
    "#         ff, node_types, bias, response, layer = zip(*self.neuron_genes)\n",
    "        ff, node_types, bias, layer = zip(*self.neuron_genes)\n",
    "        order = [i for _,i in sorted(zip(ff, range(len(ff))))]\n",
    "        cm = cm[:,order][order,:]\n",
    "        node_types = np.array(node_types)[order]\n",
    "        bias = np.array(bias)[order]\n",
    "#         response = np.array(response)[order]\n",
    "        layers = np.array(layer)[order]\n",
    "\n",
    "#         # Then, we multiply all the incoming connection weights by the response\n",
    "        cm *= np.atleast_2d(4.9).T\n",
    "        # Finally, add the bias as incoming weights from node-0\n",
    "        if not self.bias_as_node:\n",
    "            cm = np.hstack( (np.atleast_2d(bias).T, cm) )\n",
    "            cm = np.insert(cm, 0, 0.0, axis=0)\n",
    "            # TODO: this is a bit ugly, we duplicate the first node type for \n",
    "            # bias node. It shouldn't matter though since the bias is used as an input.\n",
    "            node_types = [node_types[0]] + list(node_types)\n",
    "\n",
    "        if self.feedforward and np.triu(np.nan_to_num(cm)).any():\n",
    "            import pprint\n",
    "            pprint.pprint(self.neuron_genes)\n",
    "            pprint.pprint(self.connection_genes)\n",
    "            print(ff)\n",
    "            print(order)\n",
    "            print(np.sign(cm))\n",
    "            raise Exception(\"Network is not feedforward.\")\n",
    "        \n",
    "        return cm, node_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species(object):\n",
    "    def __init__(self, initial_member):\n",
    "        self.members = [initial_member]\n",
    "        self.representative = initial_member\n",
    "        self.offspring = 0\n",
    "        self.age = 0\n",
    "        self.average_fitness = 0.\n",
    "        self.max_fitness = 0.\n",
    "        self.max_fitness_previous = 0.0\n",
    "        self.stagnation = 0\n",
    "        self.has_best = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population(object):\n",
    "    def __init__(self, genome_factory,\n",
    "                population_size = 100,\n",
    "                elitism = True,\n",
    "                stop_when_solved = False,\n",
    "                tournament_selection_k = 3,\n",
    "                verbose = True,\n",
    "                max_cores = 1,\n",
    "                compatibility_threshold = 3.0,\n",
    "                compatibility_threshold_delta = 0.4,\n",
    "                target_species = 12,\n",
    "                minimum_elitism_size = 5,\n",
    "                young_age = 10,\n",
    "                young_multiplier = 1.2,\n",
    "                old_age = 30,\n",
    "                old_multiplier = 0.2,\n",
    "                stagnation_age = 15,\n",
    "                reset_innovations = False,\n",
    "                survival = 0.2):\n",
    "        \n",
    "        self.genome_factory = genome_factory\n",
    "        self.population_size = population_size\n",
    "        self.elitism = elitism\n",
    "        self.stop_when_solved = stop_when_solved\n",
    "        self.tournament_selection_k = tournament_selection_k\n",
    "        self.verbose = verbose\n",
    "        self.max_cores = max_cores\n",
    "        \n",
    "        cpus = multiprocessing.cpu_count()\n",
    "        use_cores = min(self.max_cores, cpus-1)\n",
    "        if use_cores > 1:\n",
    "            self.pool = multiprocessing.Pool(processes=use_cores, maxtasksperchild=5)\n",
    "        else:\n",
    "            self.pool = None\n",
    "        \n",
    "        self.compatibility_threshold = compatibility_threshold\n",
    "        self.compatibility_threshold_delta = compatibility_threshold_delta\n",
    "        \n",
    "        self.target_species = target_species\n",
    "        self.minimum_elitism_size = minimum_elitism_size\n",
    "        \n",
    "        self.young_age = young_age\n",
    "        self.young_multiplier = young_multiplier\n",
    "        self.old_age = old_age\n",
    "        self.old_multiplier = old_multiplier\n",
    "        \n",
    "        self.stagnation_age = stagnation_age\n",
    "        \n",
    "        self.reset_innovations = reset_innovations\n",
    "        self.survival = survival\n",
    "    \n",
    "    # Peas has this function outside the class\n",
    "    def evaluate_individual(self,item):\n",
    "        (individual, evaluator) = item\n",
    "        if callable(evaluator):\n",
    "            individual.stats = evaluator(individual)\n",
    "        elif hasattr(evaluator, 'evaluate'):\n",
    "            individual.stats = evaluator.evaluate(individual)\n",
    "        else:\n",
    "            raise Exception(\"Evaluator must be a callable or object\" \\\n",
    "                        \"with a callable attribute 'evaluate'.\")\n",
    "        return individual\n",
    "        \n",
    "    def _evaluate_all(self, population, evaluator):\n",
    "        to_eval = [(individual, evaluator) for individual in population]\n",
    "        if self.pool is not None:\n",
    "            population = list(self.pool.map(self.evaluate_indivual, to_eval))\n",
    "        else:\n",
    "            population = list(map(self.evaluate_individual, to_eval))\n",
    "        \n",
    "        return population\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.champions = []\n",
    "        self.generation = 0\n",
    "        self.solved_at = None\n",
    "        self.stats = defaultdict(list)\n",
    "        self.species = []\n",
    "        self.global_innovation_number = 0\n",
    "        self.innovations = {}\n",
    "        self.current_compatibility_threshold = self.compatibility_threshold\n",
    "        \n",
    "    def _find_best(self, population, solution = None):\n",
    "        self.champions.append(max(population, key=lambda individual: individual.stats['fitness']))\n",
    "        \n",
    "        if solution is not None:\n",
    "            if isinstance(solution, (int, float)):\n",
    "                solved = (self.champions[-1].stats['fitness'] >= solution)\n",
    "            elif callable(solution):\n",
    "                solved = solution(self.champions[-1])\n",
    "            elif hasattr(solution, 'solve'):\n",
    "                solved = solution.solve(self.champions[-1])\n",
    "                \n",
    "            if solved and self.solved_at is None:\n",
    "                self.solved_at = self.generation\n",
    "            \n",
    "    @property\n",
    "    def population(self):\n",
    "        for specie in self.species:\n",
    "            for member in specie.members:\n",
    "                yield member\n",
    "    \n",
    "    def _evolve(self, evaluator, solution=None):\n",
    "        population = list(self.population)\n",
    "        \n",
    "        while len(population) < self.population_size:\n",
    "            individual = self.genome_factory()\n",
    "            population.append(individual)        \n",
    "            \n",
    "        population = self._evaluate_all(population, evaluator)\n",
    "        \n",
    "        # Speciation\n",
    "        for specie in self.species:\n",
    "            # Choose random specie representative for distance comparison\n",
    "            specie.representative = random.choice(specie.members)\n",
    "            specie.members = []\n",
    "            specie.age += 1\n",
    "            \n",
    "        # Add each individual to a species\n",
    "        for individual in population:\n",
    "            found = False\n",
    "            for specie in self.species:\n",
    "                if individual.distance(specie.representative) <= self.current_compatibility_threshold:\n",
    "                    specie.members.append(individual)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                s = Species(individual)\n",
    "                self.species.append(s)\n",
    "        \n",
    "        # Remove empty species\n",
    "        self.species = list(filter(lambda s: len(s.members) > 0, self.species))\n",
    "        \n",
    "        # Adjust compatibility threshold\n",
    "        if len(self.species) < self.target_species:\n",
    "            self.current_compatibility_threshold -= self.compatibility_threshold_delta\n",
    "        elif len(self.species) > self.target_species:\n",
    "            self.current_compatibility_threshold += self.compatibility_threshold_delta\n",
    "        \n",
    "        # Find champion and check for solution\n",
    "        self._find_best(population, solution)\n",
    "        \n",
    "        # Recombination\n",
    "        \n",
    "        for specie in self.species:\n",
    "            specie.max_fitness_previous = specie.max_fitness\n",
    "            specie.average_fitness = np.mean([individual.stats['fitness'] for individual in specie.members])\n",
    "            specie.max_fitness = np.max([individual.stats['fitness'] for individual in specie.members])\n",
    "            if specie.max_fitness <= specie.max_fitness_previous:\n",
    "                specie.stagnation += 1\n",
    "            else:\n",
    "                specie.stagnation = 0\n",
    "            specie.has_best = self.champions[-1] in specie.members\n",
    "        \n",
    "        # Keep species that have the best or within stagnation age range\n",
    "        self.species = list(filter(lambda s: s.stagnation < self.stagnation_age or s.has_best, self.species))\n",
    "        \n",
    "        average_fitness = np.array([specie.average_fitness for specie in self.species])\n",
    "        \n",
    "        # Adjust fitness based on age\n",
    "        age = np.array([specie.age for specie in self.species])\n",
    "        for specie in self.species:\n",
    "            if specie.age < self.young_age:\n",
    "                specie.average_fitness *= self.young_multiplier\n",
    "            if specie.age > self.old_age:\n",
    "                specie.average_fitness *= self.old_multiplier\n",
    "                \n",
    "        # Compute offspring size\n",
    "        total_fitness = sum(specie.average_fitness for specie in self.species)\n",
    "        for specie in self.species:\n",
    "            specie.offspring = int(round(self.population_size * specie.average_fitness / total_fitness))\n",
    "            \n",
    "        \n",
    "        \n",
    "        # Remove species without offspring\n",
    "        self.species = list(filter(lambda s: s.offspring > 0, self.species))\n",
    "\n",
    "        for specie in self.species:\n",
    "            specie.members.sort(key=lambda individual: individual.stats['fitness'], reverse = True)\n",
    "            keep = max(1, int(round(len(specie.members)*self.survival)))\n",
    "            pool = specie.members[:keep]\n",
    "            \n",
    "            if self.elitism and len(specie.members) > self.minimum_elitism_size:\n",
    "                specie.members = specie.members[:1]\n",
    "            else:\n",
    "                specie.members = []\n",
    "                \n",
    "            while len(specie.members) < specie.offspring:\n",
    "                k = min(len(pool), self.tournament_selection_k)\n",
    "                p1 = max(random.sample(pool,k), key=lambda individual: individual.stats['fitness'])\n",
    "                p2 = max(random.sample(pool,k), key=lambda individual: individual.stats['fitness'])\n",
    "                \n",
    "                child = p1.recombinate(p2)\n",
    "                child.mutate(innovations=self.innovations, global_innovation_number = self.global_innovation_number)\n",
    "                specie.members.append(child)\n",
    "                \n",
    "        if self.innovations:\n",
    "            self.global_innovation_number = max(self.innovations.values())\n",
    "            \n",
    "        self._gather_stats(population)\n",
    "            \n",
    "    def epoch(self, evaluator, generations, solution=None, reset=True, callback= None):\n",
    "        if reset:\n",
    "            self._reset()\n",
    "            \n",
    "        for i in range(generations):\n",
    "            self._evolve(evaluator, solution)\n",
    "            self.generation += 1\n",
    "            \n",
    "            if self.verbose:\n",
    "                self._status_report()\n",
    "                \n",
    "            if callback is not None:\n",
    "                callback(self)\n",
    "            \n",
    "            if self.solved_at is not None and self.stop_when_solved:\n",
    "                break\n",
    "        \n",
    "        return {'stats': self.stats, 'champions': self.champions}\n",
    "    \n",
    "    def _gather_stats(self, population):\n",
    "        for key in population[0].stats:\n",
    "            self.stats[key+'_avg'].append(np.mean([individual.stats[key] for individual in population]))\n",
    "            self.stats[key+'_max'].append(np.max([individual.stats[key] for individual in population]))\n",
    "            self.stats[key+'_min'].append(np.min([individual.stats[key] for individual in population]))\n",
    "        self.stats['solved'].append( self.solved_at is not None )\n",
    "    \n",
    "    def _status_report(self):\n",
    "        print(\"\\n== Generation %d ==\" % self.generation)\n",
    "        print(\"Best (%.2f): %s %s\" % (self.champions[-1].stats['fitness'], self.champions[-1], self.champions[-1].stats))\n",
    "        print(\"Solved: %s\" % (self.solved_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Package with some classes to simulate neural nets.\n",
    "\"\"\"\n",
    "\n",
    "### IMPORTS ###\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "np.seterr(over='ignore', divide='raise')\n",
    "\n",
    "# Libraries\n",
    "\n",
    "# Local\n",
    "\n",
    "\n",
    "# Shortcuts\n",
    "\n",
    "inf = float('inf')\n",
    "sqrt_two_pi = np.sqrt(np.pi * 2)\n",
    "\n",
    "### FUNCTIONS ###\n",
    "\n",
    "# Node functions\n",
    "def ident(x):\n",
    "    return x\n",
    "\n",
    "def bound(x, clip=(-1.0, 1.0)):\n",
    "    return np.clip(x, *clip)\n",
    "\n",
    "def gauss(x):\n",
    "    \"\"\" Returns the pdf of a gaussian.\n",
    "    \"\"\"\n",
    "    return np.exp(-x ** 2 / 2.0) / sqrt_two_pi\n",
    "    \n",
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function. \n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid2(x):\n",
    "    \"\"\" Sigmoid function. \n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-4.9*x))\n",
    "\n",
    "def abs(x):\n",
    "    return np.abs(x)\n",
    "\n",
    "def sin(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def summed(fn):\n",
    "    return lambda x: fn(sum(x))\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x>0)\n",
    "\n",
    "### CONSTANTS ###\n",
    "\n",
    "SIMPLE_NODE_FUNCS = {\n",
    "    'sin': np.sin,\n",
    "    'abs': np.abs,\n",
    "    'ident': ident,\n",
    "    'linear': ident,\n",
    "    'bound': bound,\n",
    "    'gauss': gauss,\n",
    "    'sigmoid': sigmoid,\n",
    "    'sigmoid2': sigmoid2,\n",
    "    'exp': sigmoid,\n",
    "    'tanh': tanh,\n",
    "    'relu': relu,\n",
    "    None : ident\n",
    "}\n",
    "\n",
    "def rbfgauss(x):\n",
    "    return np.exp(-(x ** 2).sum() / 2.0) / sqrt_two_pi\n",
    "\n",
    "def rbfwavelet(x):\n",
    "    return np.exp(-(x ** 2).sum() / ( 2* 0.5**2 )) * np.sin(2 * np.pi * x[0])\n",
    "\n",
    "COMPLEX_NODE_FUNCS = {\n",
    "    'rbfgauss': rbfgauss,\n",
    "    'rbfwavelet': rbfwavelet\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "### CLASSES ### \n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    \"\"\" A neural network. Can have recursive connections.\n",
    "    \"\"\"\n",
    "    \n",
    "    def from_matrix(self, matrix, node_types=['sigmoid']):\n",
    "        \"\"\" Constructs a network from a weight matrix. \n",
    "        \"\"\"\n",
    "        # Initialize net\n",
    "        self.original_shape = matrix.shape[:matrix.ndim//2]\n",
    "        # If the connectivity matrix is given as a hypercube, squash it down to 2D\n",
    "        n_nodes = np.prod(self.original_shape)\n",
    "        self.cm  = matrix.reshape((n_nodes,n_nodes))\n",
    "        self.node_types = node_types\n",
    "        if len(self.node_types) == 1:\n",
    "            self.node_types *= n_nodes\n",
    "        self.act = np.zeros(self.cm.shape[0])\n",
    "        self.optimize()\n",
    "        return self\n",
    "        \n",
    "    def from_neatchromosome(self, chromosome):\n",
    "        \"\"\" Construct a network from a Chromosome instance, from\n",
    "            the neat-python package. This is a connection-list\n",
    "            representation.\n",
    "        \"\"\"\n",
    "        # TODO Deprecate the neat-python compatibility\n",
    "        # Typecheck\n",
    "        import neat.chromosome\n",
    "        \n",
    "        if not isinstance(chromosome, neat.chromosome.Chromosome):\n",
    "            raise Exception(\"Input should be a NEAT chromosome, is %r.\" % (chromosome))\n",
    "        # Sort nodes: BIAS, INPUT, HIDDEN, OUTPUT, with HIDDEN sorted by feed-forward.\n",
    "        nodes = dict((n.id, n) for n in chromosome.neuron_genes)\n",
    "        node_order = ['bias']\n",
    "        node_order += [n.id for n in filter(lambda n: n.type == 'INPUT', nodes.values())]\n",
    "        if isinstance(chromosome, neat.chromosome.FFChromosome):\n",
    "            node_order += chromosome.node_order\n",
    "        else:\n",
    "            node_order += [n.id for n in filter(lambda n: n.type == 'HIDDEN', nodes.values())]\n",
    "        node_order += [n.id for n in filter(lambda n: n.type == 'OUTPUT', nodes.values())]\n",
    "        # Construct object\n",
    "        self.cm = np.zeros((len(node_order), len(node_order)))\n",
    "        # Add bias connections\n",
    "        for id, node in nodes.items():\n",
    "            self.cm[node_order.index(id), 0] = node.bias\n",
    "            self.cm[node_order.index(id), 1:] = node.response\n",
    "        # Add the connections\n",
    "        for conn in chromosome.connection_genes:\n",
    "            if conn.enabled:\n",
    "                to = node_order.index(conn.outnodeid)\n",
    "                fr = node_order.index(conn.innodeid)\n",
    "                # dir(conn.weight)\n",
    "                self.cm[to, fr] *= conn.weight\n",
    "        # Verify actual feed forward\n",
    "        if isinstance(chromosome, neat.chromosome.FFChromosome):\n",
    "            if np.triu(self.cm).any():\n",
    "                raise Exception(\"NEAT Chromosome does not describe feedforward network.\")\n",
    "        node_order.remove('bias')\n",
    "        self.node_types = [nodes[i].activation_type for i in node_order]\n",
    "        self.node_types = ['ident'] + self.node_types\n",
    "        self.act = np.zeros(self.cm.shape[0])\n",
    "        self.optimize()\n",
    "        return self\n",
    "\n",
    "    def optimize(self):\n",
    "        # If all nodes are simple nodes\n",
    "        if all(fn in SIMPLE_NODE_FUNCS for fn in self.node_types):\n",
    "            # Simply always sum the node inputs, this is faster\n",
    "            self.sum_all_node_inputs = True\n",
    "            self.cm = np.nan_to_num(self.cm)\n",
    "            # If all nodes are identical types\n",
    "            if all(fn == self.node_types[0] for fn in self.node_types):\n",
    "                self.all_nodes_same_function = True\n",
    "            self.node_types = [SIMPLE_NODE_FUNCS[fn] for fn in self.node_types]\n",
    "        else:\n",
    "            nt = []\n",
    "            for fn in self.node_types:\n",
    "                if fn in SIMPLE_NODE_FUNCS:\n",
    "                    # Substitute the function(x) for function(sum(x))\n",
    "                    nt.append(summed(SIMPLE_NODE_FUNCS[fn]))\n",
    "                else:\n",
    "                    nt.append(COMPLEX_NODE_FUNCS[fn])\n",
    "            self.node_types = nt\n",
    "\n",
    "    \n",
    "    def __init__(self, source=None):\n",
    "        # Set instance vars\n",
    "        self.feedforward    = False\n",
    "        self.sandwich       = False   \n",
    "        self.cm             = None\n",
    "        self.node_types     = None\n",
    "        self.original_shape = None\n",
    "        self.sum_all_node_inputs = False\n",
    "        self.all_nodes_same_function = False\n",
    "        \n",
    "        if source is not None:\n",
    "            try:\n",
    "                self.from_matrix(*source.get_network_data())\n",
    "                if hasattr(source, 'feedforward') and source.feedforward:\n",
    "                    self.make_feedforward()\n",
    "            except AttributeError as e:\n",
    "                print(e)\n",
    "                raise Exception(\"Cannot convert from %s to %s\" % (source.__class__, self.__class__))\n",
    "\n",
    "    def make_sandwich(self):\n",
    "        \"\"\" Turns the network into a sandwich network,\n",
    "            a network with no hidden nodes and 2 layers.\n",
    "        \"\"\"\n",
    "        self.sandwich = True\n",
    "        self.cm = np.hstack((self.cm, np.zeros(self.cm.shape)))\n",
    "        self.cm = np.vstack((np.zeros(self.cm.shape), self.cm))\n",
    "        self.act = np.zeros(self.cm.shape[0])\n",
    "        return self\n",
    "        \n",
    "    def num_nodes(self):\n",
    "        return self.cm.shape[0]\n",
    "        \n",
    "    def make_feedforward(self):\n",
    "        \"\"\" Zeros out all recursive connections. \n",
    "        \"\"\"\n",
    "        if np.triu(np.nan_to_num(self.cm)).any():\n",
    "            raise Exception(\"Connection Matrix does not describe feedforward network. \\n %s\" % np.sign(self.cm))\n",
    "        self.feedforward = True\n",
    "        self.cm[np.triu_indices(self.cm.shape[0])] = 0\n",
    "        \n",
    "    def flush(self):\n",
    "        \"\"\" Reset activation values. \"\"\"\n",
    "        self.act = np.zeros(self.cm.shape[0])\n",
    "        \n",
    "    def feed(self, input_activation, add_bias=True, propagate=1):\n",
    "        \"\"\" Feed an input to the network, returns the entire\n",
    "            activation state, you need to extract the output nodes\n",
    "            manually.\n",
    "            \n",
    "            :param add_bias: Add a bias input automatically, before other inputs.\n",
    "        \"\"\"\n",
    "        if propagate != 1 and (self.feedforward or self.sandwich):\n",
    "            raise Exception(\"Feedforward and sandwich network have a fixed number of propagation steps.\")\n",
    "        act = self.act\n",
    "        node_types = self.node_types\n",
    "        cm = self.cm\n",
    "        input_shape = input_activation.shape\n",
    "        \n",
    "        if add_bias:\n",
    "            input_activation = np.hstack((1.0, input_activation))\n",
    "        \n",
    "        if input_activation.size >= act.size:\n",
    "            raise Exception(\"More input values (%s) than nodes (%s).\" % (input_activation.shape, act.shape))\n",
    "        \n",
    "        input_size = min(act.size - 1, input_activation.size)\n",
    "        node_count = act.size\n",
    "        \n",
    "        # Feed forward nets reset the activation, and activate as many\n",
    "        # times as there are nodes\n",
    "        if self.feedforward:\n",
    "            act = np.zeros(cm.shape[0])\n",
    "            propagate = len(node_types)\n",
    "        # Sandwich networks only need to activate a single time\n",
    "        if self.sandwich:\n",
    "            propagate = 1\n",
    "        for _ in range(propagate):\n",
    "            act[:input_size] = input_activation.flat[:input_size]\n",
    "            \n",
    "            if self.sum_all_node_inputs:\n",
    "                nodeinputs = np.dot(self.cm, act)\n",
    "            else:\n",
    "                nodeinputs = self.cm * act\n",
    "                nodeinputs = [ni[-np.isnan(ni)] for ni in nodeinputs]\n",
    "            \n",
    "            if self.all_nodes_same_function:\n",
    "                act = node_types[0](nodeinputs)\n",
    "            else:\n",
    "                for i in range(len(node_types)):\n",
    "                    act[i] = node_types[i](nodeinputs[i])\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "        # Reshape the output to 2D if it was 2D\n",
    "        if self.sandwich:\n",
    "            return act[act.size//2:].reshape(input_shape)      \n",
    "        else:\n",
    "            return act.reshape(self.original_shape)\n",
    "\n",
    "    def cm_string(self):\n",
    "        print(\"Connectivity matrix: %s\" % (self.cm.shape,))\n",
    "        cp = self.cm.copy()\n",
    "        s = np.empty(cp.shape, dtype='a1')\n",
    "        s[cp == 0] = ' '\n",
    "        s[cp > 0] = '+'\n",
    "        s[cp < 0] = '-'\n",
    "        return '\\n'.join([''.join(l) + '|' for l in s])\n",
    "\n",
    "    \n",
    "    def visualize(self, filename, inputs=3, outputs=1):\n",
    "        \"\"\" Visualize the network, stores in file. \"\"\"\n",
    "        if self.cm.shape[0] > 50:\n",
    "            return\n",
    "        import pygraphviz as pgv\n",
    "        # Some settings\n",
    "        node_dist = 1\n",
    "        cm = self.cm.copy()\n",
    "        # Sandwich network have half input nodes.\n",
    "        if self.sandwich:\n",
    "            inputs = cm.shape[0] // 2\n",
    "            outputs = inputs\n",
    "        # Clear connections to input nodes, these arent used anyway\n",
    "\n",
    "        G = pgv.AGraph(directed=True)\n",
    "        mw = abs(cm).max()\n",
    "        for i in range(cm.shape[0]):\n",
    "            G.add_node(i)\n",
    "            t = self.node_types[i].__name__\n",
    "            G.get_node(i).attr['label'] = '%d:%s' % (i, t[:3])\n",
    "            for j in range(cm.shape[1]):\n",
    "                w = cm[i,j]\n",
    "                if abs(w) > 0.01:\n",
    "                    G.add_edge(j, i, penwidth=abs(w)/mw*4, color='blue' if w > 0 else 'red')\n",
    "        for n in range(inputs):\n",
    "            pos = (node_dist*n, 0)\n",
    "            G.get_node(n).attr['pos'] = '%s,%s!' % pos\n",
    "            G.get_node(n).attr['shape'] = 'doublecircle'\n",
    "            G.get_node(n).attr['fillcolor'] = 'steelblue'\n",
    "            G.get_node(n).attr['style'] = 'filled'\n",
    "        for i,n in enumerate(range(cm.shape[0] - outputs,cm.shape[0])):\n",
    "            pos = (node_dist*i, -node_dist * 5)\n",
    "            G.get_node(n).attr['pos'] = '%s,%s!' % pos\n",
    "            G.get_node(n).attr['shape'] = 'doublecircle'\n",
    "            G.get_node(n).attr['fillcolor'] = 'tan'\n",
    "            G.get_node(n).attr['style'] = 'filled'\n",
    "        \n",
    "        G.node_attr['shape'] = 'circle'\n",
    "        if self.sandwich: \n",
    "            # neato supports fixed node positions, so it's better for\n",
    "            # sandwich networks\n",
    "            prog = 'neato'\n",
    "        else:\n",
    "            prog = 'dot'\n",
    "        G.draw(filename, prog=prog)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Neuralnet with %d nodes.' % (self.act.shape[0])\n",
    "    \n",
    "\n",
    "\"\"\" Input/output relation task. Every input and output\n",
    "    is explicitly defined. XOR is an example of this task.\n",
    "\"\"\"\n",
    "\n",
    "### IMPORTS ###\n",
    "import random\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Local\n",
    "\n",
    "\n",
    "\n",
    "class XORTask(object):\n",
    "    \n",
    "    # Default XOR input/output pairs\n",
    "    INPUTS  = [(0,0), (0,1), (1,0), (1,1)]\n",
    "    OUTPUTS = [(-1,), (1,), (1,), (-1,)]\n",
    "    EPSILON = 1e-100\n",
    "    \n",
    "    def __init__(self, do_all=True):\n",
    "        self.do_all = do_all\n",
    "        self.INPUTS = np.array(self.INPUTS, dtype=float)\n",
    "        self.OUTPUTS = np.array(self.OUTPUTS, dtype=float)\n",
    "    \n",
    "    def evaluate(self, network, verbose=False):\n",
    "        if not isinstance(network, NeuralNetwork):\n",
    "            network = NeuralNetwork(network)\n",
    "        \n",
    "        network.make_feedforward()\n",
    "        \n",
    "        pairs = list(zip(self.INPUTS, self.OUTPUTS))\n",
    "        random.shuffle(pairs)\n",
    "        if not self.do_all:\n",
    "            pairs = [random.choice(pairs)]\n",
    "        rmse = 0.0\n",
    "        for (i, target) in pairs:\n",
    "            # Feed with bias\n",
    "            output = network.feed(i)\n",
    "            # Grab the output\n",
    "            output = output[-len(target):]\n",
    "            err = (target - output)\n",
    "            err[abs(err) < self.EPSILON] = 0;\n",
    "            err = (err ** 2).mean()\n",
    "            # Add error\n",
    "            if verbose:\n",
    "                print(\"%r -> %r (%.2f)\" % (i, output, err))\n",
    "            rmse += err \n",
    "\n",
    "        score = 1/(1+np.sqrt(rmse / len(pairs)))\n",
    "        return {'fitness': score}\n",
    "        \n",
    "    def solve(self, network):\n",
    "        return int(self.evaluate(network)['fitness'] > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 3\n",
    "outputs = 4\n",
    "nonlinearities = ['tanh']\n",
    "topology = None\n",
    "feedforward = True\n",
    "max_depth = None\n",
    "max_nodes = float('inf')\n",
    "bias_as_node = False\n",
    "initial_weight_stdev = 2.0\n",
    "p_add_neuron = 0.03\n",
    "p_add_connection = 0.3\n",
    "p_mutate_weight = 0.8\n",
    "p_reset_weight = 0.1\n",
    "p_reenable_connection = 0.01\n",
    "p_disable_connection = 0.01\n",
    "p_reenable_parent=0.25\n",
    "p_mutate_bias = 0.2\n",
    "p_mutate_type = 0.2\n",
    "stdev_mutate_weight = 1.5\n",
    "stdev_mutate_bias = 0.5\n",
    "weight_range = (-50.,50.)\n",
    "\n",
    "distance_excess_weight = 1.0\n",
    "distance_disjoint_weight = 1.0\n",
    "distance_weight = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Generation 1 ==\n",
      "Best (0.43): <__main__.Genotype object at 0x7f18e21a8e10> {'fitness': 0.4293012081629934}\n",
      "Solved: None\n",
      "\n",
      "== Generation 2 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2306d68> {'fitness': 0.4997914051002222}\n",
      "Solved: None\n",
      "\n",
      "== Generation 3 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e34d5470> {'fitness': 0.4999997639043954}\n",
      "Solved: None\n",
      "\n",
      "== Generation 4 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e34d5470> {'fitness': 0.4999997639043954}\n",
      "Solved: None\n",
      "\n",
      "== Generation 5 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22e36d8> {'fitness': 0.4999999999999919}\n",
      "Solved: None\n",
      "\n",
      "== Generation 6 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22e36d8> {'fitness': 0.4999999999999919}\n",
      "Solved: None\n",
      "\n",
      "== Generation 7 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2320c88> {'fitness': 0.499999999999997}\n",
      "Solved: None\n",
      "\n",
      "== Generation 8 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 9 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 10 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 11 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 12 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 13 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 14 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e26f0358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 15 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 16 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 17 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 18 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 19 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 20 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 21 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 22 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 23 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 24 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 25 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 26 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 27 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 28 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 29 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e241e780> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 30 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 31 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 32 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 33 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 34 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 35 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 36 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 37 ==\n",
      "Best (0.54): <__main__.Genotype object at 0x7f18e2320390> {'fitness': 0.5352308720899692}\n",
      "Solved: None\n",
      "\n",
      "== Generation 38 ==\n",
      "Best (0.51): <__main__.Genotype object at 0x7f18e32fa5c0> {'fitness': 0.505978048617464}\n",
      "Solved: None\n",
      "\n",
      "== Generation 39 ==\n",
      "Best (0.51): <__main__.Genotype object at 0x7f18e32fa5c0> {'fitness': 0.505978048617464}\n",
      "Solved: None\n",
      "\n",
      "== Generation 40 ==\n",
      "Best (0.51): <__main__.Genotype object at 0x7f18e32fa5c0> {'fitness': 0.505978048617464}\n",
      "Solved: None\n",
      "\n",
      "== Generation 41 ==\n",
      "Best (0.51): <__main__.Genotype object at 0x7f18e32fa5c0> {'fitness': 0.505978048617464}\n",
      "Solved: None\n",
      "\n",
      "== Generation 42 ==\n",
      "Best (0.51): <__main__.Genotype object at 0x7f18e32fa5c0> {'fitness': 0.505978048617464}\n",
      "Solved: None\n",
      "\n",
      "== Generation 43 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 44 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 45 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 46 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 47 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 48 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 49 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 50 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 51 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 52 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 53 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 54 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 55 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 56 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 57 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 58 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 59 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2207978> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 60 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e232e358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 61 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e242bf60> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 62 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e2111518> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 63 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f192cf5ac50> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 64 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e232e128> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 65 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22ff358> {'fitness': 0.5}\n",
      "Solved: None\n",
      "\n",
      "== Generation 66 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22fe860> {'fitness': 0.5000000000023036}\n",
      "Solved: None\n",
      "\n",
      "== Generation 67 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f192ceba080> {'fitness': 0.5000000233146523}\n",
      "Solved: None\n",
      "\n",
      "== Generation 68 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22fe208> {'fitness': 0.5000005150802979}\n",
      "Solved: None\n",
      "\n",
      "== Generation 69 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22fe208> {'fitness': 0.5000005150802979}\n",
      "Solved: None\n",
      "\n",
      "== Generation 70 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e22fe7f0> {'fitness': 0.5000221674849281}\n",
      "Solved: None\n",
      "\n",
      "== Generation 71 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 72 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Generation 73 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 74 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 75 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 76 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 77 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 78 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 79 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 80 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 81 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 82 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 83 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 84 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 85 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 86 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 87 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 88 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 89 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 90 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 91 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 92 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e21b81d0> {'fitness': 0.5011493507923912}\n",
      "Solved: None\n",
      "\n",
      "== Generation 93 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e240bcf8> {'fitness': 0.5000000000000002}\n",
      "Solved: None\n",
      "\n",
      "== Generation 94 ==\n",
      "Best (0.50): <__main__.Genotype object at 0x7f18e240bcf8> {'fitness': 0.5000000000000002}\n",
      "Solved: None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-860-ed1dd2198f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melitism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_when_solved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament_selection_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatibility_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompatibility_threshold_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_species\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_elitism_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myoung_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myoung_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_multiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstagnation_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_innovations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurvival\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXORTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-856-82a6dd5ae85c>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(self, evaluator, generations, solution, reset, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-856-82a6dd5ae85c>\u001b[0m in \u001b[0;36m_evolve\u001b[0;34m(self, evaluator, solution)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mspecie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_compatibility_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                     \u001b[0mspecie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-854-5b064c3f7632>\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minnovation_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_innovations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minnovation_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself_connections\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minnovation_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_connections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_connections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minnovation_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother_connections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minnovation_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0minnovation_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself_connections\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minnovation_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_connections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "elitism = True\n",
    "stop_when_solved = False \n",
    "tournament_selection_k = 3 \n",
    "verbose = True\n",
    "max_cores = 1\n",
    "compatibility_threshold = 3.0\n",
    "compatibility_threshold_delta = 0.4 \n",
    "target_species = 12\n",
    "minimum_elitism_size = 5 \n",
    "young_age = 10\n",
    "young_multiplier = 1.2 \n",
    "old_age = 30\n",
    "old_multiplier = 0.2 \n",
    "stagnation_age = 15\n",
    "reset_innovations = False\n",
    "survival = 0.2\n",
    "\n",
    "# genome_factory = lambda: Genotype(inputs, outputs, nonlinearities, topology, feedforward, max_depth, max_nodes, bias_as_node, \n",
    "#                                   p_add_neuron, p_add_connection, p_mutate_weight, p_reenable_connection, p_disable_connection, \n",
    "#                                   p_reenable_parent, p_mutate_bias, p_mutate_type, \n",
    "#                                   distance_excess_weight, distance_disjoint_weight, distance_weight)\n",
    "\n",
    "genome_factory = lambda: Genotype(inputs, outputs, nonlinearities, topology, feedforward, max_depth, max_nodes, initial_weight_stdev, bias_as_node, p_add_neuron, p_add_connection, p_mutate_weight, p_reenable_connection, p_disable_connection, p_reenable_parent, p_mutate_bias, p_mutate_type, stdev_mutate_weight, stdev_mutate_bias, weight_range, distance_excess_weight, distance_disjoint_weight, distance_weight)\n",
    "\n",
    "population = Population(genome_factory, population_size, elitism, stop_when_solved, tournament_selection_k, verbose, max_cores, compatibility_threshold, compatibility_threshold_delta, target_species, minimum_elitism_size, young_age, young_multiplier, old_age, old_multiplier, stagnation_age, reset_innovations, survival)\n",
    "task = XORTask()\n",
    "population.epoch(evaluator = task, generations = 1000, solution = task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(inputs):\n",
    "    ((fr, to), cg) =inputs\n",
    "    print(fr)\n",
    "\n",
    "conns = {}\n",
    "conns[(1,5)] = [2,2,3]\n",
    "dict(filter(f, conns.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = j = 5\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
